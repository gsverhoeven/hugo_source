{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing online Blood Bowl matches using Python: Pandas and plotnine\n",
    "\n",
    "This blogpost is about **Blood Bowl**, a boardgame I finally started playing last year. The goal of this blog post is to use the `pandas` and `plotnine` Python packages to analyse and visualise the [public dataset of matches I have put together](Link/to/other/blog/post).\n",
    "\n",
    "Blood bowl is a game of Fantasy Football, where not all teams (think \"Orcs\" or \"Elves\") are equally strong. There exists a lively tournament scene. Most tournaments make some effort in order to create a more level playing ground for the different teams to compete. Doing so requires knowledge of the relative team strength when using the official ruleset.\n",
    "\n",
    "In 2020, a new version of the Blood Bowl board game came out with several changes to the rules, and to the available teams to play with.\n",
    "In september 2021, the online Blood Bowl gaming website **FUMBBL** switched to the new ruleset (\"BB2020\"), with players largely abandoning the previous ruleset (from 2016, \"BB2016\" hereafter). \n",
    "\n",
    "With a daily game volume of a few hundred matches, I decided it would be interesting to analyse the win rates of the different teams (or \"races\", given the fantasy world setting), and how these have been impacted by the new ruleset. In gaming, it is common to see rule changes where something can get **nerfed** (made weaker) or **buffed** (made stronger). The goal of changes are common in any gaming community, in an attempt to achieve more balance in the game. \n",
    "\n",
    "We examine whether the current \"three tier\" system to balance the strength differences between teams is optimal. The results can inform changes that improve balance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python packages used in this blog post\n",
    "\n",
    "This blogpost is written as a Jupyter notebook, and is fully reproducible. The idea is to make Blood Bowl data analysis accessible to others. Using only open source tooling reduces the barriers for others to take what i created and build on it. Apart from having Python installed, you need a code editor. Jupyter Notebooks can be read by many code editors, such as Jupyterlab, or Pycharm, i decided to try out [Visual Studio Code](https://code.visualstudio.com/), or **VS code** for short. It ticks all my boxes such as being cross platform (I use linux at home and Windows at work), being open source, and having a large user base, as [visible on Github](https://github.com/microsoft/vscode) with more than 125K stars. It works pretty well, the only thing I really miss is have a [Python console connected to the same kernel my Notebook is running on](https://stackoverflow.com/questions/54987778/is-it-possible-to-link-the-interactive-python-window-to-a-running-jupyter-notebo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "\n",
    "#import statsmodels.api as sm # statistics library\n",
    "\n",
    "# Function for computing confidence intervals\n",
    "from statsmodels.stats.proportion import proportion_confint   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PM Load the four prepped datasets\n",
    "df_matches\n",
    "df_wins\n",
    "df_teams\n",
    "df_inducements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Blood Bowl\n",
    "\n",
    "Blood Bowl is a two player game on a board, with playing pieces, like Chess. But instead of two medieval kingdoms fighting, Blood Bowl is about fantasy football, say Tolkien meets rugby. It appealed to me as a teenager (I bought the game in 1994) because it combined the Warhammer playing pieces I liked so much (miniature models \"minis\" of Orcs, Elves, Dwarves etc) with simple game mechanics, but resulted in complex gameplay. Blood bowl requires a lot of skill to play well, with complex strategic decision making with a lot of uncertainty (heavy dice rolling involved). Blood Bowl is very much alive nowaydays: Over the timespan of a few decennia, an international gaming community has formed around the game, with a players' association, the NAF, with thousands of members, a World championship every two years, and with new editions and models being released on a regular basis. Blood Bowl is not only a game, it is also a sport, [like Chess](https://www.chess.com/article/view/is-chess-a-sport).\n",
    "And with all sports, statistics is not far away. So lets dive in the world of Blood Bowl stats nerdery.\n",
    "\n",
    "# Not all teams are created equal: tiers in Blood Bowl\n",
    "\n",
    "There are around 25 \"official\" races / different teams, such as orcs, elves, humans etc.\n",
    "Each race has different player types, with different strength, abilities, skills, etc.\n",
    "\n",
    "As already mentioned above, Blood Bowl is not balanced with respect to the (30) different team \"races\" available. For example, it is much harder to win a match playing with a **Vampires** team, compared to playing with an **Orc** team. Not surprisingly, teams that have a higher probability of winning are more popular both in Tabletop tournaments as well as online at FUMBBL. \n",
    "\n",
    "According to [this article from the NAF from 2017](https://www.thenaf.net/2017/05/tiers/), already since 2010 efforts were made to balance things out a bit between the different team strengths. For example, the weaker teams get more gold to spend on players, or get more so-called \"Star player points\" to spend on skilling players up. According to [the NAF](https://www.thenaf.net/tournaments/information/tiers-and-tiering/), traditionally team tiering consists of three groups, with Tier 1 being the strongest teams, and tier 3 the weakest teams. \n",
    " \n",
    "\n",
    "Below I made a visualization of these three groups, as well as the new BB2020 tiers per the 2020 rulebook. For **Humans** and **Old World Alliance** it is not entirely clear what is the \"official tier\", as the [current online NAF tournament](https://fumbbl.com/p/group?op=view&group=9298) places them in Tier 2 (same as always), but GW BB2020 places both Humans and Old World Alliance in tier 1, which is kind of weird given that their rules did not change much. So i plotted both.\n",
    "\n",
    "\n",
    "\n",
    "PM Hier moeten de nieuwe tiers bij.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_tiers = pd.read_excel('data/race_tiers_mapping.xlsx',  engine='openpyxl')\n",
    "race_tiers = race_tiers[ ['race_name', 'bb2020_tier', 'naf_tier', 'bb2020_nov21_tier']]\n",
    "race_tiers = race_tiers.dropna()\n",
    "# format for plotnine\n",
    "race_tiers_long = pd.melt(race_tiers, id_vars='race_name', value_vars=['bb2020_tier', 'naf_tier', 'bb2020_nov21_tier'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = race_tiers_long, mapping = p9.aes(x = 'reorder(race_name, value)', y = 'factor(value)', group = 'variable', color = 'variable'))\n",
    "    + p9.geom_point(size = 5) \n",
    "    + p9.coord_flip())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most NAF sanctioned tournaments use some form of tiering, but there exists a lot of variation in how this is implemented.\n",
    "From the [rules for obtaining NAF sanctioning](https://www.thenaf.net/wp-content/uploads/2020/11/NAF_Tournament_Approval_Document_2021.pdf):\n",
    "\n",
    "```\n",
    "Individual rules variations in tournaments are permitted, even encouraged. This is \n",
    "in order to give each tournament its individual character.\n",
    "[...]\n",
    "Modifications should not radically affect the existing balance between \n",
    "races, but incentives may be given to the traditionally less-competitive \n",
    "teams, provided this is in moderation. \n",
    "```\n",
    "\n",
    "For example, for the [World Cup in Austria (2019)](http://www.nafworldcup.sbbm-turniere.com/EN/WC4Rules.html), the Tier 2 teams above were further split up, giving four tiers in total. PM example Dutch open 2020\n",
    "\n",
    "# Analyzing NAF data\n",
    "\n",
    "Because there is all this variation in tiering, it is difficult to draw conclusions from NAF tournament data.\n",
    "We can still try though.\n",
    "\n",
    "Here are the win rates (with a draw counted as half a point) for BB2020 NAF tournaments. These were taken from the [NAF Tableau pages](https://public.tableau.com/app/profile/mike.sann0638.davies/viz/NAFGames_0/Variety) and contain match outcomes of all NAF tournaments since december 2020 using the new ruleset. \n",
    "I added uncertainty intervals assuming a simple \"coin flip\" process with a fixed probability of succes *p*, where i use for *p* the probability of succes that is calculated from the data. This gives us some indication of what variation to expect given the match volumes in the NAF database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naf = pd.read_csv('data/W_Race_Record_Full_Data_data_bb2020.csv', na_values = '')\n",
    "\n",
    "df_naf = df_naf.rename(columns={\"Race\": \"race_name\", \n",
    "                                \"Variant\": \"ruleset_version\", \n",
    "                                \"Win %\": \"wins\"})\n",
    "\n",
    "# transform wins to 0, 0.5 or 1 numeric\n",
    "df_naf['wins'] = df_naf['wins'].str.replace('%$', '')\n",
    "df_naf['wins'] = df_naf['wins'].fillna(0).astype(float).astype(np.int64)\n",
    "df_naf['wins'] = df_naf['wins']/100\n",
    "\n",
    "# add tiers\n",
    "df_naf = pd.merge(df_naf, race_tiers, on='race_name', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidyverse-like data analysis with Pandas and plotnine\n",
    "\n",
    "Doing most of my day to day analysis in `R`, i am (by now) used to the tidyverse philosophy of breaking things up in small steps, with each step on a separate line, and in order of execution (from left to right, top to bottom). Luckily, the `Pandas` data analysis library allows us to do something similar, here it is called `method chaining`.\n",
    "The idea is that a Pandas object has methods for all the small operations we want to perform, and the python language that allows chaining these methods together.\n",
    "\n",
    "Here we demonstrate this by calculating average win percentage by race, and calling this result `perc_win`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_naf\n",
    "    .groupby(['race_name', 'ruleset_version', 'naf_tier'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .sort_values( 'n_games', ascending = False)\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res = res.dropna()\n",
    "\n",
    "\n",
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )\n",
    "\n",
    "(p9.ggplot(data = res, mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(ruleset_version)', color = 'factor(ruleset_version)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI', color = 'factor(naf_tier)'))\n",
    "    + p9.geom_point(colour = \"black\" )\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates NAF BB2020 tournaments\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, even with most tournaments having some form of tiering, there are still teams that win (in) NAF tournaments more often than others. For example, this quote is from the most recent [\"NAF tournament report\"](https://www.thenaf.net/rankings/elo-ranking/tableau/the-naf-report-2/):\n",
    "\n",
    "```\n",
    "Underworld continued to dominate in October, winning the two largest tournaments and maintaining the greater than 60% win ratio.  This is\n",
    "generally due to swarming giving them more players on the pitch and the use of Hakflem and Morg'n'Thorg. (N.b. these are special \"Star Players\" that can be added to teams)\n",
    "```\n",
    "\n",
    "This is exactly what we saw above in the NAF data. At the same time, we see that in the NAF tournaments, **Skaven** (A tier 1 team) win equally often as **Ogres**, a tier 3 team. This could very well be because of the tiering systems being used. Of course, it could also be that with more data, **Skaven** would in fact have a win rate that is a few percentage higher.\n",
    "\n",
    "However, the best way to learn about the teams relative strength is in the absence of any tiering. Then we can directly interpret the win rates as measuring relative team strength. For this, we turn to online Blood Bowl, and more specific, to **FUMBBL**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blood Bowl online: FUMBBL \n",
    "\n",
    "Blood Bowl can also be played online. A paid version called \"Blood Bowl 2\" with appealing 3D graphics is available on [Steam](https://store.steampowered.com/app/236690/Blood_Bowl_2/). However, a more basic (2D) version is available as [FUMBBL](https://fumbbl.com). It uses a Java client that uploads game results to an online server with an accompanying website that supports the managerial and community aspects of the game (Forming teams, using winnings to buy new players, organizing tournaments, forum discussions etc).\n",
    "The name **FUMBBL** is likely a wordplay on the combination of fumble (losing the ball in American Football) and BBL which stands for Blood Bowl League.\n",
    "\n",
    "The **FUMBBL** website (https://fumbbl.com) is one big pile of data. From coach pages, with their teams, to team rosters, with players, and match histories. It's all there.\n",
    "And the nice thing of **FUMBBL** , for our purpose, is that it has several divisions where all teams start out equal, i.e. there is no tiering system in place.\n",
    "This allows us to learn what the relative team strengths are purely under the GW BB2020 rules.\n",
    "\n",
    "To obtain **FUMBBL** data, we need to fetch it match by match, team by team. To do so, the site creator Christer Kaivo-oja, from Sweden, has made an API that allows us to easily fetch data. What follows is a short demonstration how the API works, before we fetch the **FUMBBL** match and team data of the last 12 months.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First analysis: Orcs are most popular!\n",
    "\n",
    "Which races are the most popular on FUMBLL in the last year?\n",
    "For this, we need only to count which races were chosen how many times.\n",
    "\n",
    "However, since each match contains two teams, we need to create a new dataframe `df_races`, double in size, that contains for each row the `match_id` and `team_race` of one of the two teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team1_races = df_matches[['match_id', 'team1_race_name']]\n",
    "team2_races = df_matches[['match_id', 'team2_race_name']]\n",
    "\n",
    "# make column names equal\n",
    "team1_races.columns = team2_races.columns = ['match_id', 'race_name']\n",
    "\n",
    "# row bind the two dataframes\n",
    "df_races = pd.concat([team1_races, team2_races])\n",
    "\n",
    "# aggregate by race_name\n",
    "res = (df_races\n",
    "        .groupby(['race_name'])\n",
    "        .size()\n",
    "        .reset_index(name='n_games')\n",
    ")\n",
    "\n",
    "# select most popular races for filtering\n",
    "top_races = res.loc[(res.n_games > 1000)]['race_name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res.loc[res['race_name'].isin(top_races)], mapping = p9.aes(x = 'reorder(race_name, n_games)', y = 'n_games'))\n",
    "    + p9.geom_point(colour = 'gray') \n",
    "    + p9.expand_limits(y = 0)\n",
    "    + p9.coord_flip()\n",
    "    + p9.ggtitle('team races with at least 1000 FUMBBL matches in 2020-2021'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the orcs are most popular! Here we should keep in mind that we have pooled all the FUMBBL matches of last year. Of course, Black Orcs and Imperial Nobility are new BB2020 teams, having only been available on FUMBBL since september 2021.\n",
    "And daemons of Khorne, Slann and Bretonnian are not available in two large FUMBBL divisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match outcomes: How much is a draw worth?\n",
    "\n",
    "If we want to calculate a win rate for each race, we need to decide what to do with draws.\n",
    "I've never given the matter much thought, but it turns out other people have!\n",
    "\n",
    "For example, in football, there is a popular weighting scheme where wins are given 3 points, draws 1 point and losses 0 points.\n",
    "This is called [three points for a win](https://en.wikipedia.org/wiki/Three_points_for_a_win) . \n",
    "In Blood bowl leagues and tournaments, this rule is often used as well.\n",
    "So, if we want to predict which teams perform best in these settings (have the highest probability of winning a tournament), we need to weigh the match outcomes accordingly.\n",
    "\n",
    "However, in Blood Bowl data analysis, it seems that a 2:1:0 (W / D / L) weighting scheme is most commonly used. \n",
    "This scheme has the advantage that the weighted average win percentage over all matches is always 50%, creating a nice reference point allowing conclusions such as this and that team has an x percent above average win percentage.\n",
    "\n",
    "For example, Mike Davies from the NAF calculates win rate by weighting each win as 1 point, and each draw as 0.5 points (For example, [here](https://public.tableau.com/app/profile/mike.sann0638.davies/viz/NAFGames_0/SuccessBB2020)).\n",
    "\n",
    "So if we want to compare with others, it makes sense to adapt this scheme as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the divisions and leagues to analyse\n",
    "\n",
    "FUMBBL allows coaches to create their own rulesets to play their own leagues and tournaments with. For example, there is a so-called \"Secret League\" where coaches can play with \"Ninja halflings\", of with \"Ethereal\" spirits etc. \n",
    "\n",
    "Since we want the team strength for the official rulesets BB2016 and BB2020, we need to drop the matches that are played under different rules.\n",
    "\n",
    "Lets have look at the various divisions and leagues, which rulesets are used, and which races are played how often.\n",
    "There are a lot of small leagues being played on FUMBBL, they account for maybe X% of all the matches.\n",
    "\n",
    "We only look at divisions and leagues with a sufficient volume of matches, or otherwise we do not have sufficient statistics for each race.\n",
    "\n",
    "So I aggregated the data by division, league and ruleset, and filtered on at least 150 different teams that have played at least once last year.\n",
    "Apart from the main \"Divisions\" that are part of FUMBBL, there were a few user-run leagues present in this table, so I looked up their names on FUMBBL and what ruleset is used (BB2016, BB2020 or some other variant). This information (contained in an xlsx) is added to the dataset below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ruleset_version and division_name from xlsx\n",
    "ruleset_division_names = pd.read_excel('data/ruleset_division_names.xlsx',  engine='openpyxl')\n",
    "\n",
    "df_teams = pd.merge(df_teams, ruleset_division_names, on= ['league', 'ruleset', 'division_id'], how='left')\n",
    "\n",
    "df_teams['division_name'] = df_teams['new_division_name']\n",
    "\n",
    "df_teams = df_teams.drop('new_division_name', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_teams\n",
    "    .groupby(['ruleset', 'league', 'division_id', 'division_name',  'ruleset_version'], dropna=False)\n",
    "    .agg( n_teams = ('ruleset', 'count')\n",
    "    )\n",
    "    .sort_values('n_teams', ascending = False)\n",
    "    .query('n_teams > 150')['n_teams']\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are primary interested in the new BB2020 ruleset version. We see that apart from the new **Competitive** division of FUMBBL itself, already a few user run leagues have started to use BB2020 rules. However, I chose to not include these leagues in the comparison: \n",
    "\n",
    "* Both NAF and Lega Gladio tournaments consist of a mix of BB2016 and BB2020 matches, making these more difficult to analyse. \n",
    "* Then there is the Secret League, which is different because of all the extra teams available there. \n",
    "* Test Open League BB2020 has likely been the test group before the Competitive Division became available.\n",
    "\n",
    "The NAF tournaments current ruleset is interesting, because it introduces (for the first time) tiers in FUMBBL!\n",
    "The NAF online tournament allows coaches to distribute a fixed number of skills, depending on the team's tier.\n",
    "This makes match outcomes in this league less comparable to other divisions on FUMBBL.\n",
    "\n",
    "Then on to the BB2016 ruleset. Here we have three big FUMBBL divisions: Blackbox, Ranked and (regular) League.\n",
    "Blackbox and Ranked use ruleset 1. FUMBBL has a nice display of a rulesets, see e.g. here for [ruleset 1](https://fumbbl.com/p/ruleset?id=1). Comparing this ruleset to the ruleset used in the BB2016 regular league, we find a few small differences: e.g. the latter has the special play cards, has a few extra teams available (e.g. Simyin), but does not allow for wizards and does not the use the expensive mistakes rule.\n",
    "\n",
    "To get sufficient observations for all the 25+ teams, we need at least a few thousands matches played.\n",
    "\n",
    "So we end up with comparing\n",
    "\n",
    "* Competitive BB2020\n",
    "\n",
    "VERSUS\n",
    "\n",
    "* Ranked BB2016\n",
    "* Black box BB2016\n",
    "* standard BB2016 League division (ruleset 6 / league 0)\n",
    "\n",
    "If the differences between these three division can be considered to be small, we can pool the matches from these three leagues to get better statistics.\n",
    "So lets compare win rates between these three divisions. To do so we add the division information to the `df_wins` data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Time series of number of games\n",
    "\n",
    "Now that we have a proper `datetime` type variable for each week, `week_date`, we can use plotnine to plot a nice time series graph of the total number of games played each week.\n",
    "The introduction of the new **Competitive** league with BB2020 rules is marked by a vertical red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins\n",
    "    .loc[(df_wins['week_date'] >= '2020-09-01' ) & (df_wins['week_date'] < '2021-11-25')]\n",
    "    .groupby(['week_date', 'week_number'])\n",
    "    .agg(        \n",
    "        n_games = ('race_name', \"count\") \n",
    "    )\n",
    "\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res['n_games'] = res['n_games']/2 # each games creates two rows in df_wins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res, mapping = p9.aes(x = 'week_date', y = 'n_games', group = '1'))\n",
    "    + p9.geom_point() \n",
    "    + p9.geom_line()\n",
    "    + p9.expand_limits(y=[0,2000])\n",
    "    + p9.geom_vline(xintercept = '2021-09-01', color = \"red\")\n",
    "    + p9.ggtitle(\"Total FUMBBL games played in the last year\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a check on our data fetching work, we compare with the plots that FUMBBL itself provides at https://fumbbl.com/p/stats.\n",
    "\n",
    "Comparing with the 30-week Statistics plot on the FUMMBBL we can conclude that our dataset for sept 2020/ okt 2021 is complete!\n",
    "The effect of starting the new BB2020 division is also clearly visible, with the number of games played each week almost doubling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Games per week by division\n",
    "\n",
    "We already look at the number of teams playing in each division.\n",
    "Now let us have a look at game volume over time, within the various divisions and leagues / tournaments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins\n",
    "    .loc[(df_wins['week_date'] >= '2020-09-01' ) & (df_wins['week_date'] < '2021-11-25')]\n",
    "    .groupby(['division_name', 'week_date', 'year'])\n",
    "    .agg(        \n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res['n_games'] = res['n_games']/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res.query(\"division_name != 'FFB Test'\"), mapping = p9.aes(x = 'week_date', y = 'n_games', \n",
    "group = 'factor(division_name)', color = 'factor(division_name)'))\n",
    "    + p9.geom_point() \n",
    "    + p9.geom_line()\n",
    "    + p9.expand_limits(y=[0,2000])\n",
    "    + p9.ggtitle(\"FUMBBL games played in the last year\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is interesting to compare the *Black box* division with the *League* division."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: win rate Blackbox vs Ranked vs League division\n",
    "\n",
    "Now in the end, we want to compare BB2016 with BB2020. But as we can see above, there are various BB2016 divisions.\n",
    "Can we just pool them? Or are there differences that are important for our comparison?\n",
    "\n",
    "Lets first check out the BB2016 divisions.\n",
    "\n",
    "Does it matter if coaches both need to agree for a match as in the `Ranked` division? \n",
    "For the BB2016 rules, we have data for both divisions, one in which coaches can choose their opponent, and one for which they are randomly matched to other teams. \n",
    "\n",
    "First, compare Team value distributions between the two divisions, to see what exactly we are comparing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2016_divisions = ['Ranked', 'Regular_league', 'Blackbox']\n",
    "\n",
    "(p9.ggplot(data = df_wins[df_wins['division_name'].isin(bb2016_divisions)], mapping = p9.aes(x = 'reorder(division_name, team_value)', y = 'team_value', \n",
    "group = 'factor(division_name)', color = 'factor(division_name)'))\n",
    "    + p9.geom_boxplot()\n",
    "    #+ p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 1100)\n",
    "    + p9.ggtitle(\"Team value distributions\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, regular league (tournaments) have much lower team value, with a median slightly above 1100, often used for tournaments.\n",
    "This makes sense, as people tend to play longer with teams outside of leagues / tournaments, which force redrafts and / or are limited in duration.\n",
    "So, we have to look within TV bins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bb2016_divisions = ['Ranked', 'Regular_league']\n",
    "bb2016_divisions = ['Ranked', 'Blackbox', 'Regular_league']\n",
    "\n",
    "#tv_bins = ['1K', '1.3K', '1.6K']\n",
    "tv_bins = ['1.1K', '1.4K', '1.7K']\n",
    "\n",
    "res = (df_wins[df_wins['division_name'].isin(bb2016_divisions)]\n",
    "    .loc[df_wins['tv_bin'].isin(tv_bins)]\n",
    "    .groupby(['division_name', 'ruleset_version', 'race_name', 'tv_bin'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .sort_values( 'n_games', ascending = False)\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res = res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Function for computing confidence intervals\n",
    "from statsmodels.stats.proportion import proportion_confint   \n",
    "\n",
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(p9.ggplot(data = res.query('n_games > 10 & tv_bin == \"1.1K\"'), mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(division_name)', color = 'factor(division_name)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI'), position=p9.position_dodge2(preserve='single'))\n",
    "    + p9.geom_point(shape = '|', size = 5) # color = 'black', \n",
    "    + p9.facet_wrap('tv_bin')\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates Ranked vs Regular league\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.query('tv_bin == \"1.1K\" & division_name == \"Regular_league\" & race_name == \"Amazon\" & mirror_match == 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we compare Ranked vs regular league **within Team value bins**, no clear substantial differences appear.\n",
    "This suggests we can pool both leagues and compare both to the Competitive BB2020 match results.\n",
    "As long as we use team value bins, like \"Taureau Amiral\".\n",
    "\n",
    "\n",
    "*Conclusions for Ranked vs Black box*\n",
    "For the lower tier teams Ogre, Halfling and Goblin, clear differences can be seen between Ranked and Blackbox. Black box performance is lower.\n",
    "This suggests that we see the effect of strategically avoiding certain opponents, which is not possible in Blackbox. \n",
    "\n",
    "This argument could also explain the lower performance of Amazon at higher TV, which are known to perform better at low TV.\n",
    "For Chaos Chosen, we see a pattern that could be explained if players in Ranked strategically choose their opponents to skill up the team, which is known to only become competitive at higher team value.\n",
    "\n",
    "This gives some strength to the argument that the Competitive Division is not a **truly** competitive division, since players can choose their opponents, which is not possible at tournaments, and at random matching environments such as Blackbox was.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main analysis: win rate BB2016 vs BB2020\n",
    "\n",
    "If we want two summary statistics instead of one, we need to use the `agg()` method.\n",
    "Furthermore, if we want the variable we group over as a regular column in the DataFrame, we need to use `reset_index()`.\n",
    "Now we have the data ready to make a nice plot.\n",
    "\n",
    "We are going to do the comparison for the main divisions that use BB2016 and BB2020 rules.\n",
    "The BB2016 rules are in three divisions: Blackbox, Ranked and regular league.\n",
    "\n",
    "We drop so-called **mirror matches** (a small percentage of matches) where for example Orcs play Orcs.\n",
    "\n",
    "We also restrict the analysis to matches **without Star Players**. This way, we can exclude that the win rate was influenced by popular Star Players such as Hakflem, Morg or Griff.\n",
    "\n",
    "AND, we also restrict ourself to matches where the coach difference is small (less than 5), so that we can with more confidence attribute the outcome to the races, and not to the ability of the coach.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_divisions = ['Blackbox', 'Ranked', 'Regular_league', 'Competitive']\n",
    "\n",
    "res = (df_wins[df_wins['division_name'].isin(main_divisions)]\n",
    "    .query('mirror_match == 0 & has_sp == 0 & CR_diff < 5')\n",
    "    .groupby(['race_name', 'ruleset_version', 'naf_tier', 'tv_bin'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .query('n_games > 0')\n",
    "    .reset_index()) # this adds the group by variable (now index) as a column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_wins[df_wins['division_name'].isin(main_divisions)]\n",
    "    .query('mirror_match == 0 & has_sp == 0 & CR_diff < 5'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding credible intervals for the win rates\n",
    "\n",
    "Comparing the win rates of BB2016 and BB2020 to koadah's dataset on http://fumbbldata.azurewebsites.net/stats.html , we find strong agreement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )\n",
    "#np.sum(res.query('ruleset_version == \"bb2020\"')[['n_games']])/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(p9.ggplot(data = res.query('n_games > 10 & tv_bin == \"1.1K\" '), mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(ruleset_version)', color = 'factor(ruleset_version)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI'))\n",
    "    + p9.geom_point(p9.aes(color = 'factor(naf_tier)') )\n",
    "    + p9.facet_wrap('tv_bin')\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates by ruleset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interpreting these results, we should keep in mind that this is at low Team value, for example starting rosters, without any tiering.\n",
    "\n",
    "First, we check out the new teams introduced in BB2020. Both teams, Imperial nobility and Black orcs, are not the strongest teams around with win rates that are below average.\n",
    "\n",
    "In Tier 1, Amazons and Orcs improved substantially. \n",
    "Surprisingly, Underworld denizens are now among the strongest teams around. \n",
    "\n",
    "In Tier 2, Old World Alliance got substantially worse. There is no evidence for a higher win rate for High Elves, as was observed in the NAF tournament data of 2021.\n",
    "\n",
    "In Tier 3, Halflings and goblins improved. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(p9.ggplot(data = res.query('n_games > 10 & tv_bin == \"1.4K\" '), mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(ruleset_version)', color = 'factor(ruleset_version)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI'))\n",
    "    + p9.geom_point(p9.aes(color = 'factor(naf_tier)') )\n",
    "    + p9.facet_wrap('tv_bin')\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates by ruleset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At higher TV, the uncertainty is larger, as less teams \"make it\" to higher team values. Because it takes time, and the data is from the first three months of BB2020 play, and it takes energy (you can lose a few games, and have to recover from that).\n",
    "\n",
    "The clearest changes at medium team value (around 1.4K +/-150) are improvements for Goblins and for Underworld Denizens. For goblins, the typical inducement is bribes. Even with 150K team value, 3 bribes are often induced, instead of a star player. \n",
    "Both new BB2020 teams, Imperial Nobility and Black Orcs, appear to be below average strength teams."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations and causal effects\n",
    "\n",
    "\n",
    "For the teams that already existed in BB2016, there were a few notable changes in relative team strength.\n",
    "\n",
    "[...]\n",
    "\n",
    "Important: Access to / changes in rules wrt Star players seem important in for example explaining the succes for Underworld.\n",
    "For example, a lot of underworld teams seem to keep Team value low, and choose Hakflem as star player. **NOT TRUE**. \n",
    "\n",
    "Hakflem appears to be very good value for money, according to this [article in Grotty Little Newspaper](https://fumbbl.com/modules.php?op=modload&name=Sections&file=index&req=viewarticle&artid=26&page=8) (from August 28th 2511 :-). In BB2020, Hakflem can be induced for 180K, whereas his roster value is estimated at 220K.\n",
    "\n",
    "PM Hakflem and Morg became more expensive. And even without Hakflem the win rate of Underworld remains super high.So we must conclude it is the team itself (including Swarming) that makes them really powerfull in BB2020.\n",
    "\n",
    "# Elephant in the room\n",
    "\n",
    "Correlation is not causation, as the saying goes. Big elephant here in the room is player ability, which our analysis completely ignores.\n",
    "\n",
    "If the more experienced coaches know which teams are strongest, and choose those teams more often, we will see high win rates for those teams.\n",
    "\n",
    "If a team is more difficult to coach succesfully, inexperienced coaches picking such a team pull the winning rate down. On the other hand, they might be less tempted to pick the team, whereas experienced coaches might be attracted to the team, pulling the winning rate up.\n",
    "\n",
    "So, if experienced coaches have different preferences for teams, compared to inexperienced coaches, this will influence win rates.\n",
    "The win rates we now attribute to differences in innate race strength, might be caused by the unobserved abilities of the coaches playing.\n",
    "\n",
    "Nevertheless, it is striking that the win rates more or less following the tiers \n",
    "\n",
    "PM New NAF FUMBBL tournament with 5 tiers, skill stacking etc.\n",
    "\n",
    "Others have come to similar conclusions, for example [this](https://bbtactics.com/tournament-skill-stacking/)  \n",
    "\n",
    "And check out this ruleset: Project \"all teams viable\". The idea behind this ruleset is to make all teams competitive - while trying to maintain balance.\n",
    "https://bloodbowl.dk/onewebmedia/All_Teams_Viable_Ruleset.pdf\n",
    "\n",
    "Ref to Artificial turf paper.\n",
    "REF NAAR ERRATA NOV 2021 de UW nerfs, en nieuwe tiers. High elves T1, Orcs T2, WTF!!! Niet relevant, maar zijn toch misleidend, zetten nieuwe spelers op het verkeerde been.\n",
    "\n",
    "PM \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subsetting on  strong coaches\n",
    "\n",
    "For this to work we need to divide coach1 and coach2 rankings.\n",
    "\n",
    "PM calculate average coach ranking \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_divisions = ['Blackbox', 'Ranked', 'Regular_league', 'Competitive']\n",
    "\n",
    "res = (df_wins[df_wins['division_name'].isin(main_divisions)]\n",
    "    .query('team_value > 800 & team_value < 2500')\n",
    "    .groupby(['coach_id'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .query('n_games > 100')\n",
    "    .sort_values('perc_win', ascending = False)\n",
    "    .reset_index()) # this adds the group by variable (now index) as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res\n",
    "\n",
    "res['quartile'] = pd.qcut(res['perc_win'], 4, labels=False)\n",
    "\n",
    "# PM select top quartile players, and lower quartile players. Compare n_games by race for both groups. Do winning players choose different teams compared to losing players?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_coaches = res.query(\"quartile == 3\")['coach_id']\n",
    "\n",
    "q4_coaches = res.query(\"quartile == 0\")['coach_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins[df_wins['coach_id'].isin(q1_coaches)]\n",
    "    .query('division_name != \"Competitive\" & tv_bin == \"1.4  K\" & mirror_match == 0')\n",
    "    .groupby(['race_name'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .query('n_games > 150')\n",
    "    .sort_values('perc_win', ascending = False)\n",
    "    .reset_index()) # this adds the group by variable (now index) as a column\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins[df_wins['coach_id'].isin(q4_coaches)]\n",
    "    .query('division_name != \"Competitive\" & tv_bin == \"1.1K\"')\n",
    "    .groupby(['race_name'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .query('n_games > 100')\n",
    "    .sort_values('n_games', ascending = False)\n",
    "    .reset_index()) # this adds the group by variable (now index) as a column\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_wins.query(\"tv_diff > 150 & race_name == 'Human' & division_name == 'Regular_league' & tv_bin == '1K'\").sort_values('race_name')\n",
    "\n",
    "df_wins.query('coach_id == 128852') # starjump\n",
    "df_wins.query('coach_id == 256723') # JepClock\n",
    "df_wins.query('coach_id == 249628') # DaPreacher heeft een super orc team in ranked. Hoge win rates allemaal bij tier 1 teams (dwarf, orc, undead etc)\n",
    "\n",
    "df_wins.query('coach_id == 254756')\n",
    "\n",
    "df_wins['match_id'].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are the most popular inducements?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate by race_name\n",
    "res = (inducements\n",
    "        .query(\"inducements != ''\")\n",
    "        .groupby(['inducements', 'star_player', 'special_card'])\n",
    "        .agg(n_games = ('inducements', \"count\"))\n",
    "        .reset_index()\n",
    "        .sort_values(\"n_games\", ascending=False)\n",
    ")\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res['inducements'].str.contains('bribe', na = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res.query(\"n_games > 100 & star_player == 0 & special_card == 1\"), mapping = p9.aes(x = 'reorder(inducements, n_games)', y = 'n_games'))\n",
    "    + p9.geom_point(colour = 'gray') \n",
    "    + p9.expand_limits(y = 0)\n",
    "    + p9.coord_flip()\n",
    "    + p9.ggtitle('Card Inducements used in 2020-2021'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res.query(\"n_games > 300 & star_player == 1 & special_card == 0\"), mapping = p9.aes(x = 'reorder(inducements, n_games)', y = 'n_games'))\n",
    "    + p9.geom_point(colour = 'gray') \n",
    "    + p9.expand_limits(y = 0)\n",
    "    + p9.coord_flip()\n",
    "    + p9.ggtitle('Star Players used > 300 times in 2020-2021'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uw_match_inducements = df_wins.query(\"race_name == 'Underworld Denizens' & division_name == 'Competitive' & team_value < tv_match\")['match_id']\n",
    "\n",
    "# aggregate by race_name\n",
    "res = (inducements[inducements['match_id'].isin(uw_match_inducements)]\n",
    "        .query(\"inducements != ''\")\n",
    "        .groupby(['inducements', 'star_player', 'special_card'])\n",
    "        .agg(n_games = ('inducements', \"count\"))\n",
    "        .reset_index()\n",
    "        .sort_values(\"n_games\", ascending=False)\n",
    ")\n",
    "\n",
    "(p9.ggplot(data = res.query(\"n_games > 10\"), mapping = p9.aes(x = 'reorder(inducements, n_games)', y = 'n_games'))\n",
    "    + p9.geom_point(colour = 'gray') \n",
    "    + p9.expand_limits(y = 0)\n",
    "    + p9.coord_flip()\n",
    "    + p9.ggtitle('Underworld BB2020 Inducements in 2020-2021'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitive_matches = df_wins.query(\"division_name == 'Competitive'\")['match_id']\n",
    "\n",
    "# aggregate by race_name\n",
    "res = (inducements[inducements['match_id'].isin(competitive_matches)]\n",
    "        .query(\"inducements != ''\")\n",
    "        .groupby(['inducements', 'star_player', 'special_card'])\n",
    "        .agg(n_games = ('inducements', \"count\"))\n",
    "        .reset_index()\n",
    "        .sort_values(\"n_games\", ascending=False)\n",
    ")\n",
    "\n",
    "(p9.ggplot(data = res.query(\"n_games > 100\"), mapping = p9.aes(x = 'reorder(inducements, n_games)', y = 'n_games'))\n",
    "    + p9.geom_point(colour = 'gray') \n",
    "    + p9.expand_limits(y = 0)\n",
    "    + p9.coord_flip()\n",
    "    + p9.ggtitle('Top Inducements for BB2020'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50276fd1884268afe39607052f22ef19b84d915691d702a5c7e9a67a09867105"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('requests_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
