{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing online Blood Bowl matches using Python: API scraping, pandas and plotnine\n",
    "\n",
    "This blogpost is about **Blood Bowl**, a boardgame I finally started playing last year. The goal of this blog post is to use Python API scraping to fetch online Blood Bowl match outcome data, and to use the `pandas` and `plotnine` Python packages to analyse and visualise the data.\n",
    "\n",
    "In 2020, a new version of the Blood Bowl board game came out with several changes to the rules, and to the available teams to play with.\n",
    "Last september, the online Blood Bowl gaming website **FUMBBL** switched to the new ruleset (\"BB2020\"), with players largely abandoning the previous ruleset (from 2016, \"BB2016\" hereafter). With a daily game volume of a few hundred matches, I decided it would be interesting to analyse the win rates of the different teams (or \"races\", given the fantasy world setting), and how these have been impacted by the new ruleset. This is important, because races can get **nerfed** (made weaker) or **buffed** (made stronger) when new versions of the ruleset are released. These changes are common in any gaming community, in an attempt to achieve more balance in the game. We examine whether the current \"three tier\" system to balance the strength differences between teams is optimal. The results can inform changes that improve balance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python packages used in this blog post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import requests # API library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "\n",
    "#import statsmodels.api as sm # statistics library\n",
    "\n",
    "# Function for computing confidence intervals\n",
    "from statsmodels.stats.proportion import proportion_confint   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Blood Bowl\n",
    "\n",
    "Blood Bowl is a two player game on a board, with playing pieces, like Chess. But instead of two medieval kingdoms fighting, Blood Bowl is about fantasy football, say Tolkien meets rugby. It appealed to me as a teenager (I bought the game in 1994) because it combined the Warhammer playing pieces I liked so much (miniature models \"minis\" of Orcs, Elves, Dwarves etc) with simple game mechanics, but resulted in complex gameplay. Blood bowl requires a lot of skill to play well, with complex strategic decision making with a lot of uncertainty (heavy dice rolling involved). Blood Bowl is very much alive nowaydays: Over the timespan of a few decennia, an international gaming community has formed around the game, with a players' association, the NAF, with thousands of members, a World championship every two years, and with new editions and models being released on a regular basis. Blood Bowl is not only a game, it is also a sport, [like Chess](https://www.chess.com/article/view/is-chess-a-sport).\n",
    "And with all sports, statistics is not far away. So lets dive in the world of Blood Bowl stats nerdery.\n",
    "\n",
    "# Not all teams are created equal: tiers in Blood Bowl\n",
    "\n",
    "As already mentioned above, Blood Bowl is not balanced with respect to the (30) different team \"races\" available. For example, it is much harder to win a match playing with a **Vampires** team, compared to playing with an **Orc** team. Not surprisingly, teams that have a higher probability of winning are more popular both in Tabletop tournaments as well as online at FUMBBL. \n",
    "\n",
    "According to [this article from the NAF from 2017](https://www.thenaf.net/2017/05/tiers/), already since 2010 efforts were made to balance things out a bit between the different team strengths. For example, the weaker teams get more gold to spend on players, or get more so-called \"Star player points\" to spend on skilling players up. According to [the NAF](https://www.thenaf.net/tournaments/information/tiers-and-tiering/), traditionally team tiering consists of three groups, with Tier 1 being the strongest teams, and tier 3 the weakest teams. \n",
    " \n",
    "\n",
    "Below I made a visualization of these three groups, as well as the new BB2020 tiers per the 2020 rulebook. For **Humans** and **Old World Alliance** it is not entirely clear what is the \"official tier\", as the [current online NAF tournament](https://fumbbl.com/p/group?op=view&group=9298) places them in Tier 2 (same as always), but GW BB2020 places both Humans and Old World Alliance in tier 1, which is kind of weird given that their rules did not change much. So i plotted both.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_tiers = pd.read_excel('data/race_tiers_mapping.xlsx',  engine='openpyxl')\n",
    "race_tiers = race_tiers[ ['race_name', 'bb2020_tier', 'naf_tier']]\n",
    "race_tiers = race_tiers.dropna()\n",
    "# format for plotnine\n",
    "race_tiers_long = pd.melt(race_tiers, id_vars='race_name', value_vars=['bb2020_tier', 'naf_tier'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = race_tiers_long, mapping = p9.aes(x = 'reorder(race_name, value)', y = 'factor(value)', group = 'variable', color = 'variable'))\n",
    "    + p9.geom_point(size = 5) \n",
    "    + p9.coord_flip())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most NAF sanctioned tournaments use some form of tiering, but there exists a lot of variation in how this is implemented.\n",
    "From the [rules for obtaining NAF sanctioning](https://www.thenaf.net/wp-content/uploads/2020/11/NAF_Tournament_Approval_Document_2021.pdf):\n",
    "\n",
    "```\n",
    "Individual rules variations in tournaments are permitted, even encouraged. This is \n",
    "in order to give each tournament its individual character.\n",
    "[...]\n",
    "Modifications should not radically affect the existing balance between \n",
    "races, but incentives may be given to the traditionally less-competitive \n",
    "teams, provided this is in moderation. \n",
    "```\n",
    "\n",
    "For example, for the [World Cup in Austria (2019)](http://www.nafworldcup.sbbm-turniere.com/EN/WC4Rules.html), the Tier 2 teams above were further split up, giving four tiers in total. PM example Dutch open 2020\n",
    "\n",
    "# Analyzing NAF data\n",
    "\n",
    "Because there is all this variation in tiering, it is difficult to draw conclusions from NAF tournament data.\n",
    "We can still try though.\n",
    "\n",
    "Here are the win rates (with a draw counted as half a point) for BB2020 NAF tournaments. These were taken from the [NAF Tableau pages](https://public.tableau.com/app/profile/mike.sann0638.davies/viz/NAFGames_0/Variety) and contain match outcomes of all NAF tournaments since december 2020 using the new ruleset. \n",
    "I added uncertainty intervals assuming a simple \"coin flip\" process with a fixed probability of succes *p*, where i use for *p* the probability of succes that is calculated from the data. This gives us some indication of what variation to expect given the match volumes in the NAF database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naf = pd.read_csv('data/W_Race_Record_Full_Data_data_bb2020.csv', na_values = '')\n",
    "\n",
    "df_naf = df_naf.rename(columns={\"Race\": \"race_name\", \n",
    "                                \"Variant\": \"ruleset_name\", \n",
    "                                \"Win %\": \"wins\"})\n",
    "\n",
    "# transform wins to 0, 0.5 or 1 numeric\n",
    "df_naf['wins'] = df_naf['wins'].str.replace('%$', '')\n",
    "df_naf['wins'] = df_naf['wins'].fillna(0).astype(float).astype(np.int64)\n",
    "df_naf['wins'] = df_naf['wins']/100\n",
    "\n",
    "# add tiers\n",
    "df_naf = pd.merge(df_naf, race_tiers, on='race_name', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidyverse-like data analysis with Pandas and plotnine\n",
    "\n",
    "Doing most of my day to day analysis in `R`, i am (by now) used to the tidyverse filosophy of breaking things apart in small steps, with each step on a separate line, and in order of execution. Luckily, the `Pandas` data analysis library allows us to do something similar, here it is called `method chaining`.\n",
    "The idea is that a Pandas object has methods for all the small operations we want to perform, and the python language that allows chaining these methods together.\n",
    "\n",
    "Here we demonstrate this by calculating average win percentage by race, and calling this result `perc_win`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_naf\n",
    "    .groupby(['race_name', 'ruleset_name', 'naf_tier'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .sort_values( 'n_games', ascending = False)\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res = res.dropna()\n",
    "\n",
    "\n",
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )\n",
    "\n",
    "(p9.ggplot(data = res, mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(ruleset_name)', color = 'factor(ruleset_name)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI', color = 'factor(naf_tier)'))\n",
    "    + p9.geom_point(colour = \"black\" )\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates NAF BB2020 tournaments\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, even with most tournaments having some form of tiering, there are still teams that win NAF tournaments more often than others. For example, this quote is from the most recent [\"NAF tournament report\"](https://www.thenaf.net/rankings/elo-ranking/tableau/the-naf-report-2/):\n",
    "\n",
    "```\n",
    "Underworld continued to dominate in October, winning the two largest tournaments and maintaining the greater than 60% win ratio.  This is\n",
    "generally due to swarming giving them more players on the pitch and the use of Hakflem and Morg'n'Thorg. (N.b. these are special \"Star Players\" that can be added to teams)\n",
    "```\n",
    "\n",
    "This is exactly what we saw above in the NAF data. At the same time, we see that in the NAF tournaments, **Skaven** (A tier 1 team) win equally often as **Ogres**, a tier 3 team. This could very well be because of the tiering systems being used.\n",
    "\n",
    "However, the best way to learn about the teams relative strength is in the absence of any tiering. Then we can directly interpret the win rates as measuring relative team strength. For this, we turn to online Blood Bowl, and more specific, to **FUMBBL**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blood Bowl online: FUMBBL \n",
    "\n",
    "Blood Bowl can also be played online. A paid version called \"Blood Bowl 2\" with appealing 3D graphics is available on [Steam](https://store.steampowered.com/app/236690/Blood_Bowl_2/). However, a more basic (2D) version is available as [FUMBBL](https://fumbbl.com). It uses a Java client that uploads game results to an online server with an accompanying website that supports the managerial and community aspects of the game (Forming teams, using winnings to buy new players, organizing tournaments, forum discussions etc).\n",
    "The name **FUMBBL** is likely a wordplay on the combination of fumble (losing the ball in American Football) and BBL which stands for Blood Bowl League.\n",
    "\n",
    "The **FUMBBL** website (https://fumbbl.com) is one big pile of data. From coach pages, with their teams, to team rosters, with players, and match histories. It's all there.\n",
    "And the nice thing of **FUMBBL** , for our purpose, is that it has several divisions where all teams start out equal, i.e. there is no tiering system in place.\n",
    "This allows us to learn what the relative team strengths are purely under the GW BB2020 rules.\n",
    "\n",
    "To obtain **FUMBBL** data, we need to fetch it match by match, team by team. To do so, the site creator Christer Kaivo-oja, from Sweden, has made an API that allows us to easily fetch data. What follows is a short demonstration how the API works, before we fetch the **FUMBBL** match and team data of the last 12 months.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behold, the power of Requests / Using Python to fetch FUMBBL data\n",
    "\n",
    "We use the [Python **Requests** library](https://docs.python-requests.org/en/latest/) to make the API call over HTTPS and obtain the response from the FUMBLL server. The response is in the JSON format, a [light-weight data-interchange format](https://www.json.org/json-en.html) which is both easy to read and write for humans, and easy to parse and generate by computers. So this makes it a natural choice for an API.\n",
    "\n",
    "Here is an example of what is available at the coach level (in Blood Bowl, people playing the game are called *coaches*, since the playing pieces are already called the *players*). The full documentation of the API can be found at (https://fumbbl.com/apidoc/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://fumbbl.com/api/coach/teams/gsverhoeven\")\n",
    "# display the complete JSON object {}\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing JSON data\n",
    "\n",
    "Let's have a closer look at the JSON data structure here.\n",
    "We have a list of key-value pairs. \n",
    "Some keys contain simple values, such as `name`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but some return as value a new list of key-value pairs, such as `teams`.\n",
    "Actually this is a \"list of \"lists of key-value pairs\", since we have a separate list for each team.\n",
    "Even the list of a single team contains new structure, for example under the key `raceLogos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['teams'][2]['raceLogos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['teams'][2]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What data do we need? And in what shape?\n",
    "\n",
    "Now we know how the data comes in, we need to think about which variables we want, and how to structure them.\n",
    "The most straightforward level to analyze race strength is to look at **match outcomes**.\n",
    "At its core, the data consists of matches played by teams, commanded by coaches.\n",
    "Furthermore, we expect race strength to change over time, as new strategies are discovered by the players, or new rules get introduced. So the time dimension is important as well.\n",
    "\n",
    "So, let's go with a flat data frame with **rows for each match**, and columns for the various variables associated with each match.\n",
    "These would include:\n",
    "\n",
    "* Coach ids\n",
    "* Team races\n",
    "* Team ids\n",
    "* Date of the match\n",
    "* Outcome (Touchdowns of both teams)\n",
    "\n",
    "With this basic structure, we can add as many match related variables in the future, keeping the basic structure (each row is a match) unchanged.\n",
    "\n",
    "So lets get the match data!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Getting the match data\n",
    "\n",
    "So we are mostly intested in the current ruleset, this is `BB2020`. This ruleset became available in **FUMBBL** at september 1st 2021, and two months later, some 5000 games have been played. We also want to compare with the previous ruleset, where we have much more data available. How far do we go back? \n",
    "Lets start with matches played during the last year. So starting from september 1st, 2020, up to oktober 1st, 2021. \n",
    "This way, we have roughly 12 months of `BB2016` ruleset matches, and one month of `BB2020` matches.\n",
    "\n",
    "The easiest way to collect match data over a particular period of time is to just loop over `match_id`. The most recent match was 4.334.456, and since rougly 100.000 matches are played each year, we can fiddle about and we find match 4.226.550 played on september 1st, 2020.  So that means we need to collect some 110K matches. \n",
    "\n",
    "**VERY IMPORTANT: We do not want to overload the **FUMBBL** server, so we make only three API requests per second. In this way, the server load is hardly affected and it can continue functioning properly for all the Blood Bowl coaches playing their daily games!**\n",
    "\n",
    "To collect 110K matches, we will need 110000*0.333/3600 = 15 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated hours fetching data\n",
    "(4339204-4216257)*0.333/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches = pd.DataFrame(columns=['match_id', 'match_date', 'match_time',  \n",
    "    'team1_id', 'team1_coach_id', 'team1_roster_id', 'team1_race_name', 'team1_value',\n",
    "    'team2_id', 'team2_coach_id', 'team2_roster_id', 'team2_race_name', 'team2_value',\n",
    "    'team1_score', 'team2_score'])\n",
    "\n",
    "target = 'data/df_matches_' + time.strftime(\"%Y%m%d_%H%M%S\") + '.h5'\n",
    "print(target)\n",
    "\n",
    "end_match = 4339204\t\n",
    "begin_match = 4216257 \n",
    "n_matches = end_match - begin_match\n",
    "full_run = 0\n",
    "print(n_matches)\n",
    "\n",
    "if(full_run):\n",
    "    for i in range(n_matches):\n",
    "        api_string = \"https://fumbbl.com/api/match/get/\" + str(end_match - i)\n",
    "        # wait 0.5 s on average between each API call\n",
    "        wait_time = (random.uniform(0.5, 1) + 0.25)/3\n",
    "        time.sleep(wait_time)\n",
    "        match = requests.get(api_string)\n",
    "        match = match.json()\n",
    "        if match: # fix for matches that do not exist\n",
    "            match_id = match['id']\n",
    "            match_date = match['date']\n",
    "            match_time = match['time']\n",
    "            team1_id = match['team1']['id']\n",
    "            team2_id = match['team2']['id']\n",
    "            team1_score = match['team1']['score']\n",
    "            team2_score = match['team2']['score']  \n",
    "            team1_roster_id = match['team1']['roster']['id']\n",
    "            team2_roster_id = match['team2']['roster']['id']            \n",
    "            team1_coach_id = match['team1']['coach']['id']\n",
    "            team2_coach_id = match['team2']['coach']['id']\n",
    "            team1_race_name = match['team1']['roster']['name'] \n",
    "            team2_race_name = match['team2']['roster']['name'] \n",
    "            team1_value = match['team1']['teamValue']\n",
    "            team2_value = match['team2']['teamValue']\n",
    "            #print(match_id)     \n",
    "            df_matches.loc[i] = [match_id, match_date, match_time, \n",
    "                team1_id, team1_coach_id, team1_roster_id, team1_race_name, team1_value,\n",
    "                team2_id, team2_coach_id, team2_roster_id, team2_race_name, team2_value,\n",
    "                team1_score, team2_score]\n",
    "        else:\n",
    "            # empty data for this match, create empty row\n",
    "            match_id = int(end_match - i)\n",
    "            df_matches.loc[i] = [np.NaN, np.NaN, np.NaN, \n",
    "            np.NaN,np.NaN,np.NaN,np.NaN,\n",
    "            np.NaN,np.NaN,np.NaN,np.NaN,\n",
    "            np.NaN,np.NaN, np.NaN, np.NaN] # try np.repeat([np.NaN], 13, axis=0) next time\n",
    "            df_matches.loc[i]['match_id'] = int(match_id)\n",
    "        if i % 100 == 0: \n",
    "            # write tmp data as hdf5 file\n",
    "            print(i, end='')\n",
    "            print(\".\", end='')\n",
    "            df_matches.to_hdf(target, key='df_matches', mode='w')\n",
    "\n",
    "    # write data as hdf5 file\n",
    "    df_matches.to_hdf(target, key='df_matches', mode='w')\n",
    "else:\n",
    "    # read from hdf5 file\n",
    "    #df_matches = pd.read_hdf('data/df_matches_20211102_083311.h5')\n",
    "    df_matches = pd.read_hdf('data/df_matches_20211106_205843.h5')\n",
    "#\n",
    "df_matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert object dtype columns to proper pandas dtypes datetime and numeric\n",
    "df_matches['match_date'] = pd.to_datetime(df_matches.match_date) # Datetime object\n",
    "df_matches['match_id'] = pd.to_numeric(df_matches.match_id) \n",
    "df_matches['team1_id'] = pd.to_numeric(df_matches.team1_id) \n",
    "df_matches['team1_coach_id'] = pd.to_numeric(df_matches.team1_coach_id) \n",
    "df_matches['team1_roster_id'] = pd.to_numeric(df_matches.team1_roster_id) \n",
    "df_matches['team2_id'] = pd.to_numeric(df_matches.team2_id) \n",
    "df_matches['team2_coach_id'] = pd.to_numeric(df_matches.team2_coach_id) \n",
    "df_matches['team2_roster_id'] = pd.to_numeric(df_matches.team2_roster_id) \n",
    "df_matches['team1_score'] = pd.to_numeric(df_matches.team1_score) \n",
    "df_matches['team2_score'] = pd.to_numeric(df_matches.team2_score) \n",
    "\n",
    "# calculate match score difference\n",
    "df_matches['team1_win'] = np.sign(df_matches['team1_score'] - df_matches['team2_score'])\n",
    "df_matches['team2_win'] = np.sign(df_matches['team2_score'] - df_matches['team1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 123K matches\n",
    "df_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First analysis: Orcs are most popular!\n",
    "\n",
    "Which races are the most popular on FUMBLL in the last year?\n",
    "For this, we need only to count which races were chosen how many times.\n",
    "\n",
    "However, since each match contains two teams, we need to create a new dataframe `df_races`, double in size, that contains for each row the `match_id` and `team_race` of one of the two teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team1_races = df_matches[['match_id', 'team1_race_name']]\n",
    "team2_races = df_matches[['match_id', 'team2_race_name']]\n",
    "\n",
    "# make column names equal\n",
    "team1_races.columns = team2_races.columns = ['match_id', 'race_name']\n",
    "\n",
    "# row bind the two dataframes\n",
    "df_races = pd.concat([team1_races, team2_races])\n",
    "\n",
    "# aggregate by race_name\n",
    "res = (df_races\n",
    "        .groupby(['race_name'])\n",
    "        .size()\n",
    "        .reset_index(name='n_games')\n",
    ")\n",
    "\n",
    "# select most popular races for filtering\n",
    "top_races = res.loc[(res.n_games > 1000)]['race_name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res.loc[res['race_name'].isin(top_races)], mapping = p9.aes(x = 'reorder(race_name, n_games)', y = 'n_games'))\n",
    "    + p9.geom_point(colour = 'gray') \n",
    "    + p9.coord_flip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the orcs are most popular! \n",
    "\n",
    "# dataprep: df_wins prepare for raw win rates by race\n",
    "\n",
    "If we want to calculate a win rate for each race, we need to decide what to do with draws.\n",
    "I've never given the matter much thought, but it turns out other people have!\n",
    "For example, in football, there is a popular weighting scheme where wins are given 3 points, draws 1 point and losses 0 points.\n",
    "This is called [three points for a win](https://en.wikipedia.org/wiki/Three_points_for_a_win) . \n",
    "In Blood bowl leagues and tournaments, my impression is that this rule is used often as well.\n",
    "If we want to predict which teams perform best in these settings (have the highest probability of winning a tournament), we need to weigh the match outcomes accordingly.\n",
    "However, in Blood Bowl, it seems that a 2:1:0 (W / D / L) weighting scheme is most commonly used. \n",
    "For example, Mike Davies from the NAF calculates win rate by weighting each win as 1 point, and each draw as 0.5 points (For example, [here](https://public.tableau.com/app/profile/mike.sann0638.davies/viz/NAFGames_0/SuccessBB2020)).\n",
    "So if we want to compare with others, it makes sense to adapt this scheme as well.\n",
    "This scheme has the advantage that the weighted average win percentage over all matches is always 50%, creating a nice reference point.\n",
    "\n",
    "\n",
    "This creates again a dataframe that is double in size, `df_wins` because each match generates two rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make two copies, one for each team in the match\n",
    "team1_wins = df_matches[['match_id', 'match_date', 'team1_id', 'team1_race_name', 'team1_value', 'team1_win']].copy()\n",
    "team2_wins = df_matches[['match_id', 'match_date',  'team2_id', 'team2_race_name', 'team2_value', 'team2_win']].copy()\n",
    "\n",
    "team1_wins.columns = team2_wins.columns = ['match_id', 'match_date', 'team_id', 'race_name', 'team_value', 'wins']\n",
    "\n",
    "# combine both dataframes\n",
    "df_wins = pd.concat([team1_wins, team2_wins])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a dataset on the match-team level, lets prep the data a bit further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.loc[df_wins['wins'] == 0, 'wins'] = 0.5\n",
    "df_wins.loc[df_wins['wins'] == -1, 'wins'] = 0\n",
    "\n",
    "# convert to float\n",
    "df_wins['wins'] = df_wins['wins'].astype(float)\n",
    "\n",
    "# convert team value 1100k to 1100 integer and and above / below median (= low / high TV)\n",
    "df_wins['team_value'] = df_wins['team_value'].str.replace('k$', '')\n",
    "df_wins['team_value'] = df_wins['team_value'].fillna(0).astype(np.int64)\n",
    "\n",
    "df_wins['tv_bin'] = pd.cut(df_wins['team_value'], [0, 850, 1150,1450, 1750, float(\"inf\")], labels=['< 850', '1K', '1.3K', '1.6K', '> 1750'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets have a look at our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.query('team_value > 1000 & team_value < 1020')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Almost there. There is still something missing though, we need to know, for all the teams in our matches dataset, in what division or league they are playing, and what version of the rules they use. For these we turn to the API again, to fetch more data.\n",
    "\n",
    "# Step 2: Fetch data on team division and ruleset\n",
    "\n",
    "Let grab for all teams in `df_matches` the team **race** and **ruleset**.\n",
    "There are around 25 \"official\" races / different teams, such as orcs, elves, humans etc.\n",
    "Each race has different player types, with different strength, abilities, skills, etc.\n",
    "\n",
    "A limitation of the API is that it shows the current status of the teams and leagues.  For example, leagues that change their rules, as the NAF who for their latest tournament switched to the new BB2020 ruleset in september 2021, but matches played earlier under this ruleset were played using BB2016 rules. \n",
    "So we have to use external information to interpret this data properly.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of all teams that need to be fetched\n",
    "team_ids = list(df_wins['team_id'].dropna())\n",
    "\n",
    "# get unique values by converting to a Python set and back to list\n",
    "team_ids = list(set(team_ids))\n",
    "\n",
    "len(team_ids)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have to fetch data for 43K different teams. We use the same approach as above, looping over all team_ids and making a separate API call for each team.\n",
    "\n",
    "**IMPORTANT: here too, we limit ourselves to 3 API calls per second to avoid overloading the FUMBBL server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = pd.DataFrame(columns=['team_id', 'division_id', 'division_name',  'league' ,\n",
    "    'ruleset', 'roster_id', 'race_name',  'games_played'])\n",
    "\n",
    "target = 'data/df_teams_' + time.strftime(\"%Y%m%d_%H%M%S\") + '.h5'\n",
    "print(target)\n",
    "\n",
    "fullrun = 0\n",
    "\n",
    "if fullrun:\n",
    "    print('fetching team data for ', len(team_ids), ' teams')\n",
    "    for t in range(len(team_ids)):    \n",
    "        api_string = \"https://fumbbl.com/api/team/get/\" + str(int(team_ids[t]))\n",
    "        wait_time = (random.uniform(0.5, 1) + 0.25)/3\n",
    "        time.sleep(wait_time)\n",
    "        team = requests.get(api_string)\n",
    "        team = team.json()\n",
    "        # grab fields\n",
    "        team_id = team['id']\n",
    "        division_id = team['divisionId']\n",
    "        division_name = team['division']\n",
    "        ruleset = team['ruleset']\n",
    "        league = team['league']\n",
    "        roster_id = team['roster']['id']\n",
    "        race_name = team['roster']['name']\n",
    "        games_played = team['record']['games']\n",
    "        # add to dataframe\n",
    "        df_teams.loc[t] = [team_id, division_id, division_name, league, ruleset, roster_id, race_name, games_played]\n",
    "        if t % 100 == 0: \n",
    "            # write tmp data as hdf5 file\n",
    "            print(t, end='')\n",
    "            print(\".\", end='')\n",
    "            df_teams.to_hdf(target, key='df_teams', mode='w')\n",
    "    \n",
    "    df_teams.to_hdf(target, key='df_teams', mode='w')\n",
    "else:\n",
    "    # read from hdf5 file\n",
    "    df_teams = pd.read_hdf('data/df_teams_20211030_115137.h5')\n",
    "\n",
    "\n",
    "df_teams['roster_name'] = df_teams['roster_id'].astype(str) + '_' + df_teams['race_name']\n",
    "\n",
    "df_teams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PM make this an external code list\n",
    "\n",
    "# Splitting out a few particular leagues\n",
    "df_teams.loc[(df_teams['league'] == 0) & (df_teams['ruleset'] == 6), 'division_name'] = 'Regular_league'\n",
    "df_teams.loc[(df_teams['league'] == 9298), 'division_name'] = 'NAF'\n",
    "df_teams.loc[(df_teams['league'] == 10263), 'division_name'] = 'Secret League'\n",
    "df_teams.loc[(df_teams['league'] == 10455), 'division_name'] = 'CIBBL'\n",
    "df_teams.loc[(df_teams['league'] == 14713), 'division_name'] = 'Test Open League BB2020'\n",
    "df_teams.loc[(df_teams['ruleset'] == 888), 'division_name'] = 'LegaGladio'\n",
    "df_teams.loc[(df_teams['ruleset'] == 1049), 'division_name'] = 'NAF 7s'\n",
    "\n",
    "# add column ruleset_name\n",
    "df_teams['ruleset_name'] = 'bb2016'\n",
    "df_teams['ruleset_name'] = 'bb2016'\n",
    "df_teams.loc[df_teams['ruleset'] == 4, 'ruleset_name'] = 'bb2020'\n",
    "df_teams.loc[df_teams['ruleset'] == 2198, 'ruleset_name'] = 'bb2020'\n",
    "df_teams.loc[df_teams['ruleset'] == 2198, 'division_name'] = 'SL BB2020'\n",
    "df_teams.loc[df_teams['division_name'] == 'NAF', 'ruleset_name'] = 'mixed'\n",
    "df_teams.loc[df_teams['division_name'] == 'LegaGladio', 'ruleset_name'] = 'mixed'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUMBBL divisions and rulesets\n",
    "\n",
    "FUMBBL allows coaches to create their own rulesets to play their own leagues and tournaments with. For example, there is a so-called \"Secret League\" where coaches can play with \"Ninja halflings\", of with \"Ethereal\" spirits etc. \n",
    "\n",
    "Since we want the team strength for the official rulesets BB2016 and BB2020, we need to drop the matches that are played under different rules.\n",
    "\n",
    "Lets have look at the various divisions and leagues, which rulesets are used, and which races are played how often.\n",
    "We only look at divisions and leagues with a sufficient volume of matches, or otherwise we do not have sufficient statistics for each race.\n",
    "This gives us 33K teams of 43K, so roughly 75% of all teams created last year."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter on most common rulesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_teams\n",
    "    .groupby(['ruleset',  'league', 'division_id', 'division_name', 'ruleset_name'])\n",
    "    .agg( n_teams = ('ruleset', 'count')\n",
    "    )\n",
    "    .sort_values('n_teams', ascending = False)\n",
    "    .query('n_teams > 150')['n_teams']\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between ruleset 1 and 6: no expensive mistakes and wizards inducements and 5 cards. And few different teams.\n",
    "\n",
    "\n",
    "* Ruleset 6: League (Also BB2016 with Simyin (monkeys) / Bretonnian / Slann / Khorne)\n",
    "* Ruleset 2228: NAF-BB2020 (switched during 2021 from BB2016 to BB2020)\n",
    "\n",
    "PM write post suggesting change to freeze rulesets as soons as matches have been played with them.\n",
    "And force users to create new rulesets if they want to update / change previous rulesets.\n",
    "\n",
    "\n",
    "\n",
    "* Ruleset 303: United Open Rules (BB2016, used by the Secret League, it allows a lot of extra teams like Ethereal)\n",
    "* Ruleset 888: LegaGladio (Italians, likely also switched from BB2016 to BB2020)\n",
    "* Ruleset 2198: Secret League 2020, SL did it proper and created a new ruleset for BB2020\n",
    "\n",
    "\n",
    "There are a lot of small leagues being played on FUMBBL. Reasons to play in small local leagues vary.\n",
    "\n",
    "There are a few larger leagues, that have nation wide scale. \n",
    "\n",
    "There are two leagues that are international and have sufficient scale to analyse separately.\n",
    "\n",
    "This is the NAF tournaments (league 9298), and the Secret League (10263).\n",
    "\n",
    "## NAF Tournaments: What is with ruleset 2228\n",
    "\n",
    "Ruleset 2228 appears to be BB2020 + slann + khorne, which the NAF prefers over the GW BB2020 ruleset.\n",
    "From the roster ids, we can see that only from oktober 2021, the NAF switched to BB2020 teams.\n",
    "\n",
    "Checked by christer: Does this mean that the API only serves the most recent version of a ruleset, and that rulesets can be changed without requiring a new ruleset id to be created? Correct\n",
    "\n",
    "They seem to be small scale, but consistent 6 week duration events? lets look up a few matches on FUMBBL.\n",
    "\n",
    "match 4274272 is within a tournament called SteelBowl 2021 [EU]\n",
    "The tournament has start /end dates 24 jan 2021. The match was at 29 jan.\n",
    "\n",
    "The match was a league division game, the team played 6 games in jan/feb/march.\n",
    "The League is called Online NAF tournaments.\n",
    "ACtually this is a group 9298 that contains tournaments.\n",
    "The group uses ruleset 2228.\n",
    "\n",
    "https://fumbbl.com/p/ruleset?id=2228\n",
    "\n",
    "Skills are awarded prior to games according to a predetermined list, THAT USES TIERS.\n",
    "\n",
    "\n",
    "**An important feature of this league is that a tier system has been implemented**\n",
    "This makes match outcomes in this league less comparable to other divisions on FUMBBL.\n",
    "\n",
    "BUT: Make sure your custom ruleset is set to Predetermined skill progression.\n",
    "\n",
    "\n",
    "\n",
    "# So final groupings\n",
    "\n",
    "* Competitive BB2020\n",
    "\n",
    "VERSUS\n",
    "\n",
    "* Ranked BB2016\n",
    "* Black box BB2016\n",
    "* standard BB2016 League division (ruleset 6 / league 0)\n",
    "\n",
    "First we check if we can pool these three groups.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep: Merging the match data with the team / ruleset data and team tiers\n",
    "\n",
    "For each match in the `df_wins` **DataFrame** we can now add the team-level information from `df_teams`.\n",
    "We also add the team tiers we used for the NAF dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins = pd.merge(df_wins.drop('race_name', 1), df_teams, on='team_id', how='left')\n",
    "\n",
    "# 66 empty matches: we drop these\n",
    "#df_wins.query('match_date != match_date')\n",
    "\n",
    "df_wins = df_wins.dropna(subset=['match_date'])\n",
    "\n",
    "# add bb2020 tiers\n",
    "df_wins = pd.merge(df_wins, race_tiers, on='race_name', how='left')\n",
    "\n",
    "df_wins['team_id'] = pd.to_numeric(df_wins.team_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep: getting the time right\n",
    "\n",
    "To see time trends, its useful to aggregate the data by week. For this we add a week number for each date, and from this week number, we convert back to a date to get a week_date. This last part is useful for plotting with `plotnine`, as this treats dates in a special way (PM how)\n",
    "We use the ISO definition of week, this has some unexpected behavior near the beginning / end of each year. \n",
    "\n",
    "The data starts in week x of 2020, and stops halfway week 44 in 2021. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins['week_number'] = df_wins['match_date'].dt.isocalendar().week\n",
    "\n",
    "\n",
    "# cannot convert to np int64 becaues of missing values\n",
    "# cannot convert to 'int64'-dtype NumPy array with missing values. Specify an appropriate 'na_value' for this dtype.\n",
    "df_wins['week_number'] = df_wins['week_number'].astype('Int64')\n",
    "#df_wins['week_number'] = df_wins['week_number'].fillna(0).astype(np.int64)\n",
    "\n",
    "# add year based on match dat\n",
    "df_wins['year'] = pd.DatetimeIndex(df_wins['match_date']).year\n",
    "\n",
    "# fix year for  ISO week 53 weeks jan 2021\n",
    "df_wins.loc[(df_wins['year'] == 2021) & (df_wins['week_number'] == 53), 'year'] = 2020\n",
    "\n",
    "df_wins['week_year'] = df_wins['year'].astype(str) + '-' + df_wins['week_number'].astype(str)\n",
    "\n",
    "df_wins['week_date'] = pd.to_datetime(df_wins['week_year'].astype(\"string\") + '-1', format = \"%Y-%U-%w\")\n",
    "\n",
    "# manual fix of week date (grrrr)\n",
    "df_wins.loc[(df_wins['week_date'] ==  '2021-01-04') & (df_wins['week_number'] == 53), 'week_date'] = pd.to_datetime('2020-12-31')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Time series of number of games\n",
    "\n",
    "Now that we have a date variable for each week, `week_date`, we can use plotnine to plot a nice timer series graph of the total number of games played each week.\n",
    "The introduction of the new **Competitive** league with BB2020 rules is marked by a vertical red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins\n",
    "    .loc[(df_wins['week_date'] >= '2020-09-01' ) & (df_wins['week_date'] < '2021-10-25')]\n",
    "    .groupby(['week_date', 'week_number'])\n",
    "    .agg(        \n",
    "        n_games = ('race_name', \"count\") \n",
    "    )\n",
    "\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res['n_games'] = res['n_games']/2 # each games creates two rows in df_wins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res, mapping = p9.aes(x = 'week_date', y = 'n_games', group = '1'))\n",
    "    + p9.geom_point() \n",
    "    + p9.geom_line()\n",
    "    + p9.expand_limits(y=[0,2000])\n",
    "    + p9.geom_vline(xintercept = '2021-09-01', color = \"red\")\n",
    "    + p9.ggtitle(\"Total FUMBBL games played in the last year\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a check on our work, we compare with the plots that FUMBBL itself provides at https://fumbbl.com/p/stats.\n",
    "\n",
    "Comparing with the 30-week Statistics plot on the FUMMBBL we can conclude that our dataset for sept 2020/ okt 2021 is complete!\n",
    "The effect of starting the new BB2020 division is also clearly visible, with the number of games played each week almost doubling.\n",
    "\n",
    "Not visible on this plot, but clearly visible on the FUMBBL website, is the effect of COVID-19 on online gaming volume.\n",
    "Starting in march 2020, online gaming activity saw a huge surge. Tabletop leagues switched to online etc. \n",
    "\n",
    "What this plot does show is that the COVID-19 effect was declining in 2021, with game volume in july 2021 falling below july 2019 (pre-corona) levels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Games per week by division\n",
    "\n",
    "The games on FUMBBL are played within several divisions. Lets do a breakdown by division:\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins\n",
    "    .loc[(df_wins['week_date'] >= '2020-09-01' ) & (df_wins['week_date'] < '2021-10-25')]\n",
    "    .groupby(['division_name', 'week_date', 'year'])\n",
    "    .agg(        \n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res['n_games'] = res['n_games']/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res.query(\"division_name != 'FFB Test'\"), mapping = p9.aes(x = 'week_date', y = 'n_games', \n",
    "group = 'factor(division_name)', color = 'factor(division_name)'))\n",
    "    + p9.geom_point() \n",
    "    + p9.geom_line()\n",
    "    + p9.expand_limits(y=[0,2000])\n",
    "    + p9.ggtitle(\"FUMBBL games played in the last year\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is interesting to compare the *Black box* division with the *League* division."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: win rate Blackbox vs Ranked vs League division\n",
    "\n",
    "Now in the end, we want to compare BB2016 with BB2020. But as we can see above, there are various BB2016 divisions.\n",
    "Can we just pool them? Or are there differences that are important for our comparison?\n",
    "\n",
    "Lets first check out the BB2016 divisions.\n",
    "\n",
    "Does it matter if coaches both need to agree for a match as in the `Ranked` division? \n",
    "For the BB2016 rules, we have data for both divisions, one in which coaches can choose their opponent, and one for which they are randomly matched to other teams. \n",
    "\n",
    "First, compare Team value distributions between the two divisions, to see what exactly we are comparing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2016_divisions = ['Ranked', 'Regular_league', 'Blackbox']\n",
    "\n",
    "(p9.ggplot(data = df_wins[df_wins['division_name'].isin(bb2016_divisions)], mapping = p9.aes(x = 'reorder(division_name, team_value)', y = 'team_value', \n",
    "group = 'factor(division_name)', color = 'factor(division_name)'))\n",
    "    + p9.geom_boxplot()\n",
    "    #+ p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 1100)\n",
    "    + p9.ggtitle(\"Team value distributions\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, regular league (tournaments) have much lower team value, with a median slightly above 1100, often used for tournaments.\n",
    "This makes sense, as people tend to play longer with teams outside of leagues / tournaments, which force redrafts and / or are limited in duration.\n",
    "So, we have to look within TV bins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bb2016_divisions = ['Ranked', 'Regular_league']\n",
    "bb2016_divisions = ['Ranked', 'Blackbox', 'Regular_league']\n",
    "\n",
    "tv_bins = ['1K', '1.3K', '1.6K']\n",
    "\n",
    "res = (df_wins[df_wins['division_name'].isin(bb2016_divisions)]\n",
    "    .loc[df_wins['tv_bin'].isin(tv_bins)]\n",
    "    .groupby(['division_name', 'ruleset_name', 'race_name', 'tv_bin'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .sort_values( 'n_games', ascending = False)\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res = res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Function for computing confidence intervals\n",
    "from statsmodels.stats.proportion import proportion_confint   \n",
    "\n",
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(p9.ggplot(data = res.query('n_games > 10 & tv_bin == \"1K\"'), mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(division_name)', color = 'factor(division_name)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI'))\n",
    "    + p9.geom_point(shape = '|', size = 5) # color = 'black', \n",
    "    + p9.facet_wrap('tv_bin')\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates Ranked vs Regular league\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.query('tv_bin == \"1K\" & division_name == \"Regular_league\" & race_name == \"Amazon\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we compare Ranked vs regular league **within Team value bins**, no clear substantial differences appear.\n",
    "This suggests we can pool both leagues and compare both to the Competitive BB2020 match results.\n",
    "As long as we use team value bins, like \"Taureau Amiral\".\n",
    "\n",
    "\n",
    "*Conclusions for Ranked vs Black box*\n",
    "For the lower tier teams Ogre, Halfling and Goblin, clear differences can be seen between Ranked and Blackbox. Black box performance is lower.\n",
    "This suggests that we see the effect of strategically avoiding certain opponents, which is not possible in Blackbox. \n",
    "\n",
    "This argument could also explain the lower performance of Amazon at higher TV, which are known to perform better at low TV.\n",
    "For Chaos Chosen, we see a pattern that could be explained if players in Ranked strategically choose their opponents to skill up the team, which is known to only become competitive at higher team value.\n",
    "\n",
    "This gives some strength to the argument that the Competitive Division is not a **truly** competitive division, since players can choose their opponents, which is not possible at tournaments, and at random matching environments such as Blackbox was.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main analysis: win rate BB2016 vs BB2020\n",
    "\n",
    "If we want two summary statistics instead of one, we need to use the `agg()` method.\n",
    "Furthermore, if we want the variable we group over as a regular column in the DataFrame, we need to use `reset_index()`.\n",
    "Now we have the data ready to make a nice plot.\n",
    "\n",
    "We are going to do the comparison for the main divisions that use BB2016 and BB2020 rules.\n",
    "The BB2016 rules are in three divisions: Blackbox, Ranked and regular league."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins\n",
    "    .groupby(['division_name', 'ruleset', 'league'])\n",
    "    .agg(        \n",
    "        #perc_win = ('wins', \"mean\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .sort_values( 'n_games', ascending = False)\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res['n_games'] = res['n_games']/2\n",
    "\n",
    "main_divisions = res.query('n_games > 6000')['division_name']\n",
    "\n",
    "main_divisions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins[df_wins['division_name'].isin(main_divisions)]\n",
    "    #.query('team_value > 800 & team_value < 2500')\n",
    "    .groupby(['race_name', 'ruleset_name', 'naf_tier', 'tv_bin'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .query('n_games > 0')\n",
    "    .reset_index()) # this adds the group by variable (now index) as a column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding credible intervals for the win rates\n",
    "\n",
    "Comparing the win rates of BB2016 and BB2020 to koadah's dataset on http://fumbbldata.azurewebsites.net/stats.html , we find strong agreement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Function for computing confidence intervals\n",
    "from statsmodels.stats.proportion import proportion_confint   \n",
    "\n",
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(p9.ggplot(data = res.query('n_games > 10 & tv_bin == \"1K\" '), mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(ruleset_name)', color = 'factor(ruleset_name)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI'))\n",
    "    + p9.geom_point(p9.aes(color = 'factor(naf_tier)') )\n",
    "    + p9.facet_wrap('tv_bin')\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates by ruleset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Tier 1, Amazons and Orcs improved substantially. \n",
    "Surprisingly, Underworld denizens are now among the strongest teams around, de\n",
    "\n",
    "In Tier 3, Halflings and goblins also improved. \n",
    "\n",
    "Humans a bit. https://bbtactics.com/bb2020-human-starting-rosters/ Do ppl use halflings with ogres? It appears they do.\n",
    "\n",
    "Old World Alliance got substantially worse. \n",
    "Nurgle slightly worse, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(p9.ggplot(data = res.query('n_games > 10 & tv_bin == \"1.3K\" '), mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(ruleset_name)', color = 'factor(ruleset_name)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI'))\n",
    "    + p9.geom_point(p9.aes(color = 'factor(naf_tier)') )\n",
    "    + p9.facet_wrap('tv_bin')\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates by ruleset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n",
    "\n",
    "\n",
    "Both new teams introduced in BB2020, Imperial nobility and Black orcs, are not the strongest teams around with win rates that are below average.\n",
    "Slann and daemons of Khorne had no official rules from GW yet, so are not included in the Competitive division that uses BB2020 rules.\n",
    "Bretonnians have been replaced by Imperial Nobility.\n",
    "\n",
    "Clearly, the BB2020 results mostly apply to low team value (around 1K +/- 150), as there is too little data on FUMBBL yet at higher team values, because skilling up takes time.\n",
    "The only clear changes at medium team value (around 1.3K +/-150) are improvements for Goblins and for Underworld Denizens.\n",
    "\n",
    "Others have come to similar conclusions, for example [this](https://bbtactics.com/tournament-skill-stacking/)  \n",
    "\n",
    "And check out this ruleset\n",
    "Project all teams viable\n",
    "The idea behind this ruleset is to make all teams competitive - while trying to maintain balance.\n",
    "\n",
    "https://bloodbowl.dk/onewebmedia/All_Teams_Viable_Ruleset.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.query('race_name == \"Human\" & ruleset_name == \"bb2020\" & wins == 1 & team_value < 1150')['team_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus analysis: is there a learning effect of the BB2020 rules\n",
    "\n",
    "Answer: no not really. PM do this only for TV 1K bin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate by year and week number\n",
    "\n",
    "res = (df_wins.query('division_name == \"Competitive\"')\n",
    "    .groupby(['week_number', 'year', 'ruleset', 'race_name'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res\n",
    "\n",
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )\n",
    "\n",
    "(p9.ggplot(data = res.query('year > 2020 & week_number > 36 & week_number < 43'), \n",
    "    mapping = p9.aes(x = 'week_number', y = 'perc_win', group = 'factor(race_name)', color = 'factor(race_name)'))\n",
    "    + p9.geom_point(p9.aes(size = 'n_games')) \n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI'))\n",
    "    + p9.geom_line()\n",
    "    + p9.scale_size_area() \n",
    "    + p9.facet_wrap('race_name')\n",
    "    + p9.ggtitle(\"FUMBBL BB2020 win rates by race and week_nr\")\n",
    "    + p9.theme(figure_size=(16, 8)) \n",
    "    + p9.theme(legend_position='none'))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50276fd1884268afe39607052f22ef19b84d915691d702a5c7e9a67a09867105"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('requests_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
