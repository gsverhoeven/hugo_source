{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing online Blood Bowl matches using Python: API scraping, pandas and plotnine\n",
    "\n",
    "When I was a teenager, back in 1994, I bought the Blood Bowl strategy boardgame. Its like chess, but instead of two medieval kingdoms fighting, the game is about fantasy football, say Tolkien meets rugby. Already back then, the game appealed to me because it combined the Warhammer playing pieces I liked so much (e.g. models of Orcs, Elves, Dwarves etc) with a game that had simple rules (compared to the main wargaming systems at the time, Warhammer Fantasy Battle, and Warhammer 40K), but resulted in complex gameplay. Blood bowl requires a lot of skill to play well, with complex strategic decision making in the face of uncertainty (heavy dice rolling involved). Then, after painting half of the figures, I moved on to new exciting things. But throughout the years, this was the only game I kept moving to new places etc.\n",
    "To my surprise, when I regained interest a few years ago, an international gaming community had formed around the game, with a players' association, the NAF, with thousands of members, a World championship every two years, and with new editions and models being released on a regular basis.\n",
    "\n",
    "So last year, I finally decided to pick it up again, painted the remaining figures (see photo below for the end result) and started my search for actual opponents to play against. I found a local community in a city nearby, and I am having a great time learning the strategic finesses of the all the teams, painting new miniatures, and looking forward to my first tabletop tournament, to be held in a few months if the dreaded Nurgle rot (aka Corona) allows it.\n",
    "\n",
    "Of course, you want to see a photo of my painted team right? (It appears i am not the only one who has this urge, there are special Reddit and Facebook groups where you can showcase your painted Blood Bowl team).\n",
    "\n",
    "Now, Another amazing thing happened while I was away: Blood Bowl went online, with people playing games using a (free!) client-server system called FUMBBL, that came into existence at around 2003. As with all sports (and yes, Blood Bowl is a sport, like Chess and Go), statistics are not far away. The website (https://fumbbl.com) is one big pile of data. From coach pages, with their teams, to team rosters, with players, and match histories. It's all there. And what's more: the site creator Christer Kaivo-oja, from Sweden, has made an API that allows us to easily fetch data. The full documentation of the API can be found at (https://fumbbl.com/apidoc/). \n",
    "\n",
    "The goal of this blog post is to use Python API scraping to fetch the data, and to use the pandas and plotnine packages to analyse and visualise the data.\n",
    "\n",
    "We do three analyses:\n",
    "\n",
    "* Which races are most popular?\n",
    "* Ploting the number of games per week over time for each division\n",
    "* Plotting the average win rate for each team race\n",
    "* Comparing that win rate between the old and new rules to see what changed\n",
    "\n",
    "Along the way we discover what it is possible. A big limitation of the API is that it shows the current status of the teams and leagues.\n",
    "This means for example, that for matches played in the past, team value is no longer available. Also, leagues that change their rules, for example the NAF switched to the new ruleset (including Khorne and Slann) in september 2021, but matches played earlier under this ruleset were played  using BB2016 rules.\n",
    "\n",
    "PM Questions we answer (races, ruleset) and why"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behold, the power of Requests / Using Python to fetch FUMBBL data\n",
    "\n",
    "We use the [Python **Requests** library](https://docs.python-requests.org/en/latest/) to make the API call over HTTPS and obtain the response from the FUMBLL server. The response is in the JSON format, a [light-weight data-interchange format](https://www.json.org/json-en.html) which is both easy to read and write for humans, and easy to parse and generate by computers. So this makes it a natural choice for an API.\n",
    "\n",
    "Here is an example of what is available at the coach level (in Blood Bowl, people playing the game are called *coaches*, since the playing pieces are already called the *players*). A complete overview of what available in the FUMBBL API is here []()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import random\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "response = requests.get(\"https://fumbbl.com/api/coach/teams/gsverhoeven\")\n",
    "# display the complete JSON object {}\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing JSON data\n",
    "\n",
    "Let's have a close look at the JSON data structure here.\n",
    "We have a list of key-value pairs. \n",
    "Some keys contain simple values, such as `name`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but some return as value a new list of key-value pairs, such as `teams`.\n",
    "Actually this is a list of lists of key-value pairs, since we have a separate list for each team.\n",
    "Even the list of a single team contains new structure, for example under the key `raceLogos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['teams'][2]['raceLogos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['teams'][2]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting the data in a Pandas dataframe for analysis\n",
    "\n",
    "Now we know how the data comes in, we need to think about how we want it.\n",
    "\n",
    "Now what would be a logical data structure to analyse race strength?\n",
    "\n",
    "The most straightforward level to analyze race strength is to look at **match outcomes**.\n",
    "Furthermore, we expect race strength to change over time, as new strategies are discovered by the players, or new rules get introduced. So the time dimension is important as well.\n",
    "\n",
    "For now, we go with a flat data frame with **rows for each match**, and columns for the various variables associated with each match.\n",
    "These would include:\n",
    "\n",
    "* Coach ids\n",
    "* Races\n",
    "* Team ids\n",
    "* Date of the match\n",
    "* Outcome (Touchdowns of both teams)\n",
    "\n",
    "With this basic structure, we can add as many match related variables in the future, keeping the basic structure (each row is a match) unchanged.\n",
    "\n",
    "So lets get the match data!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Getting the match data\n",
    "\n",
    "So we are mostly intested in the current ruleset, this is `BB2020`. This ruleset became available last month, and some 5000 games have been played since.\n",
    "We also want to compare with the previous ruleset, where we have much more data available. How far do we go back? \n",
    "Lets start with matches played during the last year. So starting from september 1st, 2020, up to oktober 1st, 2021. \n",
    "This way, we have roughly 12 months of `BB2016` ruleset matches, and one month of `BB2020` matches.\n",
    "\n",
    "Easiest way to fetch them appears to just loop over `match_id`. The most recent match was 4.334.456, and since rougly 100.000 matches are played each year, we can fiddle about and we find match 4.226.550 played on september 1st, 2020.  So that means we need to collect some 110K matches. \n",
    "We do not want to overload the server, so let's make two API requests per second. To collect 110K matches, we will need 110000*0.5/3600 = 15 hours.\n",
    "We can manage this by two nightly runs of 8 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated hours fetching data\n",
    "110000*0.5/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "df_matches_final = pd.DataFrame(columns=['match_id', 'match_date', 'match_time',  \n",
    "    'team1_id', 'team1_coach_id', 'team1_roster_id', 'team1_race_name', 'team1_value',\n",
    "    'team2_id', 'team2_coach_id', 'team2_roster_id', 'team2_race_name', 'team2_value',\n",
    "    'team1_score', 'team2_score'])\n",
    "\n",
    "target = 'data/df_matches_' + time.strftime(\"%Y%m%d_%H%M%S\") + '.h5'\n",
    "print(target)\n",
    "\n",
    "end_match = 4339204\t\n",
    "begin_match = 4216257 \n",
    "n_matches = end_match - begin_match\n",
    "full_run = 0\n",
    "print(n_matches)\n",
    "\n",
    "if(full_run):\n",
    "    for i in range(n_matches):\n",
    "        api_string = \"https://fumbbl.com/api/match/get/\" + str(end_match - i)\n",
    "        # wait 0.5 s on average between each API call\n",
    "        wait_time = (random.uniform(0.5, 1) + 0.25)/3\n",
    "        time.sleep(wait_time)\n",
    "        match = requests.get(api_string)\n",
    "        match = match.json()\n",
    "        if match: # fix for matches that do not exist\n",
    "            match_id = match['id']\n",
    "            match_date = match['date']\n",
    "            match_time = match['time']\n",
    "            team1_id = match['team1']['id']\n",
    "            team2_id = match['team2']['id']\n",
    "            team1_score = match['team1']['score']\n",
    "            team2_score = match['team2']['score']  \n",
    "            team1_roster_id = match['team1']['roster']['id']\n",
    "            team2_roster_id = match['team2']['roster']['id']            \n",
    "            team1_coach_id = match['team1']['coach']['id']\n",
    "            team2_coach_id = match['team2']['coach']['id']\n",
    "            team1_race_name = match['team1']['roster']['name'] \n",
    "            team2_race_name = match['team2']['roster']['name'] \n",
    "            team1_value = match['team1']['teamValue']\n",
    "            team2_value = match['team2']['teamValue']\n",
    "            #print(match_id)     \n",
    "            df_matches_final.loc[i] = [match_id, match_date, match_time, \n",
    "                team1_id, team1_coach_id, team1_roster_id, team1_race_name, team1_value,\n",
    "                team2_id, team2_coach_id, team2_roster_id, team2_race_name, team2_value,\n",
    "                team1_score, team2_score]\n",
    "        else:\n",
    "            # empty data for this match, create empty row\n",
    "            match_id = int(end_match - i)\n",
    "            df_matches_final.loc[i] = [np.NaN, np.NaN, np.NaN, \n",
    "            np.NaN,np.NaN,np.NaN,np.NaN,\n",
    "            np.NaN,np.NaN,np.NaN,np.NaN,\n",
    "            np.NaN,np.NaN, np.NaN, np.NaN] # try np.repeat([np.NaN], 13, axis=0) next time\n",
    "            df_matches_final.loc[i]['match_id'] = int(match_id)\n",
    "        if i % 100 == 0: \n",
    "            # write tmp data as hdf5 file\n",
    "            print(i, end='')\n",
    "            print(\".\", end='')\n",
    "            df_matches_final.to_hdf(target, key='df_matches_final', mode='w')\n",
    "\n",
    "    # write data as hdf5 file\n",
    "    df_matches_final.to_hdf(target, key='df_matches_final', mode='w')\n",
    "else:\n",
    "    # read from hdf5 file\n",
    "    #df_matches_final = pd.read_hdf('data/df_matches_20211102_083311.h5')\n",
    "    df_matches_final = pd.read_hdf('data/df_matches_20211106_205843.h5')\n",
    "#\n",
    "df_matches_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert object dtype columns to proper pandas dtypes datetime and numeric\n",
    "df_matches_final['match_date'] = pd.to_datetime(df_matches_final.match_date) # Datetime object\n",
    "df_matches_final['match_id'] = pd.to_numeric(df_matches_final.match_id) \n",
    "df_matches_final['team1_id'] = pd.to_numeric(df_matches_final.team1_id) \n",
    "df_matches_final['team1_coach_id'] = pd.to_numeric(df_matches_final.team1_coach_id) \n",
    "df_matches_final['team1_roster_id'] = pd.to_numeric(df_matches_final.team1_roster_id) \n",
    "df_matches_final['team2_id'] = pd.to_numeric(df_matches_final.team2_id) \n",
    "df_matches_final['team2_coach_id'] = pd.to_numeric(df_matches_final.team2_coach_id) \n",
    "df_matches_final['team2_roster_id'] = pd.to_numeric(df_matches_final.team2_roster_id) \n",
    "df_matches_final['team1_score'] = pd.to_numeric(df_matches_final.team1_score) \n",
    "df_matches_final['team2_score'] = pd.to_numeric(df_matches_final.team2_score) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches_final.dtypes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 123K matches\n",
    "df_matches_final"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First analysis: Orcs are most popular!\n",
    "\n",
    "Which races are the most popular on FUMBLL in the last year?\n",
    "For this, we need only to count which races were chosen how many times.\n",
    "\n",
    "However, since each match contains two teams, we need to create a new dataframe `df_races`, double in size, that contains for each row the `match_id` and `team_race` of one of the two teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team1_races = df_matches_final[['match_id', 'team1_race_name']]\n",
    "team2_races = df_matches_final[['match_id', 'team2_race_name']]\n",
    "\n",
    "# make column names equal\n",
    "team1_races.columns = team2_races.columns = ['match_id', 'race_name']\n",
    "\n",
    "# row bind the two dataframes\n",
    "df_races = pd.concat([team1_races, team2_races])\n",
    "\n",
    "# aggregate by race_name\n",
    "res = (df_races\n",
    "        .groupby(['race_name'])\n",
    "        .size()\n",
    "        .reset_index(name='n_games')\n",
    ")\n",
    "\n",
    "# select most popular races for filtering\n",
    "top_races = res.loc[(res.n_games > 1000)]['race_name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as p9\n",
    "\n",
    "(p9.ggplot(data = res.loc[res['race_name'].isin(top_races)], mapping = p9.aes(x = 'reorder(race_name, n_games)', y = 'n_games'))\n",
    "    + p9.geom_point(colour = 'gray') \n",
    "    + p9.coord_flip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the orcs are most popular! \n",
    "\n",
    "# dataprep: df_wins prepare for raw win rates by race\n",
    "\n",
    "If we want to calculate a win rate for each race, we need to decide what to do with draws.\n",
    "I've never given the matter much thought, but it turns out other people have!\n",
    "For example, in football, there is a popular weighting scheme where wins are given 3 points, draws 1 point and losses 0 points.\n",
    "This is called [three points for a win](https://en.wikipedia.org/wiki/Three_points_for_a_win) . \n",
    "In Blood bowl leagues and tournaments, my impression is that this rule is used often as well.\n",
    "\n",
    "Mike Davies from the NAF calculates win rate by weighting each win as 1 point, and each draw as 0.5 points (For example, [here](https://public.tableau.com/app/profile/mike.sann0638.davies/viz/NAFGames_0/SuccessBB2020)). Let's do the same here!\n",
    "\n",
    "This creates again a dataframe that is double in size, `df_wins` because each match generates two rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# calculate match score difference\n",
    "df_matches_final['team1_win'] = np.sign(df_matches_final['team1_score'] - df_matches_final['team2_score'])\n",
    "df_matches_final['team2_win'] = np.sign(df_matches_final['team2_score'] - df_matches_final['team1_score'])\n",
    "\n",
    "team1_wins = df_matches_final[['match_id', 'match_date', 'team1_id', 'team1_race_name', 'team1_value', 'team1_win']].copy()\n",
    "\n",
    "team2_wins = df_matches_final[['match_id', 'match_date',  'team2_id', 'team2_race_name', 'team2_value', 'team2_win']].copy()\n",
    "\n",
    "\n",
    "team1_wins.columns = team2_wins.columns = ['match_id', 'match_date', 'team_id', 'race_name', 'team_value', 'wins']\n",
    "#team2_wins['wins'] = -1 * team2_wins['wins']\n",
    "\n",
    "df_wins = pd.concat([team1_wins, team2_wins])\n",
    "\n",
    "df_wins.loc[df_wins['wins'] == 0, 'wins'] = 0.5\n",
    "df_wins.loc[df_wins['wins'] == -1, 'wins'] = 0\n",
    "\n",
    "# convert to float\n",
    "df_wins['wins'] = df_wins['wins'].astype(float)\n",
    "\n",
    "# convert team value 1100k to 1100 integer and and above / below median (= low / high TV)\n",
    "df_wins['team_value'] = df_wins['team_value'].str.replace('k$', '')\n",
    "df_wins['team_value'] = df_wins['team_value'].fillna(0).astype(np.int64)\n",
    "\n",
    "df_wins['tv_quartile'] = pd.qcut(df_wins['team_value'], q=2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.query('team_value < 800 & team_value > 0')#['team_value'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidyverse-like data analysis with Pandas and plotnine\n",
    "\n",
    "Doing most of my day to day analysis in `R`, i am (by now) used to the tidyverse filosophy of breaking things apart in small steps, with each step on a separate line, and in order of execution. Luckily, the `Pandas` data analysis library allows us to do something similar, here it is called `method chaining`.\n",
    "The idea is that a Pandas object has methods for all the small operations we want to perform, and the python language that allows chaining these methods together.\n",
    "\n",
    "Here we demonstrate this by calculating average win percentage by race, and calling this result `perc_win`.\n",
    "\n",
    "**We still ignore ruleset and division because we do not have it yet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotnine as p9\n",
    "\n",
    "res = (df_wins\n",
    "        .loc[df_wins['race_name'].isin(top_races.array)]\n",
    "        .groupby('race_name')['wins']        \n",
    "        .mean()\n",
    "        .reset_index(name='perc_win'))\n",
    "\n",
    "\n",
    "(p9.ggplot(data = res, mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win'))\n",
    "    + p9.geom_point(colour = 'gray') \n",
    "    + p9.coord_flip()\n",
    "    + p9.ggtitle(\"raw win rate, ignoring ruleset\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins\n",
    "        .loc[df_wins['race_name'].isin(top_races.array)]\n",
    "        .query('team_value > 800 & team_value < 2500')\n",
    "        .groupby(['race_name', 'tv_quartile'])['wins']        \n",
    "        .mean()\n",
    "        .reset_index(name='perc_win'))\n",
    "\n",
    "\n",
    "(p9.ggplot(data = res, mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', color = 'tv_quartile'))\n",
    "    + p9.geom_point() \n",
    "    + p9.coord_flip()\n",
    "    + p9.scale_color_manual(values=[\"#990099\", \"#009F99\"])\n",
    "    + p9.ggtitle(\"raw win rate, ignoring ruleset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Fetch team level data (division, ruleset, roster, games_played) for all the teams in our matches dataset\n",
    "\n",
    "Let grab for all teams in `df_matches` the team **race** and **ruleset**.\n",
    "There are around 25 \"official\" races / different teams, such as orcs, elves, humans etc.\n",
    "Each race has different player types, with different strength, abilities, skills, etc.\n",
    "So we are cur\n",
    "\n",
    "The ruleset is important, because races can get **nerfed** (made weaker) or **buffed** (made stronger) when new versions of the ruleset are released.\n",
    "These changes are common in any gaming community, in an attempt to achieve more balance in the game.\n",
    "\n",
    "The division is also important. \n",
    "\n",
    "530 min for 44K teams. This uses Python sets (minus operator gives elements of set that are different)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = pd.DataFrame(columns=['team_id', 'division_id', 'division_name',  'league' ,\n",
    "    'ruleset', 'roster_id', 'race_name',  'games_played'])\n",
    "\n",
    "team_ids = list(df_matches_final['team1_id'].dropna()) + list(df_matches_final['team2_id'].dropna())\n",
    "\n",
    "\n",
    "# get unique values (nog steeds floats, grrr)\n",
    "team_ids = list(set(team_ids))\n",
    "\n",
    "target = 'data/df_teams_' + time.strftime(\"%Y%m%d_%H%M%S\") + '.h5'\n",
    "print(target)\n",
    "\n",
    "fullrun = 0\n",
    "\n",
    "if fullrun:\n",
    "    print('fetching team data for ', len(team_ids), ' teams')\n",
    "    for t in range(len(team_ids)):    \n",
    "        api_string = \"https://fumbbl.com/api/team/get/\" + str(int(team_ids[t]))\n",
    "        wait_time = (random.uniform(0.5, 1) + 0.25)/2 # avg time 0.5 s\n",
    "        time.sleep(wait_time)\n",
    "        team = requests.get(api_string)\n",
    "        team = team.json()\n",
    "        # grab fields\n",
    "        team_id = team['id']\n",
    "        division_id = team['divisionId']\n",
    "        division_name = team['division']\n",
    "        ruleset = team['ruleset']\n",
    "        league = team['league']\n",
    "        roster_id = team['roster']['id']\n",
    "        race_name = team['roster']['name']\n",
    "        games_played = team['record']['games']\n",
    "        # add to dataframe\n",
    "        df_teams.loc[t] = [team_id, division_id, division_name, league, ruleset, roster_id, race_name, games_played]\n",
    "        if t % 100 == 0: \n",
    "            # write tmp data as hdf5 file\n",
    "            print(t, end='')\n",
    "            print(\".\", end='')\n",
    "            df_teams.to_hdf(target, key='df_teams', mode='w')\n",
    "    \n",
    "    df_teams.to_hdf(target, key='df_teams', mode='w')\n",
    "else:\n",
    "    # read from hdf5 file\n",
    "    df_teams = pd.read_hdf('data/df_teams_20211030_115137.h5')\n",
    "\n",
    "#df_teams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how many teams do we have? We have data on 43K teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUMBBL divisions and rulesets\n",
    "\n",
    "FUMBBL allows coaches to create their own rulesets to play their own leagues and tournaments with. For example, there is a so-called \"Secret League\" where coaches can play with \"Ninja halflings\", of with \"Ethereal\" spirits etc. \n",
    "\n",
    "Since we want the team strength for the official rulesets, we need to drop the other rulesets.\n",
    "Also differences between divisions are potentially of importance.\n",
    "\n",
    "Lets have look at the various divisions and leagues, which rulesets are used, and which races are played how often.\n",
    "We only look at divisions and leagues with a sufficient volume of matches, or otherwise we do not have sufficient statistics for each race.\n",
    "This gives us 33K teams of 43K, so roughly 75% of all teams created last year.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter on most common rulesets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_teams\n",
    "    .groupby(['ruleset',  'league', 'division_id', 'division_name'])\n",
    "    .agg( n_teams = ('ruleset', 'count')\n",
    "    )\n",
    "    .query('n_teams > 1000')['n_teams']\n",
    "    .sum()\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Ruletset 4: BB2020 (correlated with Competitive division)\n",
    "* Ruleset 1: BB2016 (correlated with Ranked division but also with Black box)\n",
    "* Ruleset 6: League\n",
    "* Ruleset 2228: NAF-BB2020\n",
    "* Ruleset 303: United Open Rules (used by the Secret League, it allows teams like Ethereal)\n",
    "\n",
    "# League analyse\n",
    "\n",
    "There are a lot of small leagues being played on FUMBBL. Reasons to play in small local leagues vary.\n",
    "\n",
    "There are a few larger leagues, that have nation wide scale. \n",
    "\n",
    "There are two leagues that are international and have sufficient scale to analyse separately.\n",
    "\n",
    "This is the NAF tournaments (league 9298), and the Secret League (10263).\n",
    "\n",
    "## NAF Tournaments: What is with ruleset 2228\n",
    "\n",
    "They seem to be small scale, but consistent 6 week duration events? lets look up a few matches on FUMBBL.\n",
    "\n",
    "match 4274272 is within a tournament called SteelBowl 2021 [EU]\n",
    "The tournament has start /end dates 24 jan 2021. The match was at 29 jan.\n",
    "\n",
    "The match was a league division game, the team played 6 games in jan/feb/march.\n",
    "The League is called Online NAF tournaments.\n",
    "ACtually this is a group 9298 that contains tournaments.\n",
    "The group uses ruleset 2228.\n",
    "\n",
    "# So final groupings\n",
    "\n",
    "* Competitive BB2020\n",
    "* Ranked BB2016\n",
    "* Black box BB2016\n",
    "* League ruleset 6 / league 0 (regular league)\n",
    "* League ruleset 2228 / league 9298 (NAF tournaments)\n",
    "\n",
    "Checked by christer: Does this mean that the API only serves the most recent version of a ruleset, and that rulesets can be changed without requiring a new ruleset id to be created? Correct\n",
    "\n",
    "## Rulesets can be overwritten \n",
    "\n",
    "Ruleset 2228 appears to be BB2020 + slann + khorne, which the NAF prefers over the GW BB2020 ruleset.\n",
    "From the roster ids, we can see that only from oktober 2021, the NAF switched to BB2020 teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_rulesets = (df_teams\n",
    "    .groupby(['ruleset', 'league', 'division_id', 'division_name'])\n",
    "    .agg( n_teams = ('ruleset', 'count')\n",
    "    )\n",
    "    .query('n_teams > 100')\n",
    "    .reset_index()\n",
    ")['ruleset']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep: Merging the match data with the team / ruleset data\n",
    "\n",
    "For each match in the `df_wins` **DataFrame** we add the team-level information for `df_teams`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins = pd.merge(df_wins.drop('race_name', 1), df_teams, on='team_id', how='left')\n",
    "\n",
    "df_wins.dropna(subset=['match_date'])\n",
    "\n",
    "df_wins['roster_name'] = df_wins['roster_id'].astype(str) + '_' + df_wins['race_name']\n",
    "\n",
    "# 66 empty matches: we drop these\n",
    "df_wins.query('match_date != match_date')\n",
    "\n",
    "df_wins = df_wins.dropna(subset=['match_date'])\n",
    "\n",
    "#df_wins.query(\"match_id == 4339204\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep: Adding Week number to df_wins\n",
    "\n",
    "To see time trends, its useful to aggregate the data by week. For this we add a week number for each date, and from this week number, we convert back to a date to get a week_date. This last part is useful for plotting with `plotnine`, as this treats dates in a special way (PM how)\n",
    "We use the ISO definition of week, this has some unexpected behavior near the beginning / end of each year. \n",
    "\n",
    "The data starts in week x of 2020, and stops halfway week 44 in 2021. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins['week_number'] = df_wins['match_date'].dt.isocalendar().week\n",
    "\n",
    "\n",
    "# cannot convert to np int64 becaues of missing values\n",
    "# cannot convert to 'int64'-dtype NumPy array with missing values. Specify an appropriate 'na_value' for this dtype.\n",
    "df_wins['week_number'] = df_wins['week_number'].astype('Int64')\n",
    "#df_wins['week_number'] = df_wins['week_number'].fillna(0).astype(np.int64)\n",
    "\n",
    "# add year based on match dat\n",
    "df_wins['year'] = pd.DatetimeIndex(df_wins['match_date']).year\n",
    "\n",
    "# fix year for  ISO week 53 weeks jan 2021\n",
    "df_wins.loc[(df_wins['year'] == 2021) & (df_wins['week_number'] == 53), 'year'] = 2020\n",
    "\n",
    "df_wins['week_year'] = df_wins['year'].astype(str) + '-' + df_wins['week_number'].astype(str)\n",
    "\n",
    "df_wins['week_date'] = pd.to_datetime(df_wins['week_year'].astype(\"string\") + '-1', format = \"%Y-%U-%w\")\n",
    "\n",
    "# manual fix of week date (grrrr)\n",
    "df_wins.loc[(df_wins['week_date'] ==  '2021-01-04') & (df_wins['week_number'] == 53), 'week_date'] = '2020-12-31'\n",
    "\n",
    "df_wins.dtypes\n",
    "df_wins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep: adding division name and ruleset_name groups for analysis\n",
    "\n",
    "Should add this to the df_teams , then join this to the df_wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting out a few particular leagues\n",
    "df_wins.loc[(df_wins['league'] == 9298), 'division_name'] = 'NAF'\n",
    "df_wins.loc[(df_wins['league'] == 0) & (df_wins['ruleset'] == 6), 'division_name'] = 'Regular_league'\n",
    "df_wins.loc[(df_wins['league'] == 10263), 'division_name'] = 'Secret League'\n",
    "df_wins.loc[(df_wins['league'] == 10455), 'division_name'] = 'CIBBL'\n",
    "\n",
    "df_wins['ruleset_name'] = 'bb2016'\n",
    "df_wins['ruleset_name'] = 'bb2016'\n",
    "df_wins.loc[df_wins['division_name'] == 'Competitive', 'ruleset_name'] = 'bb2020'\n",
    "df_wins.loc[df_wins['division_name'] == 'NAF', 'ruleset_name'] = 'mixed'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins\n",
    "    .groupby(['week_date', 'week_number'])\n",
    "    .agg(        \n",
    "        #perc_win = ('wins', \"mean\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res['n_games'] = res['n_games']/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.query(\"week_date == '2021-01-04'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res, mapping = p9.aes(x = 'week_date', y = 'n_games', group = '1'))\n",
    "    + p9.geom_point() \n",
    "    + p9.geom_line()\n",
    "    + p9.expand_limits(y=[0,2000])\n",
    "    + p9.geom_vline(xintercept = '2021-09-01', color = \"red\")\n",
    "    + p9.ggtitle(\"Total FUMBBL games played in the last year\"))\n",
    "\n",
    "    # yes we exactly reproduce the counts from FUMBBL 30 week plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduce the FUMBBL 30-weeks plot\n",
    "\n",
    "We can see that the new ruleset is a big succes, with the number of games played on FUMBBL almost doubled going from august to september 2021!\n",
    "\n",
    "Starting in march 2020, online gaming activity saw a huge surge. Tabletop leagues switched to online etc. \n",
    "We can also see that the COVID-19 effect was declining in 2021, with game volume in july 2021 almost back at pre-corona levels.\n",
    "\n",
    "As a check on our work, we compare with the plots that FUMBBL itself provides at https://fumbbl.com/p/stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins\n",
    "    .groupby(['division_name', 'week_number', 'year'])\n",
    "    .agg(        \n",
    "        #perc_win = ('wins', \"mean\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res['n_games'] = res['n_games']/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res.query('year > 2020 & week_number < 43 & week_number > -1'), mapping = p9.aes(x = 'week_number', y = 'n_games', \n",
    "group = 'factor(division_name)', color = 'factor(division_name)'))\n",
    "    + p9.geom_point() \n",
    "    + p9.geom_line()\n",
    "    + p9.expand_limits(y=[0,2000])\n",
    "    + p9.ggtitle(\"FUMBBL games played in the last 30 weeks\"))\n",
    "\n",
    "    # yes we exactly reproduce the counts from FUMBBL 30 week plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res.query('year > 2020'), mapping = p9.aes(x = 'week_number', y = 'n_games', \n",
    "group = 'factor(division_name)', color = 'factor(division_name)'))\n",
    "    + p9.geom_point() \n",
    "    + p9.geom_line()\n",
    "    + p9.expand_limits(y=[0,2000])\n",
    "    + p9.ggtitle(\"FUMBBL games played in the last 30 weeks\"))\n",
    "\n",
    "    # yes we exactly reproduce the counts from FUMBBL 30 week plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main analysis: win rate Blackbox BB2016 vs Ranked BB2016\n",
    "\n",
    "Does it matter if coaches both need to agree for a match as in the `Ranked` division? \n",
    "For the BB2016 rules, we have data for both divisions, one in which coaches can choose their opponent, and one for which they cannot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main analysis: win rate BB2016 vs BB2020\n",
    "\n",
    "If we want two summary statistics instead of one, we need to use the `agg()` method.\n",
    "Furthermore, if we want the variable we group over as a regular column in the DataFrame, we need to use `reset_index()`.\n",
    "Now we have the data ready to make a nice plot.\n",
    "\n",
    "We are going to do the comparison for the main divisions that use BB2016 and BB2020 rules.\n",
    "The BB2016 rules are in three divisions: Blackbox, Ranked and regular league."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins\n",
    "    .groupby(['division_name', 'ruleset', 'league'])\n",
    "    .agg(        \n",
    "        #perc_win = ('wins', \"mean\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .sort_values( 'n_games', ascending = False)\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res['n_games'] = res['n_games']/2\n",
    "\n",
    "main_divisions = res.query('n_games > 6000')['division_name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins[df_wins['division_name'].isin(main_divisions)]\n",
    "    #.query('team_value > 800 & team_value < 2500')\n",
    "    .groupby(['race_name', 'ruleset_name', 'tv_quartile'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .query('n_games > 0')\n",
    "    .reset_index()) # this adds the group by variable (now index) as a column\n",
    "\n",
    "#res.sort_values('n_games')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weird: adding tv_quartile brings up n_games 0 in .agg\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding credible intervals for the win rates\n",
    "\n",
    "Comparing the win rates of BB2016 and BB2020 to koadah's dataset on http://fumbbldata.azurewebsites.net/stats.html , we find strong agreement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Function for computing confidence intervals\n",
    "from statsmodels.stats.proportion import proportion_confint   \n",
    "\n",
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(p9.ggplot(data = res.query('n_games > 10'), mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(ruleset_name)', color = 'factor(ruleset_name)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI'))\n",
    "    + p9.geom_point(color = 'black') \n",
    "    + p9.facet_wrap('tv_quartile')\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates by ruleset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion based on the confidence intervals\n",
    "\n",
    "Amazons, Orcs and Underworld denizens improved substantially. \n",
    "Halflings and goblins also improved. \n",
    "Humans a bit. Old World Alliance got substantially worse. \n",
    "Nurgle slightly worse, Vampires got worse.\n",
    "\n",
    "Both new teams introduced in BB2020, Imperial nobility and Black orcs, are not the strongest teams around with win rates that are below average.\n",
    "Slann and daemons of Khorne had no official rules from GW yet, so are not included in the Competitive division that uses BB2020 rules.\n",
    "\n",
    "Clearly, the BB2020 results mostly apply to low team value, as coaches did not have sufficient time to play enough to level up their teams with the new BB2020 rules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus analysis: is there a learning effect of the BB2020 rules\n",
    "\n",
    "Answer: no not really."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate by year and week number\n",
    "\n",
    "res = (df_wins.query('division_name == \"Competitive\"')\n",
    "    .groupby(['week_number', 'year', 'ruleset', 'race_name'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res\n",
    "\n",
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )\n",
    "\n",
    "(p9.ggplot(data = res.query('year > 2020 & week_number > 36 & week_number < 43'), \n",
    "    mapping = p9.aes(x = 'week_number', y = 'perc_win', group = 'factor(race_name)', color = 'factor(race_name)'))\n",
    "    + p9.geom_point(p9.aes(size = 'n_games')) \n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI'))\n",
    "    + p9.geom_line()\n",
    "    + p9.scale_size_area() \n",
    "    + p9.facet_wrap('race_name')\n",
    "    + p9.ggtitle(\"FUMBBL BB2020 win rates by race and week_nr\")\n",
    "    + p9.theme(figure_size=(16, 8)) \n",
    "    + p9.theme(legend_position='none'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluding remarks\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_wins.query('week_number == 4') # DOES NOT WORK week_number has UINT32 dtype which is not supported by query ??? wtf\n",
    "#df_wins.loc[(df_wins['week_number'] == 4) & (df_wins['ruleset'] == 2228)]\n",
    "\n",
    "(df_wins.loc[(df_wins['ruleset'] == 2228) & (df_wins['roster_id'] == 4956)])\n",
    "    #.groupby('roster_id')\n",
    "    #.count()).sort_values('roster_id', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the league field\n",
    "# aggregate by year and week number\n",
    "\n",
    "\n",
    "res = (df_wins\n",
    "    .groupby(['division_name', 'ruleset', 'league'])\n",
    "    .agg(        \n",
    "        #perc_win = ('wins', \"mean\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .sort_values( 'n_games', ascending = False)\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res['n_games'] = res['n_games']/2\n",
    "\n",
    "res.query('n_games > 2000')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50276fd1884268afe39607052f22ef19b84d915691d702a5c7e9a67a09867105"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('requests_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
