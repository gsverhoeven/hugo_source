{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing online Blood Bowl matches using Python: API scraping, pandas and plotnine\n",
    "\n",
    "This blogpost is about **Blood Bowl**, a boardgame I finally started playing last year. The goal of this blog post is to use Python API scraping to fetch online Blood Bowl match outcome data, and to use the `pandas` and `plotnine` Python packages to analyse and visualise the data.\n",
    "\n",
    "In 2020, a new version of the Blood Bowl board game came out with several changes to the rules, and to the available teams to play with.\n",
    "Last september, the online Blood Bowl gaming website **FUMBBL** switched to the new ruleset (\"BB2020\"), with players largely abandoning the previous ruleset (from 2016, \"BB2016\" hereafter). With a daily game volume of a few hundred matches, I decided it would be interesting to analyse the win rates of the different teams (or \"races\", given the fantasy world setting), and how these have been impacted by the new ruleset. This is important, because races can get **nerfed** (made weaker) or **buffed** (made stronger) when new versions of the ruleset are released. These changes are common in any gaming community, in an attempt to achieve more balance in the game. We examine whether the current \"three tier\" system to balance the strength differences between teams is optimal. The results can inform changes that improve balance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python packages used in this blog post\n",
    "\n",
    "This blogpost is written as a Jupyter notebook, and is fully reproducible. The idea is to make Blood Bowl data analysis accessible to others. Using only open source tooling reduces the barriers for others to take what i created and build on it. Apart from having Python installed, you need a code editor. Jupyter Notebooks can be read by many code editors, such as Jupyterlab, or Pycharm, i decided to try out [Visual Studio Code](https://code.visualstudio.com/), or **VS code** for short. It ticks all my boxes such as being cross platform (I use linux at home and Windows at work), being open source, and having a large user base, as [visible on Github](https://github.com/microsoft/vscode) with more than 125K stars. It works pretty well, the only thing I really miss is have a [Python console connected to the same kernel my Notebook is running on](https://stackoverflow.com/questions/54987778/is-it-possible-to-link-the-interactive-python-window-to-a-running-jupyter-notebo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import requests # API library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "\n",
    "#import statsmodels.api as sm # statistics library\n",
    "\n",
    "# Function for computing confidence intervals\n",
    "from statsmodels.stats.proportion import proportion_confint   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Blood Bowl\n",
    "\n",
    "Blood Bowl is a two player game on a board, with playing pieces, like Chess. But instead of two medieval kingdoms fighting, Blood Bowl is about fantasy football, say Tolkien meets rugby. It appealed to me as a teenager (I bought the game in 1994) because it combined the Warhammer playing pieces I liked so much (miniature models \"minis\" of Orcs, Elves, Dwarves etc) with simple game mechanics, but resulted in complex gameplay. Blood bowl requires a lot of skill to play well, with complex strategic decision making with a lot of uncertainty (heavy dice rolling involved). Blood Bowl is very much alive nowaydays: Over the timespan of a few decennia, an international gaming community has formed around the game, with a players' association, the NAF, with thousands of members, a World championship every two years, and with new editions and models being released on a regular basis. Blood Bowl is not only a game, it is also a sport, [like Chess](https://www.chess.com/article/view/is-chess-a-sport).\n",
    "And with all sports, statistics is not far away. So lets dive in the world of Blood Bowl stats nerdery.\n",
    "\n",
    "# Not all teams are created equal: tiers in Blood Bowl\n",
    "\n",
    "There are around 25 \"official\" races / different teams, such as orcs, elves, humans etc.\n",
    "Each race has different player types, with different strength, abilities, skills, etc.\n",
    "\n",
    "As already mentioned above, Blood Bowl is not balanced with respect to the (30) different team \"races\" available. For example, it is much harder to win a match playing with a **Vampires** team, compared to playing with an **Orc** team. Not surprisingly, teams that have a higher probability of winning are more popular both in Tabletop tournaments as well as online at FUMBBL. \n",
    "\n",
    "According to [this article from the NAF from 2017](https://www.thenaf.net/2017/05/tiers/), already since 2010 efforts were made to balance things out a bit between the different team strengths. For example, the weaker teams get more gold to spend on players, or get more so-called \"Star player points\" to spend on skilling players up. According to [the NAF](https://www.thenaf.net/tournaments/information/tiers-and-tiering/), traditionally team tiering consists of three groups, with Tier 1 being the strongest teams, and tier 3 the weakest teams. \n",
    " \n",
    "\n",
    "Below I made a visualization of these three groups, as well as the new BB2020 tiers per the 2020 rulebook. For **Humans** and **Old World Alliance** it is not entirely clear what is the \"official tier\", as the [current online NAF tournament](https://fumbbl.com/p/group?op=view&group=9298) places them in Tier 2 (same as always), but GW BB2020 places both Humans and Old World Alliance in tier 1, which is kind of weird given that their rules did not change much. So i plotted both.\n",
    "\n",
    "\n",
    "\n",
    "PM Hier moeten de nieuwe tiers bij.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_tiers = pd.read_excel('data/race_tiers_mapping.xlsx',  engine='openpyxl')\n",
    "race_tiers = race_tiers[ ['race_name', 'bb2020_tier', 'naf_tier', 'bb2020_nov21_tier']]\n",
    "race_tiers = race_tiers.dropna()\n",
    "# format for plotnine\n",
    "race_tiers_long = pd.melt(race_tiers, id_vars='race_name', value_vars=['bb2020_tier', 'naf_tier', 'bb2020_nov21_tier'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = race_tiers_long, mapping = p9.aes(x = 'reorder(race_name, value)', y = 'factor(value)', group = 'variable', color = 'variable'))\n",
    "    + p9.geom_point(size = 5) \n",
    "    + p9.coord_flip())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most NAF sanctioned tournaments use some form of tiering, but there exists a lot of variation in how this is implemented.\n",
    "From the [rules for obtaining NAF sanctioning](https://www.thenaf.net/wp-content/uploads/2020/11/NAF_Tournament_Approval_Document_2021.pdf):\n",
    "\n",
    "```\n",
    "Individual rules variations in tournaments are permitted, even encouraged. This is \n",
    "in order to give each tournament its individual character.\n",
    "[...]\n",
    "Modifications should not radically affect the existing balance between \n",
    "races, but incentives may be given to the traditionally less-competitive \n",
    "teams, provided this is in moderation. \n",
    "```\n",
    "\n",
    "For example, for the [World Cup in Austria (2019)](http://www.nafworldcup.sbbm-turniere.com/EN/WC4Rules.html), the Tier 2 teams above were further split up, giving four tiers in total. PM example Dutch open 2020\n",
    "\n",
    "# Analyzing NAF data\n",
    "\n",
    "Because there is all this variation in tiering, it is difficult to draw conclusions from NAF tournament data.\n",
    "We can still try though.\n",
    "\n",
    "Here are the win rates (with a draw counted as half a point) for BB2020 NAF tournaments. These were taken from the [NAF Tableau pages](https://public.tableau.com/app/profile/mike.sann0638.davies/viz/NAFGames_0/Variety) and contain match outcomes of all NAF tournaments since december 2020 using the new ruleset. \n",
    "I added uncertainty intervals assuming a simple \"coin flip\" process with a fixed probability of succes *p*, where i use for *p* the probability of succes that is calculated from the data. This gives us some indication of what variation to expect given the match volumes in the NAF database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naf = pd.read_csv('data/W_Race_Record_Full_Data_data_bb2020.csv', na_values = '')\n",
    "\n",
    "df_naf = df_naf.rename(columns={\"Race\": \"race_name\", \n",
    "                                \"Variant\": \"ruleset_version\", \n",
    "                                \"Win %\": \"wins\"})\n",
    "\n",
    "# transform wins to 0, 0.5 or 1 numeric\n",
    "df_naf['wins'] = df_naf['wins'].str.replace('%$', '')\n",
    "df_naf['wins'] = df_naf['wins'].fillna(0).astype(float).astype(np.int64)\n",
    "df_naf['wins'] = df_naf['wins']/100\n",
    "\n",
    "# add tiers\n",
    "df_naf = pd.merge(df_naf, race_tiers, on='race_name', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidyverse-like data analysis with Pandas and plotnine\n",
    "\n",
    "Doing most of my day to day analysis in `R`, i am (by now) used to the tidyverse filosophy of breaking things apart in small steps, with each step on a separate line, and in order of execution. Luckily, the `Pandas` data analysis library allows us to do something similar, here it is called `method chaining`.\n",
    "The idea is that a Pandas object has methods for all the small operations we want to perform, and the python language that allows chaining these methods together.\n",
    "\n",
    "Here we demonstrate this by calculating average win percentage by race, and calling this result `perc_win`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_naf\n",
    "    .groupby(['race_name', 'ruleset_version', 'naf_tier'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .sort_values( 'n_games', ascending = False)\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res = res.dropna()\n",
    "\n",
    "\n",
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )\n",
    "\n",
    "(p9.ggplot(data = res, mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(ruleset_version)', color = 'factor(ruleset_version)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI', color = 'factor(naf_tier)'))\n",
    "    + p9.geom_point(colour = \"black\" )\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates NAF BB2020 tournaments\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, even with most tournaments having some form of tiering, there are still teams that win NAF tournaments more often than others. For example, this quote is from the most recent [\"NAF tournament report\"](https://www.thenaf.net/rankings/elo-ranking/tableau/the-naf-report-2/):\n",
    "\n",
    "```\n",
    "Underworld continued to dominate in October, winning the two largest tournaments and maintaining the greater than 60% win ratio.  This is\n",
    "generally due to swarming giving them more players on the pitch and the use of Hakflem and Morg'n'Thorg. (N.b. these are special \"Star Players\" that can be added to teams)\n",
    "```\n",
    "\n",
    "This is exactly what we saw above in the NAF data. At the same time, we see that in the NAF tournaments, **Skaven** (A tier 1 team) win equally often as **Ogres**, a tier 3 team. This could very well be because of the tiering systems being used.\n",
    "\n",
    "However, the best way to learn about the teams relative strength is in the absence of any tiering. Then we can directly interpret the win rates as measuring relative team strength. For this, we turn to online Blood Bowl, and more specific, to **FUMBBL**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blood Bowl online: FUMBBL \n",
    "\n",
    "Blood Bowl can also be played online. A paid version called \"Blood Bowl 2\" with appealing 3D graphics is available on [Steam](https://store.steampowered.com/app/236690/Blood_Bowl_2/). However, a more basic (2D) version is available as [FUMBBL](https://fumbbl.com). It uses a Java client that uploads game results to an online server with an accompanying website that supports the managerial and community aspects of the game (Forming teams, using winnings to buy new players, organizing tournaments, forum discussions etc).\n",
    "The name **FUMBBL** is likely a wordplay on the combination of fumble (losing the ball in American Football) and BBL which stands for Blood Bowl League.\n",
    "\n",
    "The **FUMBBL** website (https://fumbbl.com) is one big pile of data. From coach pages, with their teams, to team rosters, with players, and match histories. It's all there.\n",
    "And the nice thing of **FUMBBL** , for our purpose, is that it has several divisions where all teams start out equal, i.e. there is no tiering system in place.\n",
    "This allows us to learn what the relative team strengths are purely under the GW BB2020 rules.\n",
    "\n",
    "To obtain **FUMBBL** data, we need to fetch it match by match, team by team. To do so, the site creator Christer Kaivo-oja, from Sweden, has made an API that allows us to easily fetch data. What follows is a short demonstration how the API works, before we fetch the **FUMBBL** match and team data of the last 12 months.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behold, the power of Requests / Using Python to fetch FUMBBL data\n",
    "\n",
    "We use the [Python **Requests** library](https://docs.python-requests.org/en/latest/) to make the API call over HTTPS and obtain the response from the FUMBLL server. The response is in the JSON format, a [light-weight data-interchange format](https://www.json.org/json-en.html) which is both easy to read and write for humans, and easy to parse and generate by computers. So this makes it a natural choice for an API.\n",
    "\n",
    "Here is an example of what is available at the coach level (in Blood Bowl, people playing the game are called *coaches*, since the playing pieces are already called the *players*). The full documentation of the API can be found at (https://fumbbl.com/apidoc/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://fumbbl.com/api/coach/teams/gsverhoeven\")\n",
    "# display the complete JSON object {}\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing JSON data\n",
    "\n",
    "Let's have a closer look at the JSON data structure here.\n",
    "We have a list of key-value pairs. \n",
    "Some keys contain simple values, such as `name`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but some return as value a new list of key-value pairs, such as `teams`.\n",
    "Actually this is a \"list of \"lists of key-value pairs\", since we have a separate list for each team.\n",
    "Even the list of a single team contains new structure, for example under the key `raceLogos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['teams'][2]['raceLogos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['teams'][2]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What data do we need? And in what shape?\n",
    "\n",
    "Now we know how the data comes in, we need to think about which variables we want, and how to structure them.\n",
    "The most straightforward level to analyze race strength is to look at **match outcomes**.\n",
    "At its core, the data consists of matches played by teams, commanded by coaches.\n",
    "Furthermore, we expect race strength to change over time, as new strategies are discovered by the players, or new rules get introduced. So the time dimension is important as well.\n",
    "\n",
    "So, let's go with a flat data frame with **rows for each match**, and columns for the various variables associated with each match.\n",
    "These would include:\n",
    "\n",
    "* Coach ids\n",
    "* Team races\n",
    "* Team ids\n",
    "* Date of the match\n",
    "* Outcome (Touchdowns of both teams)\n",
    "\n",
    "With this basic structure, we can add as many match related variables in the future, keeping the basic structure (each row is a match) unchanged.\n",
    "\n",
    "So lets get the match data!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Getting the match data\n",
    "\n",
    "So we are mostly intested in the current ruleset, this is `BB2020`. This ruleset became available in **FUMBBL** at september 1st 2021, and two months later, some 5000 games have been played. We also want to compare with the previous ruleset, where we have much more data available. How far do we go back? \n",
    "Lets start with matches played during the last year. So starting from september 1st, 2020, up to oktober 1st, 2021. \n",
    "This way, we have roughly 12 months of `BB2016` ruleset matches, and one month of `BB2020` matches.\n",
    "\n",
    "The easiest way to collect match data over a particular period of time is to just loop over `match_id`. The most recent match was 4.334.456, and since rougly 100.000 matches are played each year, we can fiddle about and we find match 4.226.550 played on september 1st, 2020.  So that means we need to collect some 110K matches. \n",
    "\n",
    "**VERY IMPORTANT: We do not want to overload the **FUMBBL** server, so we make only three API requests per second. In this way, the server load is hardly affected and it can continue functioning properly for all the Blood Bowl coaches playing their daily games!**\n",
    "\n",
    "To collect 110K matches, we will need 110000*0.333/3600 = 15 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated hours fetching data\n",
    "(4339204-4216257)*0.333/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches = pd.DataFrame(columns=['match_id', 'match_date', 'match_time',  \n",
    "    'team1_id', 'team1_coach_id', 'team1_roster_id', 'team1_race_name', 'team1_value',\n",
    "    'team2_id', 'team2_coach_id', 'team2_roster_id', 'team2_race_name', 'team2_value',\n",
    "    'team1_score', 'team2_score'])\n",
    "\n",
    "target = 'data/df_matches_' + time.strftime(\"%Y%m%d_%H%M%S\") + '.h5'\n",
    "print(target)\n",
    "\n",
    "end_match = 4347800\n",
    "begin_match = 4339205\n",
    "n_matches = end_match - begin_match\n",
    "full_run = 0\n",
    "print(n_matches)\n",
    "\n",
    "if(full_run):\n",
    "    for i in range(n_matches):\n",
    "        api_string = \"https://fumbbl.com/api/match/get/\" + str(end_match - i)\n",
    "        # wait 0.5 s on average between each API call\n",
    "        wait_time = (random.uniform(0.5, 1) + 0.25)/3\n",
    "        time.sleep(wait_time)\n",
    "        match = requests.get(api_string)\n",
    "        match = match.json()\n",
    "        if match: # fix for matches that do not exist\n",
    "            match_id = match['id']\n",
    "            match_date = match['date']\n",
    "            match_time = match['time']\n",
    "            team1_id = match['team1']['id']\n",
    "            team2_id = match['team2']['id']\n",
    "            team1_score = match['team1']['score']\n",
    "            team2_score = match['team2']['score']  \n",
    "            team1_roster_id = match['team1']['roster']['id']\n",
    "            team2_roster_id = match['team2']['roster']['id']            \n",
    "            team1_coach_id = match['team1']['coach']['id']\n",
    "            team2_coach_id = match['team2']['coach']['id']\n",
    "            team1_race_name = match['team1']['roster']['name'] \n",
    "            team2_race_name = match['team2']['roster']['name'] \n",
    "            team1_value = match['team1']['teamValue']\n",
    "            team2_value = match['team2']['teamValue']\n",
    "            #print(match_id)     \n",
    "            df_matches.loc[i] = [match_id, match_date, match_time, \n",
    "                team1_id, team1_coach_id, team1_roster_id, team1_race_name, team1_value,\n",
    "                team2_id, team2_coach_id, team2_roster_id, team2_race_name, team2_value,\n",
    "                team1_score, team2_score]\n",
    "        else:\n",
    "            # empty data for this match, create empty row\n",
    "            match_id = int(end_match - i)\n",
    "            df_matches.loc[i] = [np.NaN, np.NaN, np.NaN, \n",
    "            np.NaN,np.NaN,np.NaN,np.NaN,\n",
    "            np.NaN,np.NaN,np.NaN,np.NaN,\n",
    "            np.NaN,np.NaN, np.NaN, np.NaN] # try np.repeat([np.NaN], 13, axis=0) next time\n",
    "            df_matches.loc[i]['match_id'] = int(match_id)\n",
    "        if i % 100 == 0: \n",
    "            # write tmp data as hdf5 file\n",
    "            print(i, end='')\n",
    "            print(\".\", end='')\n",
    "            df_matches.to_hdf(target, key='df_matches', mode='w')\n",
    "\n",
    "    # write data as hdf5 file\n",
    "    df_matches.to_hdf(target, key='df_matches', mode='w')\n",
    "else:\n",
    "    # read from hdf5 file\n",
    "    df_matches1 = pd.read_hdf('data/df_matches_20211130_231815.h5')\n",
    "    df_matches2 = pd.read_hdf('data/df_matches_20211106_205843.h5')\n",
    "    df_matches = pd.concat([df_matches1, df_matches2], ignore_index=True)\n",
    "#\n",
    "df_matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert object dtype columns to proper pandas dtypes datetime and numeric\n",
    "df_matches['match_date'] = pd.to_datetime(df_matches.match_date) # Datetime object\n",
    "df_matches['match_id'] = pd.to_numeric(df_matches.match_id) \n",
    "df_matches['team1_id'] = pd.to_numeric(df_matches.team1_id) \n",
    "df_matches['team1_coach_id'] = pd.to_numeric(df_matches.team1_coach_id) \n",
    "df_matches['team1_roster_id'] = pd.to_numeric(df_matches.team1_roster_id) \n",
    "df_matches['team2_id'] = pd.to_numeric(df_matches.team2_id) \n",
    "df_matches['team2_coach_id'] = pd.to_numeric(df_matches.team2_coach_id) \n",
    "df_matches['team2_roster_id'] = pd.to_numeric(df_matches.team2_roster_id) \n",
    "df_matches['team1_score'] = pd.to_numeric(df_matches.team1_score) \n",
    "df_matches['team2_score'] = pd.to_numeric(df_matches.team2_score) \n",
    "\n",
    "# calculate match score difference\n",
    "df_matches['team1_win'] = np.sign(df_matches['team1_score'] - df_matches['team2_score'])\n",
    "df_matches['team2_win'] = np.sign(df_matches['team2_score'] - df_matches['team1_score'])\n",
    "\n",
    "# mirror match\n",
    "df_matches['mirror_match'] = 0\n",
    "df_matches.loc[df_matches['team1_race_name'] == df_matches['team2_race_name'], 'mirror_match'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5K mirror matches\n",
    "df_matches.query('mirror_match == 1')\n",
    "\n",
    "# Fix Khorne team name\n",
    "df_matches.loc[df_matches['team1_race_name'] == \"Khorne\", 'team1_race_name'] = 'Daemons of Khorne'\n",
    "df_matches.loc[df_matches['team2_race_name'] == \"Khorne\", 'team2_race_name'] = 'Daemons of Khorne'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches.query('team1_race_name == \"Daemons of Khorne\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep: team values\n",
    "\n",
    "In Blood Bowl, teams can develop themselves over the course of multiple matches. The winnings of each match can be spend on buying new, stronger players, or replace the players that ended up getting injured or even killed. In addition, players receive so-called *star points* for important events, such as scoring, or inflicting a casualty on the opponent. Therefore, a balancing mechanism is needed when when a newly created \"rookie\" team is facing a highly developed opponent with lots of extra skills and strong players. \n",
    "Blood Bowl solves this by calculating for both teams their **Current team value**.\n",
    "The **Team value difference** for a match determines the amount of gold that the weaker team can use to buy so-called **inducements**.\n",
    "These inducements are temporary, and can consists of a famous \"star player\" who joins the team just for this match. Another popular option is to hire a wizard that can be used to turn one of the opposing players into a frog.\n",
    "\n",
    "It is well known that the win rates of the teams depend on how developed a team is. For example, Amazons are thought to be strongest at low team value, as they already start out with lots of *block* and *dodge* skills, whereas a Chaos team start out with almost no skills.\n",
    "So if we compare win rates, we would like take into account the current team value. \n",
    "Now as this can differ between the two teams in a match up, I reasoned that the highest team value is most informative about the average development level of both teams, because of the inducement mechanism described above.\n",
    "\n",
    "In the dataset, we have for each match the current team values of both teams. Importantly, we do not have information on inducements.\n",
    "We discuss later what this means for the conclusions we can draw. Here we transform the text string `1100k` into an integer number `1100`, so that we can calculated the difference, and pick for each match the maximum team value and store it as `tv_match`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert team value 1100k to 1100 integer and and above / below median (= low / high TV)\n",
    "df_matches['team1_value'] = df_matches['team1_value'].str.replace('k$', '')\n",
    "df_matches['team1_value'] = df_matches['team1_value'].fillna(0).astype(np.int64)\n",
    "\n",
    "df_matches['team2_value'] = df_matches['team2_value'].str.replace('k$', '')\n",
    "df_matches['team2_value'] = df_matches['team2_value'].fillna(0).astype(np.int64)\n",
    "\n",
    "df_matches['tv_diff'] = np.abs(df_matches['team2_value'] - df_matches['team1_value'])\n",
    "\n",
    "df_matches['tv_match'] = df_matches[[\"team1_value\", \"team2_value\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 123K matches\n",
    "df_matches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First analysis: Orcs are most popular!\n",
    "\n",
    "Which races are the most popular on FUMBLL in the last year?\n",
    "For this, we need only to count which races were chosen how many times.\n",
    "\n",
    "However, since each match contains two teams, we need to create a new dataframe `df_races`, double in size, that contains for each row the `match_id` and `team_race` of one of the two teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team1_races = df_matches[['match_id', 'team1_race_name']]\n",
    "team2_races = df_matches[['match_id', 'team2_race_name']]\n",
    "\n",
    "# make column names equal\n",
    "team1_races.columns = team2_races.columns = ['match_id', 'race_name']\n",
    "\n",
    "# row bind the two dataframes\n",
    "df_races = pd.concat([team1_races, team2_races])\n",
    "\n",
    "# aggregate by race_name\n",
    "res = (df_races\n",
    "        .groupby(['race_name'])\n",
    "        .size()\n",
    "        .reset_index(name='n_games')\n",
    ")\n",
    "\n",
    "# select most popular races for filtering\n",
    "top_races = res.loc[(res.n_games > 1000)]['race_name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res.loc[res['race_name'].isin(top_races)], mapping = p9.aes(x = 'reorder(race_name, n_games)', y = 'n_games'))\n",
    "    + p9.geom_point(colour = 'gray') \n",
    "    + p9.expand_limits(y = 0)\n",
    "    + p9.coord_flip()\n",
    "    + p9.ggtitle('team races with at least 1000 FUMBBL matches in 2020-2021'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the orcs are most popular! Here we should keep in mind that we have pooled all the FUMBBL matches of last year. Of course, Black Orcs and Imperial Nobility are new BB2020 teams, having only been available on FUMBBL since september 2021.\n",
    "And daemons of Khorne, Slann and Bretonnian are not available in two large FUMBBL divisions.\n",
    "\n",
    "# Dataprep Start: \n",
    "\n",
    "This creates again a dataframe that is double in size, `df_wins` because each match generates two rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make two copies, one for each team in the match\n",
    "team1_wins = df_matches[['match_id', 'match_date', 'team1_id', 'team1_coach_id', 'team1_race_name', 'team1_value', 'team1_win', 'tv_diff', 'tv_match', 'mirror_match']].copy()\n",
    "team2_wins = df_matches[['match_id', 'match_date',  'team2_id', 'team2_coach_id', 'team2_race_name', 'team2_value', 'team2_win', 'tv_diff', 'tv_match', 'mirror_match']].copy()\n",
    "\n",
    "team1_wins.columns = team2_wins.columns = ['match_id', 'match_date', 'team_id', 'coach_id', 'race_name', 'team_value', 'wins', 'tv_diff', 'tv_match', 'mirror_match']\n",
    "\n",
    "# combine both dataframes\n",
    "df_wins = pd.concat([team1_wins, team2_wins])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match outcomes: How much is a draw worth?\n",
    "\n",
    "If we want to calculate a win rate for each race, we need to decide what to do with draws.\n",
    "I've never given the matter much thought, but it turns out other people have!\n",
    "\n",
    "For example, in football, there is a popular weighting scheme where wins are given 3 points, draws 1 point and losses 0 points.\n",
    "This is called [three points for a win](https://en.wikipedia.org/wiki/Three_points_for_a_win) . \n",
    "In Blood bowl leagues and tournaments, this rule is often used as well.\n",
    "So, if we want to predict which teams perform best in these settings (have the highest probability of winning a tournament), we need to weigh the match outcomes accordingly.\n",
    "\n",
    "However, in Blood Bowl data analysis, it seems that a 2:1:0 (W / D / L) weighting scheme is most commonly used. \n",
    "This scheme has the advantage that the weighted average win percentage over all matches is always 50%, creating a nice reference point allowing conclusions such as this and that team has an x percent above average win percentage.\n",
    "\n",
    "For example, Mike Davies from the NAF calculates win rate by weighting each win as 1 point, and each draw as 0.5 points (For example, [here](https://public.tableau.com/app/profile/mike.sann0638.davies/viz/NAFGames_0/SuccessBB2020)).\n",
    "\n",
    "So if we want to compare with others, it makes sense to adapt this scheme as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataset on the match-team level, lets prep the data a bit further.\n",
    "We add the half point for a draw in the `wins` column.\n",
    "\n",
    "And we create a team value bin to be able to compare win rates for teams that are hopefully more similar in team development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.loc[df_wins['wins'] == 0, 'wins'] = 0.5\n",
    "df_wins.loc[df_wins['wins'] == -1, 'wins'] = 0\n",
    "\n",
    "# convert to float\n",
    "df_wins['wins'] = df_wins['wins'].astype(float)\n",
    "\n",
    "df_wins['tv_bin'] = pd.cut(df_wins['tv_match'], [0, 950, 1250,1550, 1850, float(\"inf\")], labels=['< 950', '1.1K', '1.4K', '1.7K', '> 1850'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, Lets have a look at our dataset again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.query('team_value > 1000 & team_value < 1020')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Almost there. There is still something missing though, we need to know, for all the teams in our matches dataset, in what division or league they are playing, and what version of the rules they use. For these we turn to the API again, to fetch more data, now on the team level.\n",
    "\n",
    "# Step 2: Fetch data on team division and ruleset\n",
    "\n",
    "Let grab for all teams in `df_wins` the team **division** and **ruleset**.\n",
    "\n",
    "A limitation of the API is that it shows only the latest version of the teams and leagues.  This hides the fact that leagues have changed their rules since they were first created. For example, the NAF used BB2016 rules up until summer of 2021, and thereafter switched to the new BB2020 ruleset for their latest online tournament.\n",
    "So we have to use our \"domain knowledge\" here to interpret the data properly.\n",
    "\n",
    "**Note to self**: contact Christer suggesting change to freeze rulesets as soons as matches have been played with them.\n",
    "And force users to create new rulesets if they want to update / change previous rulesets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of all teams that need to be fetched\n",
    "team_ids = list(df_wins.query('match_id < 4339205')['team_id'].dropna())\n",
    "\n",
    "# get unique values by converting to a Python set and back to list\n",
    "team_ids = list(set(team_ids))\n",
    "\n",
    "len(team_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_team_ids = list(df_wins.query('match_id >= 4339205')['team_id'].dropna())\n",
    "team_ids = list(set(new_team_ids) - set(team_ids)) \n",
    "len(team_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have to fetch data for 43+4K different teams. \n",
    "\n",
    "We use the same approach as above, looping over all `team_id` 's and making a separate API call for each team.\n",
    "\n",
    "**IMPORTANT: here too, we limit ourselves to a maximum of 3 API calls per second to avoid overloading the FUMBBL server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = pd.DataFrame(columns=['team_id', 'division_id', 'division_name',  'league' ,\n",
    "    'ruleset', 'roster_id', 'race_name',  'games_played'])\n",
    "\n",
    "target = 'data/df_teams_' + time.strftime(\"%Y%m%d_%H%M%S\") + '.h5'\n",
    "print(target)\n",
    "\n",
    "fullrun = 0\n",
    "\n",
    "if fullrun:\n",
    "    print('fetching team data for ', len(team_ids), ' teams')\n",
    "    for t in range(len(team_ids)):    \n",
    "        api_string = \"https://fumbbl.com/api/team/get/\" + str(int(team_ids[t]))\n",
    "        wait_time = (random.uniform(0.5, 1) + 0.25)/3\n",
    "        time.sleep(wait_time)\n",
    "        team = requests.get(api_string)\n",
    "        team = team.json()\n",
    "        # grab fields\n",
    "        team_id = team['id']\n",
    "        division_id = team['divisionId']\n",
    "        division_name = team['division']\n",
    "        ruleset = team['ruleset']\n",
    "        league = team['league']\n",
    "        roster_id = team['roster']['id']\n",
    "        race_name = team['roster']['name']\n",
    "        games_played = team['record']['games']\n",
    "        # add to dataframe\n",
    "        df_teams.loc[t] = [team_id, division_id, division_name, league, ruleset, roster_id, race_name, games_played]\n",
    "        if t % 100 == 0: \n",
    "            # write tmp data as hdf5 file\n",
    "            print(t, end='')\n",
    "            print(\".\", end='')\n",
    "            df_teams.to_hdf(target, key='df_teams', mode='w')\n",
    "    \n",
    "    df_teams.to_hdf(target, key='df_teams', mode='w')\n",
    "else:\n",
    "    # read from hdf5 file\n",
    "    df_teams1 = pd.read_hdf('data/df_teams_20211030_115137.h5')\n",
    "    df_teams2 = pd.read_hdf('data/df_teams_20211202_222458.h5')\n",
    "    df_teams = pd.concat([df_teams1, df_teams2], ignore_index=True)\n",
    "\n",
    "\n",
    "df_teams['roster_name'] = df_teams['roster_id'].astype(str) + '_' + df_teams['race_name']\n",
    "\n",
    "df_teams.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the divisions and leagues to analyse\n",
    "\n",
    "FUMBBL allows coaches to create their own rulesets to play their own leagues and tournaments with. For example, there is a so-called \"Secret League\" where coaches can play with \"Ninja halflings\", of with \"Ethereal\" spirits etc. \n",
    "\n",
    "Since we want the team strength for the official rulesets BB2016 and BB2020, we need to drop the matches that are played under different rules.\n",
    "\n",
    "Lets have look at the various divisions and leagues, which rulesets are used, and which races are played how often.\n",
    "There are a lot of small leagues being played on FUMBBL, they account for maybe X% of all the matches.\n",
    "\n",
    "We only look at divisions and leagues with a sufficient volume of matches, or otherwise we do not have sufficient statistics for each race.\n",
    "\n",
    "So I aggregated the data by division, league and ruleset, and filtered on at least 150 different teams that have played at least once last year.\n",
    "Apart from the main \"Divisions\" that are part of FUMBBL, there were a few user-run leagues present in this table, so I looked up their names on FUMBBL and what ruleset is used (BB2016, BB2020 or some other variant). This information (contained in an xlsx) is added to the dataset below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ruleset_version and division_name from xlsx\n",
    "ruleset_division_names = pd.read_excel('data/ruleset_division_names.xlsx',  engine='openpyxl')\n",
    "\n",
    "df_teams = pd.merge(df_teams, ruleset_division_names, on= ['league', 'ruleset', 'division_id'], how='left')\n",
    "\n",
    "df_teams['division_name'] = df_teams['new_division_name']\n",
    "\n",
    "df_teams = df_teams.drop('new_division_name', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_teams\n",
    "    .groupby(['ruleset', 'league', 'division_id', 'division_name',  'ruleset_version'], dropna=False)\n",
    "    .agg( n_teams = ('ruleset', 'count')\n",
    "    )\n",
    "    .sort_values('n_teams', ascending = False)\n",
    "    .query('n_teams > 150')['n_teams']\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are primary interested in the new BB2020 ruleset version. We see that apart from the new **Competitive** division of FUMBBL itself, already a few user run leagues have started to use BB2020 rules. However, I chose to not include these leagues in the comparison: \n",
    "\n",
    "* Both NAF and Lega Gladio tournaments consist of a mix of BB2016 and BB2020 matches, making these more difficult to analyse. \n",
    "* Then there is the Secret League, which is different because of all the extra teams available there. \n",
    "* Test Open League BB2020 has likely been the test group before the Competitive Division became available.\n",
    "\n",
    "The NAF tournaments current ruleset is interesting, because it introduces (for the first time) tiers in FUMBBL!\n",
    "The NAF online tournament allows coaches to distribute a fixed number of skills, depending on the team's tier.\n",
    "This makes match outcomes in this league less comparable to other divisions on FUMBBL.\n",
    "\n",
    "Then on to the BB2016 ruleset. Here we have three big FUMBBL divisions: Blackbox, Ranked and (regular) League.\n",
    "Blackbox and Ranked use ruleset 1. FUMBBL has a nice display of a rulesets, see e.g. here for [ruleset 1](https://fumbbl.com/p/ruleset?id=1). Comparing this ruleset to the ruleset used in the BB2016 regular league, we find a few small differences: e.g. the latter has the special play cards, has a few extra teams available (e.g. Simyin), but does not allow for wizards and does not the use the expensive mistakes rule.\n",
    "\n",
    "To get sufficient observations for all the 25+ teams, we need at least a few thousands matches played.\n",
    "\n",
    "So we end up with comparing\n",
    "\n",
    "* Competitive BB2020\n",
    "\n",
    "VERSUS\n",
    "\n",
    "* Ranked BB2016\n",
    "* Black box BB2016\n",
    "* standard BB2016 League division (ruleset 6 / league 0)\n",
    "\n",
    "If the differences between these three division can be considered to be small, we can pool the matches from these three leagues to get better statistics.\n",
    "So lets compare win rates between these three divisions. To do so we add the division information to the `df_wins` data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep: Merging the match data with the team / ruleset data and team tiers\n",
    "\n",
    "For each match in the `df_wins` **DataFrame** we can now add the team-level information from `df_teams`.\n",
    "We also add the team tiers we used for the NAF dataset.\n",
    "As both datasets contain 'race_name', we drop one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins = pd.merge(df_wins, df_teams.drop('race_name', 1), on='team_id', how='left')\n",
    "\n",
    "# 66 empty matches: we drop these\n",
    "df_wins = df_wins.dropna(subset=['match_date'])\n",
    "\n",
    "# add bb2020 tiers\n",
    "df_wins = pd.merge(df_wins, race_tiers, on='race_name', how='left')\n",
    "\n",
    "df_wins['team_id'] = pd.to_numeric(df_wins.team_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep: getting the dates right\n",
    "\n",
    "To see time trends, its useful to aggregate the data by week. For this we add a week number for each date, and from this week number, we convert back to a date to get a week_date. This last part is useful for plotting with `plotnine`, as this treats dates in a special way (PM how)\n",
    "We use the ISO definition of week, this has some unexpected behavior near the beginning / end of each year. \n",
    "\n",
    "The data starts in week 36 (september) of 2020, and stops halfway week 44 in 2021. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins['week_number'] = df_wins['match_date'].dt.isocalendar().week\n",
    "\n",
    "\n",
    "# cannot convert to np int64 becaues of missing values\n",
    "# cannot convert to 'int64'-dtype NumPy array with missing values. Specify an appropriate 'na_value' for this dtype.\n",
    "df_wins['week_number'] = df_wins['week_number'].astype('Int64')\n",
    "#df_wins['week_number'] = df_wins['week_number'].fillna(0).astype(np.int64)\n",
    "\n",
    "# add year based on match date (but want it based on match ISO week)\n",
    "df_wins['year'] = pd.DatetimeIndex(df_wins['match_date']).year\n",
    "\n",
    "# manual fix year for ISO week 2020-53 (2020 has 53 ISO weeks, including a few days in jan 2021)\n",
    "df_wins.loc[(df_wins['year'] == 2021) & (df_wins['week_number'] == 53), 'year'] = 2020\n",
    "\n",
    "df_wins['week_year'] = df_wins['year'].astype(str) + '-' + df_wins['week_number'].astype(str)\n",
    "\n",
    "df_wins['week_date'] = pd.to_datetime(df_wins['week_year'].astype(\"string\") + '-1', format = \"%Y-%U-%w\")\n",
    "\n",
    "# manual fix of week date (grrrr)\n",
    "df_wins.loc[(df_wins['week_date'] ==  '2021-01-04') & (df_wins['week_number'] == 53), 'week_date'] = pd.to_datetime('2020-12-31')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Time series of number of games\n",
    "\n",
    "Now that we have a proper `datetime` type variable for each week, `week_date`, we can use plotnine to plot a nice time series graph of the total number of games played each week.\n",
    "The introduction of the new **Competitive** league with BB2020 rules is marked by a vertical red line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins\n",
    "    .loc[(df_wins['week_date'] >= '2020-09-01' ) & (df_wins['week_date'] < '2021-11-25')]\n",
    "    .groupby(['week_date', 'week_number'])\n",
    "    .agg(        \n",
    "        n_games = ('race_name', \"count\") \n",
    "    )\n",
    "\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res['n_games'] = res['n_games']/2 # each games creates two rows in df_wins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res, mapping = p9.aes(x = 'week_date', y = 'n_games', group = '1'))\n",
    "    + p9.geom_point() \n",
    "    + p9.geom_line()\n",
    "    + p9.expand_limits(y=[0,2000])\n",
    "    + p9.geom_vline(xintercept = '2021-09-01', color = \"red\")\n",
    "    + p9.ggtitle(\"Total FUMBBL games played in the last year\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a check on our data fetching work, we compare with the plots that FUMBBL itself provides at https://fumbbl.com/p/stats.\n",
    "\n",
    "Comparing with the 30-week Statistics plot on the FUMMBBL we can conclude that our dataset for sept 2020/ okt 2021 is complete!\n",
    "The effect of starting the new BB2020 division is also clearly visible, with the number of games played each week almost doubling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: Games per week by division\n",
    "\n",
    "We already look at the number of teams playing in each division.\n",
    "Now let us have a look at game volume over time, within the various divisions and leagues / tournaments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins\n",
    "    .loc[(df_wins['week_date'] >= '2020-09-01' ) & (df_wins['week_date'] < '2021-11-25')]\n",
    "    .groupby(['division_name', 'week_date', 'year'])\n",
    "    .agg(        \n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res['n_games'] = res['n_games']/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res.query(\"division_name != 'FFB Test'\"), mapping = p9.aes(x = 'week_date', y = 'n_games', \n",
    "group = 'factor(division_name)', color = 'factor(division_name)'))\n",
    "    + p9.geom_point() \n",
    "    + p9.geom_line()\n",
    "    + p9.expand_limits(y=[0,2000])\n",
    "    + p9.ggtitle(\"FUMBBL games played in the last year\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is interesting to compare the *Black box* division with the *League* division."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis: win rate Blackbox vs Ranked vs League division\n",
    "\n",
    "Now in the end, we want to compare BB2016 with BB2020. But as we can see above, there are various BB2016 divisions.\n",
    "Can we just pool them? Or are there differences that are important for our comparison?\n",
    "\n",
    "Lets first check out the BB2016 divisions.\n",
    "\n",
    "Does it matter if coaches both need to agree for a match as in the `Ranked` division? \n",
    "For the BB2016 rules, we have data for both divisions, one in which coaches can choose their opponent, and one for which they are randomly matched to other teams. \n",
    "\n",
    "First, compare Team value distributions between the two divisions, to see what exactly we are comparing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bb2016_divisions = ['Ranked', 'Regular_league', 'Blackbox']\n",
    "\n",
    "(p9.ggplot(data = df_wins[df_wins['division_name'].isin(bb2016_divisions)], mapping = p9.aes(x = 'reorder(division_name, team_value)', y = 'team_value', \n",
    "group = 'factor(division_name)', color = 'factor(division_name)'))\n",
    "    + p9.geom_boxplot()\n",
    "    #+ p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 1100)\n",
    "    + p9.ggtitle(\"Team value distributions\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, regular league (tournaments) have much lower team value, with a median slightly above 1100, often used for tournaments.\n",
    "This makes sense, as people tend to play longer with teams outside of leagues / tournaments, which force redrafts and / or are limited in duration.\n",
    "So, we have to look within TV bins.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bb2016_divisions = ['Ranked', 'Regular_league']\n",
    "bb2016_divisions = ['Ranked', 'Blackbox', 'Regular_league']\n",
    "\n",
    "#tv_bins = ['1K', '1.3K', '1.6K']\n",
    "tv_bins = ['1.1K', '1.4K', '1.7K']\n",
    "\n",
    "res = (df_wins[df_wins['division_name'].isin(bb2016_divisions)]\n",
    "    .loc[df_wins['tv_bin'].isin(tv_bins)]\n",
    "    .groupby(['division_name', 'ruleset_version', 'race_name', 'tv_bin'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .sort_values( 'n_games', ascending = False)\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res = res.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "# Function for computing confidence intervals\n",
    "from statsmodels.stats.proportion import proportion_confint   \n",
    "\n",
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(p9.ggplot(data = res.query('n_games > 10 & tv_bin == \"1.1K\"'), mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(division_name)', color = 'factor(division_name)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI'), position=p9.position_dodge2(preserve='single'))\n",
    "    + p9.geom_point(shape = '|', size = 5) # color = 'black', \n",
    "    + p9.facet_wrap('tv_bin')\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates Ranked vs Regular league\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.query('tv_bin == \"1.1K\" & division_name == \"Regular_league\" & race_name == \"Amazon\" & mirror_match == 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, if we compare Ranked vs regular league **within Team value bins**, no clear substantial differences appear.\n",
    "This suggests we can pool both leagues and compare both to the Competitive BB2020 match results.\n",
    "As long as we use team value bins, like \"Taureau Amiral\".\n",
    "\n",
    "\n",
    "*Conclusions for Ranked vs Black box*\n",
    "For the lower tier teams Ogre, Halfling and Goblin, clear differences can be seen between Ranked and Blackbox. Black box performance is lower.\n",
    "This suggests that we see the effect of strategically avoiding certain opponents, which is not possible in Blackbox. \n",
    "\n",
    "This argument could also explain the lower performance of Amazon at higher TV, which are known to perform better at low TV.\n",
    "For Chaos Chosen, we see a pattern that could be explained if players in Ranked strategically choose their opponents to skill up the team, which is known to only become competitive at higher team value.\n",
    "\n",
    "This gives some strength to the argument that the Competitive Division is not a **truly** competitive division, since players can choose their opponents, which is not possible at tournaments, and at random matching environments such as Blackbox was.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main analysis: win rate BB2016 vs BB2020\n",
    "\n",
    "If we want two summary statistics instead of one, we need to use the `agg()` method.\n",
    "Furthermore, if we want the variable we group over as a regular column in the DataFrame, we need to use `reset_index()`.\n",
    "Now we have the data ready to make a nice plot.\n",
    "\n",
    "We are going to do the comparison for the main divisions that use BB2016 and BB2020 rules.\n",
    "The BB2016 rules are in three divisions: Blackbox, Ranked and regular league.\n",
    "\n",
    "We drop so-called mirror matches (a small percentage of matches) and restrict the analysis to matches where the team value is lower than 150K. In this way, we can exclude the effect of popular star players such as Hackflem, Morg and Griff."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_divisions = ['Blackbox', 'Ranked', 'Regular_league', 'Competitive']\n",
    "\n",
    "res = (df_wins[df_wins['division_name'].isin(main_divisions)]\n",
    "    .query('mirror_match == 0 & tv_diff > 150')\n",
    "    .groupby(['race_name', 'ruleset_version', 'naf_tier', 'tv_bin'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .query('n_games > 0')\n",
    "    .reset_index()) # this adds the group by variable (now index) as a column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding credible intervals for the win rates\n",
    "\n",
    "Comparing the win rates of BB2016 and BB2020 to koadah's dataset on http://fumbbldata.azurewebsites.net/stats.html , we find strong agreement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )\n",
    "#np.sum(res.query('ruleset_version == \"bb2020\"')[['n_games']])/2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(p9.ggplot(data = res.query('n_games > 10 & tv_bin == \"1.1K\" '), mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(ruleset_version)', color = 'factor(ruleset_version)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI'))\n",
    "    + p9.geom_point(p9.aes(color = 'factor(naf_tier)') )\n",
    "    + p9.facet_wrap('tv_bin')\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates by ruleset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When interpreting these results, we should keep in mind that this is at low Team value, for example starting rosters, without any tiering.\n",
    "\n",
    "First, we check out the new teams introduced in BB2020. Both teams, Imperial nobility and Black orcs, are not the strongest teams around with win rates that are below average.\n",
    "\n",
    "In Tier 1, Amazons and Orcs improved substantially. \n",
    "Surprisingly, Underworld denizens are now among the strongest teams around. \n",
    "\n",
    "In Tier 2, Old World Alliance got substantially worse. There is no evidence for a higher win rate for High Elves, as was observed in the NAF tournament data of 2021.\n",
    "\n",
    "In Tier 3, Halflings and goblins improved. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(p9.ggplot(data = res.query('n_games > 10 & tv_bin == \"1.4K\" '), mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(ruleset_version)', color = 'factor(ruleset_version)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI'))\n",
    "    + p9.geom_point(p9.aes(color = 'factor(naf_tier)') )\n",
    "    + p9.facet_wrap('tv_bin')\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates by ruleset\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At higher TV, the uncertainty is larger, as less teams \"make it\" to higher team values. Because it takes time, and the data is from the first three months of BB2020 play, and it takes energy (you can lose a few games, and have to recover from that).\n",
    "\n",
    "The clearest changes at medium team value (around 1.4K +/-150) are improvements for Goblins and for Underworld Denizens. For goblins, the typical inducement is bribes. Even with 150K team value, 3 bribes are often induced, instead of a star player. \n",
    "Both new BB2020 teams, Imperial Nobility and Black Orcs, appear to be below average strength teams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df_wins.query('race_name == \"Underworld Denizens\" & tv_bin == \"1.4K\" & division_name == \"Competitive\" & mirror_match == 0 & wins == 1.0 & tv_diff > 150 & team_value < tv_match')\n",
    "\n",
    "(p9.ggplot(data = res, mapping = p9.aes(x = \"tv_diff\"))\n",
    "+ p9.geom_histogram(binwidth = 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.query('tv_diff == 90') # Peak is inducement van 2 bloodweiser kegs, of 2 bribes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df_wins.query('race_name == \"Goblin\" & tv_bin == \"1.1K\" & division_name == \"Competitive\" & mirror_match == 0 & wins == 1.0 & team_value < tv_match')\n",
    "\n",
    "(p9.ggplot(data = res, mapping = p9.aes(x = \"tv_diff\"))\n",
    "+ p9.geom_histogram(binwidth = 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = df_wins.query('race_name == \"Goblin\" & tv_bin == \"1.4K\" & division_name == \"Competitive\" & mirror_match == 0 & wins == 1.0 & team_value < tv_match')\n",
    "\n",
    "(p9.ggplot(data = res, mapping = p9.aes(x = \"tv_diff\"))\n",
    "+ p9.geom_histogram(binwidth = 10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res.query('tv_diff == 150')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observations and causal effects\n",
    "\n",
    "\n",
    "For the teams that already existed in BB2016, there were a few notable changes in relative team strength.\n",
    "\n",
    "[...]\n",
    "\n",
    "Important: Access to / changes in rules wrt Star players seem important in for example explaining the succes for Underworld.\n",
    "For example, a lot of underworld teams seem to keep Team value low, and choose Hakflem as star player.\n",
    "\n",
    "Hakflem appears to be very good value for money, according to this [article in Grotty Little Newspaper](https://fumbbl.com/modules.php?op=modload&name=Sections&file=index&req=viewarticle&artid=26&page=8) (from August 28th 2511 :-). In BB2020, Hakflem can be induced for 180K, whereas his roster value is estimated at 220K.\n",
    "\n",
    "PM Haflem and Morg became more expensive.\n",
    "\n",
    "# Elephant in the room\n",
    "\n",
    "Correlation is not causation, as the saying goes. Big elephant here in the room is player ability, which our analysis completely ignores.\n",
    "\n",
    "If the more experienced coaches know which teams are strongest, and choose those teams more often, we will see high win rates for those teams.\n",
    "\n",
    "If a team is more difficult to coach succesfully, inexperienced coaches picking such a team pull the winning rate down. On the other hand, they might be less tempted to pick the team, whereas experienced coaches might be attracted to the team, pulling the winning rate up.\n",
    "\n",
    "So, if experienced coaches have different preferences for teams, compared to inexperienced coaches, this will influence win rates.\n",
    "The win rates we now attribute to differences in innate race strength, might be caused by the unobserved abilities of the coaches playing.\n",
    "\n",
    "Nevertheless, it is striking that the win rates more or less following the tiers \n",
    "\n",
    "PM New NAF FUMBBL tournament with 5 tiers, skill stacking etc.\n",
    "\n",
    "Others have come to similar conclusions, for example [this](https://bbtactics.com/tournament-skill-stacking/)  \n",
    "\n",
    "And check out this ruleset: Project \"all teams viable\". The idea behind this ruleset is to make all teams competitive - while trying to maintain balance.\n",
    "https://bloodbowl.dk/onewebmedia/All_Teams_Viable_Ruleset.pdf\n",
    "\n",
    "Ref to Artificial turf paper.\n",
    "REF NAAR ERRATA NOV 2021 de UW nerfs, en nieuwe tiers. High elves T1, Orcs T2, WTF!!! Niet relevant, maar zijn toch misleidend, zetten nieuwe spelers op het verkeerde been.\n",
    "\n",
    "PM \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check out the inducements / star players of Blackbox and BB2020\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_divisions = ['Blackbox', 'Ranked', 'Regular_league', 'Competitive']\n",
    "\n",
    "res = (df_wins[df_wins['division_name'].isin(main_divisions)]\n",
    "    #.query('team_value > 800 & team_value < 2500')\n",
    "    .groupby(['coach_id'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .query('n_games > 100')\n",
    "    .sort_values('perc_win', ascending = False)\n",
    "    .reset_index()) # this adds the group by variable (now index) as a column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res\n",
    "\n",
    "res['quartile'] = pd.qcut(res['perc_win'], 4, labels=False)\n",
    "\n",
    "# PM select top quartile players, and lower quartile players. Compare n_games by race for both groups. Do winning players choose different teams compared to losing players?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q1_coaches = res.query(\"quartile == 3\")['coach_id']\n",
    "\n",
    "q4_coaches = res.query(\"quartile == 0\")['coach_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins[df_wins['coach_id'].isin(q1_coaches)]\n",
    "    .query('division_name != \"Competitive\" & tv_bin == \"1.4  K\" & mirror_match == 0')\n",
    "    .groupby(['race_name'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .query('n_games > 150')\n",
    "    .sort_values('perc_win', ascending = False)\n",
    "    .reset_index()) # this adds the group by variable (now index) as a column\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_wins[df_wins['coach_id'].isin(q4_coaches)]\n",
    "    .query('division_name != \"Competitive\" & tv_bin == \"1.1K\"')\n",
    "    .groupby(['race_name'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .query('n_games > 100')\n",
    "    .sort_values('n_games', ascending = False)\n",
    "    .reset_index()) # this adds the group by variable (now index) as a column\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_wins.query(\"tv_diff > 150 & race_name == 'Human' & division_name == 'Regular_league' & tv_bin == '1K'\").sort_values('race_name')\n",
    "\n",
    "df_wins.query('coach_id == 128852') # starjump\n",
    "df_wins.query('coach_id == 256723') # JepClock\n",
    "df_wins.query('coach_id == 249628') # DaPreacher heeft een super orc team in ranked. Hoge win rates allemaal bij tier 1 teams (dwarf, orc, undead etc)\n",
    "\n",
    "df_wins.query('coach_id == 254756')\n",
    "\n",
    "df_wins['match_id'].max()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching the inducements for all our matches using BeatifulSoup and Regular expressions\n",
    "\n",
    "See url here, and python library re there.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "df_inducements = pd.DataFrame(columns=['match_id', 'team1_inducements', 'team2_inducements'])\n",
    "\n",
    "target = 'data/df_inducements_' + time.strftime(\"%Y%m%d_%H%M%S\") + '.h5'\n",
    "print(target)\n",
    "\n",
    "end_match = 4334396 \n",
    "begin_match = 4296258 #4216258\n",
    "n_matches = end_match - begin_match\n",
    "\n",
    "full_run = 1\n",
    "\n",
    "print(n_matches)\n",
    "\n",
    "if(full_run):\n",
    "    for i in range(n_matches):\n",
    "        match_id = end_match - i\n",
    "        api_string = \"https://fumbbl.com/FUMBBL.php?page=match&id=\" + str(match_id)\n",
    "        # wait 0.5 s on average between each API call\n",
    "        wait_time = (random.uniform(0.5, 1) + 0.25)/2\n",
    "        time.sleep(wait_time)\n",
    "        response = requests.get(api_string)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        inducements = soup.find_all(\"div\", class_=\"inducements\")\n",
    "\n",
    "        pattern = re.compile(r'\\s+Inducements: (.*)\\n')\n",
    "\n",
    "        match = re.match(pattern, inducements[0].get_text())\n",
    "        if match:\n",
    "            team1_inducements = match.group(1)\n",
    "        else:\n",
    "            team1_inducements = ''\n",
    "\n",
    "        match = re.match(pattern, inducements[1].get_text())\n",
    "        if match:\n",
    "            team2_inducements = match.group(1)\n",
    "        else:\n",
    "            team2_inducements = ''\n",
    "\n",
    "        df_inducements.loc[i] = [match_id, team1_inducements, team2_inducements]\n",
    "        if i % 100 == 0: \n",
    "                    # write tmp data as hdf5 file\n",
    "                    print(i, end='')\n",
    "                    print(\".\", end='')\n",
    "                    df_inducements.to_hdf(target, key='df_inducements', mode='w')\n",
    "\n",
    "    # write data as hdf5 file\n",
    "    df_inducements.to_hdf(target, key='df_inducements', mode='w')\n",
    "else:\n",
    "    # read from hdf5 file\n",
    "    print(full_run)\n",
    "    #df_inducements = pd.read_hdf('data/df_inducements.h5')\n",
    "\n",
    "df_inducements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "match_id\n",
    "# 4324029 fixen, deze match is niet gespeeld./ missing"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50276fd1884268afe39607052f22ef19b84d915691d702a5c7e9a67a09867105"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('requests_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
