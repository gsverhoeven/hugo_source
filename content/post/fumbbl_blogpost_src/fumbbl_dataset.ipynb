{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A public dataset of online Blood Bowl matches played on FUMBBL.com in 2020-2021\n",
    "\n",
    "This blogpost is about **Blood Bowl**, a boardgame I finally started playing last year. The goal of this blog post is to use Python API and HTML scraping to fetch online Blood Bowl match outcome data, and to create a structured dataset ready for analysis and vizualisation. \n",
    "\n",
    "In 2020, a new version of the Blood Bowl board game came out with several changes to the rules, and to the available teams to play with.\n",
    "Last september, the online Blood Bowl gaming website **FUMBBL** switched to the new ruleset (\"BB2020\"), with players largely abandoning the previous ruleset (from 2016, \"BB2016\" hereafter). With a daily game volume of a few hundred matches, I decided it would be interesting to analyse the win rates of the different teams (or \"races\", given the fantasy world setting), and how these have been impacted by the new ruleset. This is important, because races can get **nerfed** (made weaker) or **buffed** (made stronger) when new versions of the ruleset are released. These changes are common in any gaming community, in an attempt to achieve more balance in the game. We examine whether the current \"three tier\" system to balance the strength differences between teams is optimal. The results can inform changes that improve balance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a data paper?\n",
    "\n",
    "*Data publication is becoming increasingly important to the scientific community, as it will provide a mechanism for those who create data to receive academic credit\n",
    "for their work and  will allow the conclusions arising from an analysis to be more readily verifiable, thus promoting transparency in the scientific process. Peer review of data will also provide a mechanism for ensuring the quality of datasets, and we provide suggestions on the types of activities one expects to see in the peer review of data. (Lawrence et al 2011)*\n",
    "\n",
    "To advance science, there is a need to share data. For example, to be able to reproduce the results of others, and to build upon work of others.\n",
    "Unfortunately, there are several issues with sharing data (Kratz & Strasser 2015):\n",
    "\n",
    "* Ethical issues (Human subjects data, privacy laws etc)\n",
    "* Time consuming: It takes time to carefully document the data: how it was collected, what \n",
    "* Career risk: Others might use the shared dataset to write publications that could have been yours to write.\n",
    "\n",
    "Contents of a data paper: motivation / dataset construction / dataset validation / re-use potential\n",
    "\n",
    "\n",
    "Kratz & Strasser, Researcher Perspectives on Publication and Peer Review of Data\n",
    "Lawrence et al, Citation and Peer Review of Data: Moving Towards Formal Data Publication\n",
    "\n",
    "https://arxiv.org/abs/2004.03688 With the open dataset published on Zenodo and the documentation on Arxiv.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Legal stuff FUMBBL\n",
    "\n",
    "\n",
    "All users of the FUMBBL.com website have agreed to the [terms of use](ref).\n",
    "\n",
    "```\n",
    "You explicitly agree, in using this web site or any service provided, that you shall not:\n",
    "[...]\n",
    "(c) collect or harvest any data about other users;\n",
    "```\n",
    "\n",
    "Part of the `terms of use` is the [privacy policy](https://fumbbl.com/p/privacy):\n",
    "\n",
    "```\n",
    "Content you provide through the website\n",
    "All the information you provide through the website is processed by FUMBBL. This includes things such as forum posts, private message posts, blog entries, team and player names and biographies and news comments. Data provided this way is visible by other people on the website and in most cases public even to individuals without accounts (not including private messages), and as such are considered of public interest. If direct personal information is posted in public view, you can contact moderators to resolve this. Match records are also considered content in this context, and is also considered of public interest. This data is collected as the primary purpose of the website and it is of course entirely up to you how much of this is provided to FUMBBL. \n",
    "\n",
    "Third party sharing\n",
    "Some of the public data is available through a public (*i.e. unauthenticated*) API, which shares some of the information provided by FUMBBL users in a way suitable for third-party websites and services to process.\n",
    "\n",
    "The data available through the unauthenticated API is considered non-personal as it only reflects information that is public by its nature on the website. The authenticated API will only show information connected to the authenticated account.\n",
    "\n",
    "You have already accepted these privacy rules. Should you change your mind, please go to the \"Right to Erasure\" page linked above. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python packages used in this blog post\n",
    "\n",
    "This blogpost is written as a Jupyter notebook, and is fully reproducible. The idea is to make Blood Bowl data analysis accessible to others. Using only open source tooling reduces the barriers for others to take what i created and build on it. Apart from having Python installed, you need a code editor. Jupyter Notebooks can be read by many code editors, such as Jupyterlab, or Pycharm, i decided to try out [Visual Studio Code](https://code.visualstudio.com/), or **VS code** for short. It ticks all my boxes such as being cross platform (I use linux at home and Windows at work), being open source, and having a large user base, as [visible on Github](https://github.com/microsoft/vscode) with more than 125K stars. It works pretty well, the only thing I really miss is have a [Python console connected to the same kernel my Notebook is running on](https://stackoverflow.com/questions/54987778/is-it-possible-to-link-the-interactive-python-window-to-a-running-jupyter-notebo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%connect_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "\n",
    "import requests # API library\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "\n",
    "#import statsmodels.api as sm # statistics library\n",
    "\n",
    "# Function for computing confidence intervals\n",
    "from statsmodels.stats.proportion import proportion_confint   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Introduction to Blood Bowl\n",
    "\n",
    "Blood Bowl is a two player game on a board, with playing pieces, like Chess. But instead of two medieval kingdoms fighting, Blood Bowl is about fantasy football, say Tolkien meets rugby. It appealed to me as a teenager (I bought the game in 1994) because it combined the Warhammer playing pieces I liked so much (miniature models \"minis\" of Orcs, Elves, Dwarves etc) with simple game mechanics, but resulted in complex gameplay. Blood bowl requires a lot of skill to play well, with complex strategic decision making with a lot of uncertainty (heavy dice rolling involved). Blood Bowl is very much alive nowaydays: Over the timespan of a few decennia, an international gaming community has formed around the game, with a players' association, the NAF, with thousands of members, a World championship every two years, and with new editions and models being released on a regular basis. Blood Bowl is not only a game, it is also a sport, [like Chess](https://www.chess.com/article/view/is-chess-a-sport).\n",
    "And with all sports, statistics is not far away. So lets dive in the world of Blood Bowl stats nerdery."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_tiers = pd.read_excel('data/race_tiers_mapping.xlsx',  engine='openpyxl')\n",
    "race_tiers = race_tiers[ ['race_name', 'bb2020_tier', 'naf_tier', 'bb2020_nov21_tier']]\n",
    "race_tiers = race_tiers.dropna()\n",
    "# format for plotnine\n",
    "race_tiers_long = pd.melt(race_tiers, id_vars='race_name', value_vars=['bb2020_tier', 'naf_tier', 'bb2020_nov21_tier'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = race_tiers_long, mapping = p9.aes(x = 'reorder(race_name, value)', y = 'factor(value)', group = 'variable', color = 'variable'))\n",
    "    + p9.geom_point(size = 5, mapping = p9.aes(shape = 'variable')) \n",
    "    + p9.coord_flip())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most NAF sanctioned tournaments use some form of tiering, but there exists a lot of variation in how this is implemented.\n",
    "From the [rules for obtaining NAF sanctioning](https://www.thenaf.net/wp-content/uploads/2020/11/NAF_Tournament_Approval_Document_2021.pdf):\n",
    "\n",
    "```\n",
    "Individual rules variations in tournaments are permitted, even encouraged. This is \n",
    "in order to give each tournament its individual character.\n",
    "[...]\n",
    "Modifications should not radically affect the existing balance between \n",
    "races, but incentives may be given to the traditionally less-competitive \n",
    "teams, provided this is in moderation. \n",
    "```\n",
    "\n",
    "For example, for the [World Cup in Austria (2019)](http://www.nafworldcup.sbbm-turniere.com/EN/WC4Rules.html), the Tier 2 teams above were further split up, giving four tiers in total. PM example Dutch open 2020\n",
    "\n",
    "# Analyzing NAF data\n",
    "\n",
    "Because there is all this variation in tiering, it is difficult to draw conclusions from NAF tournament data.\n",
    "We can still try though.\n",
    "\n",
    "Here are the win rates (with a draw counted as half a point) for BB2020 NAF tournaments. These were taken from the [NAF Tableau pages](https://public.tableau.com/app/profile/mike.sann0638.davies/viz/NAFGames_0/Variety) and contain match outcomes of all NAF tournaments since december 2020 using the new ruleset. \n",
    "I added uncertainty intervals assuming a simple \"coin flip\" process with a fixed probability of succes *p*, where i use for *p* the probability of succes that is calculated from the data. This gives us some indication of what variation to expect given the match volumes in the NAF database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_naf = pd.read_csv('data/W_Race_Record_Full_Data_data_bb2020.csv', na_values = '')\n",
    "\n",
    "df_naf = df_naf.rename(columns={\"Race\": \"race_name\", \n",
    "                                \"Variant\": \"ruleset_version\", \n",
    "                                \"Win %\": \"wins\"})\n",
    "\n",
    "# transform wins to 0, 0.5 or 1 numeric\n",
    "df_naf['wins'] = df_naf['wins'].str.replace('%$', '')\n",
    "df_naf['wins'] = df_naf['wins'].fillna(0).astype(float).astype(np.int64)\n",
    "df_naf['wins'] = df_naf['wins']/100\n",
    "\n",
    "# add tiers\n",
    "df_naf = pd.merge(df_naf, race_tiers, on='race_name', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidyverse-like data analysis with Pandas and plotnine\n",
    "\n",
    "Doing most of my day to day analysis in `R`, i am (by now) used to the tidyverse filosophy of breaking things apart in small steps, with each step on a separate line, and in order of execution. Luckily, the `Pandas` data analysis library allows us to do something similar, here it is called `method chaining`.\n",
    "The idea is that a Pandas object has methods for all the small operations we want to perform, and the python language that allows chaining these methods together.\n",
    "\n",
    "Here we demonstrate this by calculating average win percentage by race, and calling this result `perc_win`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = (df_naf\n",
    "    .groupby(['race_name', 'ruleset_version', 'naf_tier'])\n",
    "    .agg(        \n",
    "        perc_win = ('wins', \"mean\"),\n",
    "        n_wins = ('wins', \"sum\"),\n",
    "        n_games = ('race_name', \"count\")\n",
    "    )\n",
    "    .sort_values( 'n_games', ascending = False)\n",
    "    .reset_index()) # this adds the group by variables (now index) as a column\n",
    "\n",
    "res = res.dropna()\n",
    "\n",
    "\n",
    "res['lower_CI'], res['upper_CI'] =  proportion_confint(\n",
    "                                      count = round(res['n_wins']).astype(int),\n",
    "                                      nobs = res['n_games'],\n",
    "                                      alpha = 0.05\n",
    "                                  )\n",
    "\n",
    "(p9.ggplot(data = res, mapping = p9.aes(x = 'reorder(race_name, perc_win)', y = 'perc_win', \n",
    "size = 'n_games', group = 'factor(ruleset_version)', color = 'factor(ruleset_version)'))\n",
    "    + p9.geom_errorbar(p9.aes(ymin = 'lower_CI', ymax = 'upper_CI', color = 'factor(naf_tier)'))\n",
    "    + p9.geom_point(colour = \"black\" )\n",
    "    + p9.scale_size_area() \n",
    "    + p9.coord_flip()\n",
    "    + p9.geom_hline(yintercept = 0.5)\n",
    "    + p9.ggtitle(\"raw win rates NAF BB2020 tournaments\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that, even with most tournaments having some form of tiering, there are still teams that win NAF tournaments more often than others. For example, this quote is from the most recent [\"NAF tournament report\"](https://www.thenaf.net/rankings/elo-ranking/tableau/the-naf-report-2/):\n",
    "\n",
    "```\n",
    "Underworld continued to dominate in October, winning the two largest tournaments and maintaining the greater than 60% win ratio.  This is\n",
    "generally due to swarming giving them more players on the pitch and the use of Hakflem and Morg'n'Thorg. (N.b. these are special \"Star Players\" that can be added to teams)\n",
    "```\n",
    "\n",
    "This is exactly what we saw above in the NAF data. At the same time, we see that in the NAF tournaments, **Skaven** (A tier 1 team) win equally often as **Ogres**, a tier 3 team. This could very well be because of the tiering systems being used.\n",
    "\n",
    "However, the best way to learn about the teams relative strength is in the absence of any tiering. Then we can directly interpret the win rates as measuring relative team strength. For this, we turn to online Blood Bowl, and more specific, to **FUMBBL**!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blood Bowl online: FUMBBL \n",
    "\n",
    "Blood Bowl can also be played online. A paid version called \"Blood Bowl 2\" with appealing 3D graphics is available on [Steam](https://store.steampowered.com/app/236690/Blood_Bowl_2/). However, a more basic (2D) version is available as [FUMBBL](https://fumbbl.com). It uses a Java client that uploads game results to an online server with an accompanying website that supports the managerial and community aspects of the game (Forming teams, using winnings to buy new players, organizing tournaments, forum discussions etc).\n",
    "The name **FUMBBL** is likely a wordplay on the combination of fumble (losing the ball in American Football) and BBL which stands for Blood Bowl League.\n",
    "\n",
    "The **FUMBBL** website (https://fumbbl.com) is one big pile of data. From coach pages, with their teams, to team rosters, with players, and match histories. It's all there.\n",
    "And the nice thing of **FUMBBL** , for our purpose, is that it has several divisions where all teams start out equal, i.e. there is no tiering system in place.\n",
    "This allows us to learn what the relative team strengths are purely under the GW BB2020 rules.\n",
    "\n",
    "To obtain **FUMBBL** data, we need to fetch it match by match, team by team. To do so, the site creator Christer Kaivo-oja, from Sweden, has made an API that allows us to easily fetch data. What follows is a short demonstration how the API works, before we fetch the **FUMBBL** match and team data of the last 12 months.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Behold, the power of Requests / Using Python to fetch FUMBBL data\n",
    "\n",
    "We use the [Python **Requests** library](https://docs.python-requests.org/en/latest/) to make the API call over HTTPS and obtain the response from the FUMBLL server. The response is in the JSON format, a [light-weight data-interchange format](https://www.json.org/json-en.html) which is both easy to read and write for humans, and easy to parse and generate by computers. So this makes it a natural choice for an API.\n",
    "\n",
    "Here is an example of what is available at the coach level (in Blood Bowl, people playing the game are called *coaches*, since the playing pieces are already called the *players*). The full documentation of the API can be found at (https://fumbbl.com/apidoc/).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(\"https://fumbbl.com/api/coach/teams/gsverhoeven\")\n",
    "# display the complete JSON object {}\n",
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing JSON data\n",
    "\n",
    "Let's have a closer look at the JSON data structure here.\n",
    "We have a list of key-value pairs. \n",
    "Some keys contain simple values, such as `name`, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but some return as value a new list of key-value pairs, such as `teams`.\n",
    "Actually this is a \"list of \"lists of key-value pairs\", since we have a separate list for each team.\n",
    "Even the list of a single team contains new structure, for example under the key `raceLogos`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['teams'][2]['raceLogos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.json()['teams'][2]['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What data do we need? And in what shape?\n",
    "\n",
    "Now we know how the data comes in, we need to think about which variables we want, and how to structure them.\n",
    "The most straightforward level to analyze race strength is to look at **match outcomes**.\n",
    "At its core, the data consists of matches played by teams, commanded by coaches.\n",
    "Furthermore, we expect race strength to change over time, as new strategies are discovered by the players, or new rules get introduced. So the time dimension is important as well.\n",
    "\n",
    "So, let's go with a flat data frame with **rows for each match**, and columns for the various variables associated with each match.\n",
    "These would include:\n",
    "\n",
    "* Coach ids\n",
    "* Team races\n",
    "* Team ids\n",
    "* Date of the match\n",
    "* Outcome (Touchdowns of both teams)\n",
    "\n",
    "With this basic structure, we can add as many match related variables in the future, keeping the basic structure (each row is a match) unchanged.\n",
    "\n",
    "So lets get the match data!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Getting the match data\n",
    "\n",
    "So we are mostly intested in the current ruleset, this is `BB2020`. This ruleset became available in **FUMBBL** at september 1st 2021, and two months later, some 5000 games have been played. We also want to compare with the previous ruleset, where we have much more data available. How far do we go back? \n",
    "Lets start with matches played during the last year. So starting from september 1st, 2020, up to oktober 1st, 2021. \n",
    "This way, we have roughly 12 months of `BB2016` ruleset matches, and one month of `BB2020` matches.\n",
    "\n",
    "The easiest way to collect match data over a particular period of time is to just loop over `match_id`. The most recent match was 4.334.456, and since rougly 100.000 matches are played each year, we can fiddle about and we find match 4.226.550 played on september 1st, 2020.  So that means we need to collect some 110K matches. \n",
    "\n",
    "**VERY IMPORTANT: We do not want to overload the **FUMBBL** server, so we make only three API requests per second. In this way, the server load is hardly affected and it can continue functioning properly for all the Blood Bowl coaches playing their daily games!**\n",
    "\n",
    "To collect 110K matches, we will need 110000*0.333/3600 = 15 hours."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimated hours fetching data\n",
    "(4339204-4216257)*0.333/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches = pd.DataFrame(columns=['match_id', 'match_date', 'match_time',  \n",
    "    'team1_id', 'team1_coach_id', 'team1_roster_id', 'team1_race_name', 'team1_value',\n",
    "    'team2_id', 'team2_coach_id', 'team2_roster_id', 'team2_race_name', 'team2_value',\n",
    "    'team1_score', 'team2_score'])\n",
    "\n",
    "target = 'data/df_matches_' + time.strftime(\"%Y%m%d_%H%M%S\") + '.h5'\n",
    "print(target)\n",
    "\n",
    "end_match = 4347800\n",
    "begin_match = 4339205\n",
    "n_matches = end_match - begin_match\n",
    "full_run = 0\n",
    "print(n_matches)\n",
    "\n",
    "if(full_run):\n",
    "    for i in range(n_matches):\n",
    "        api_string = \"https://fumbbl.com/api/match/get/\" + str(end_match - i)\n",
    "        # wait 0.5 s on average between each API call\n",
    "        wait_time = (random.uniform(0.5, 1) + 0.25)/3\n",
    "        time.sleep(wait_time)\n",
    "        match = requests.get(api_string)\n",
    "        match = match.json()\n",
    "        if match: # fix for matches that do not exist\n",
    "            match_id = match['id']\n",
    "            match_date = match['date']\n",
    "            match_time = match['time']\n",
    "            team1_id = match['team1']['id']\n",
    "            team2_id = match['team2']['id']\n",
    "            team1_score = match['team1']['score']\n",
    "            team2_score = match['team2']['score']  \n",
    "            team1_roster_id = match['team1']['roster']['id']\n",
    "            team2_roster_id = match['team2']['roster']['id']            \n",
    "            team1_coach_id = match['team1']['coach']['id']\n",
    "            team2_coach_id = match['team2']['coach']['id']\n",
    "            team1_race_name = match['team1']['roster']['name'] \n",
    "            team2_race_name = match['team2']['roster']['name'] \n",
    "            team1_value = match['team1']['teamValue']\n",
    "            team2_value = match['team2']['teamValue']\n",
    "            #print(match_id)     \n",
    "            df_matches.loc[i] = [match_id, match_date, match_time, \n",
    "                team1_id, team1_coach_id, team1_roster_id, team1_race_name, team1_value,\n",
    "                team2_id, team2_coach_id, team2_roster_id, team2_race_name, team2_value,\n",
    "                team1_score, team2_score]\n",
    "        else:\n",
    "            # empty data for this match, create empty row\n",
    "            match_id = int(end_match - i)\n",
    "            df_matches.loc[i] = [np.NaN, np.NaN, np.NaN, \n",
    "            np.NaN,np.NaN,np.NaN,np.NaN,\n",
    "            np.NaN,np.NaN,np.NaN,np.NaN,\n",
    "            np.NaN,np.NaN, np.NaN, np.NaN] # try np.repeat([np.NaN], 13, axis=0) next time\n",
    "            df_matches.loc[i]['match_id'] = int(match_id)\n",
    "        if i % 100 == 0: \n",
    "            # write tmp data as hdf5 file\n",
    "            print(i, end='')\n",
    "            print(\".\", end='')\n",
    "            df_matches.to_hdf(target, key='df_matches', mode='w')\n",
    "\n",
    "    # write data as hdf5 file\n",
    "    df_matches.to_hdf(target, key='df_matches', mode='w')\n",
    "else:\n",
    "    # read from hdf5 file\n",
    "    df_matches1 = pd.read_hdf('data/df_matches_20211130_231815.h5')\n",
    "    df_matches2 = pd.read_hdf('data/df_matches_20211106_205843.h5')\n",
    "    df_matches = pd.concat([df_matches1, df_matches2], ignore_index=True)\n",
    "#\n",
    "df_matches.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert object dtype columns to proper pandas dtypes datetime and numeric\n",
    "df_matches['match_date'] = pd.to_datetime(df_matches.match_date) # Datetime object\n",
    "df_matches['match_id'] = pd.to_numeric(df_matches.match_id) \n",
    "df_matches['team1_id'] = pd.to_numeric(df_matches.team1_id) \n",
    "df_matches['team1_coach_id'] = pd.to_numeric(df_matches.team1_coach_id) \n",
    "df_matches['team1_roster_id'] = pd.to_numeric(df_matches.team1_roster_id) \n",
    "df_matches['team2_id'] = pd.to_numeric(df_matches.team2_id) \n",
    "df_matches['team2_coach_id'] = pd.to_numeric(df_matches.team2_coach_id) \n",
    "df_matches['team2_roster_id'] = pd.to_numeric(df_matches.team2_roster_id) \n",
    "df_matches['team1_score'] = pd.to_numeric(df_matches.team1_score) \n",
    "df_matches['team2_score'] = pd.to_numeric(df_matches.team2_score) \n",
    "\n",
    "# calculate match score difference\n",
    "df_matches['team1_win'] = np.sign(df_matches['team1_score'] - df_matches['team2_score'])\n",
    "df_matches['team2_win'] = np.sign(df_matches['team2_score'] - df_matches['team1_score'])\n",
    "\n",
    "# mirror match\n",
    "df_matches['mirror_match'] = 0\n",
    "df_matches.loc[df_matches['team1_race_name'] == df_matches['team2_race_name'], 'mirror_match'] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5K mirror matches\n",
    "df_matches.query('mirror_match == 1')\n",
    "\n",
    "# Fix Khorne team name\n",
    "df_matches.loc[df_matches['team1_race_name'] == \"Khorne\", 'team1_race_name'] = 'Daemons of Khorne'\n",
    "df_matches.loc[df_matches['team2_race_name'] == \"Khorne\", 'team2_race_name'] = 'Daemons of Khorne'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches.query('team1_race_name == \"Daemons of Khorne\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep: team values\n",
    "\n",
    "In Blood Bowl, teams can develop themselves over the course of multiple matches. The winnings of each match can be spend on buying new, stronger players, or replace the players that ended up getting injured or even killed. In addition, players receive so-called *star points* for important events, such as scoring, or inflicting a casualty on the opponent. Therefore, a balancing mechanism is needed when when a newly created \"rookie\" team is facing a highly developed opponent with lots of extra skills and strong players. \n",
    "Blood Bowl solves this by calculating for both teams their **Current team value**.\n",
    "The **Team value difference** for a match determines the amount of gold that the weaker team can use to buy so-called **inducements**.\n",
    "These inducements are temporary, and can consists of a famous \"star player\" who joins the team just for this match. Another popular option is to hire a wizard that can be used to turn one of the opposing players into a frog.\n",
    "\n",
    "It is well known that the win rates of the teams depend on how developed a team is. For example, Amazons are thought to be strongest at low team value, as they already start out with lots of *block* and *dodge* skills, whereas a Chaos team start out with almost no skills.\n",
    "So if we compare win rates, we would like take into account the current team value. \n",
    "Now as this can differ between the two teams in a match up, I reasoned that the highest team value is most informative about the average development level of both teams, because of the inducement mechanism described above.\n",
    "\n",
    "In the dataset, we have for each match the current team values of both teams. Importantly, we do not have information on inducements.\n",
    "We discuss later what this means for the conclusions we can draw. Here we transform the text string `1100k` into an integer number `1100`, so that we can calculated the difference, and pick for each match the maximum team value and store it as `tv_match`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# convert team value 1100k to 1100 integer and and above / below median (= low / high TV)\n",
    "df_matches['team1_value'] = df_matches['team1_value'].str.replace('k$', '')\n",
    "df_matches['team1_value'] = df_matches['team1_value'].fillna(0).astype(np.int64)\n",
    "\n",
    "df_matches['team2_value'] = df_matches['team2_value'].str.replace('k$', '')\n",
    "df_matches['team2_value'] = df_matches['team2_value'].fillna(0).astype(np.int64)\n",
    "\n",
    "df_matches['tv_diff'] = np.abs(df_matches['team2_value'] - df_matches['team1_value'])\n",
    "\n",
    "df_matches['tv_match'] = df_matches[[\"team1_value\", \"team2_value\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 123K matches\n",
    "df_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team1_races = df_matches[['match_id', 'team1_race_name']]\n",
    "team2_races = df_matches[['match_id', 'team2_race_name']]\n",
    "\n",
    "# make column names equal\n",
    "team1_races.columns = team2_races.columns = ['match_id', 'race_name']\n",
    "\n",
    "# row bind the two dataframes\n",
    "df_races = pd.concat([team1_races, team2_races])\n",
    "\n",
    "# aggregate by race_name\n",
    "res = (df_races\n",
    "        .groupby(['race_name'])\n",
    "        .size()\n",
    "        .reset_index(name='n_games')\n",
    ")\n",
    "\n",
    "# select most popular races for filtering\n",
    "top_races = res.loc[(res.n_games > 1000)]['race_name']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(p9.ggplot(data = res.loc[res['race_name'].isin(top_races)], mapping = p9.aes(x = 'reorder(race_name, n_games)', y = 'n_games'))\n",
    "    + p9.geom_point(colour = 'gray') \n",
    "    + p9.expand_limits(y = 0)\n",
    "    + p9.coord_flip()\n",
    "    + p9.ggtitle('team races with at least 1000 FUMBBL matches in 2020-2021'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the orcs are most popular! Here we should keep in mind that we have pooled all the FUMBBL matches of last year. Of course, Black Orcs and Imperial Nobility are new BB2020 teams, having only been available on FUMBBL since september 2021.\n",
    "And daemons of Khorne, Slann and Bretonnian are not available in two large FUMBBL divisions.\n",
    "\n",
    "# Dataprep Start: \n",
    "\n",
    "This creates again a dataframe that is double in size, `df_wins` because each match generates two rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make two copies, one for each team in the match\n",
    "team1_wins = df_matches[['match_id', 'match_date', 'team1_id', 'team1_coach_id', 'team1_race_name', 'team1_value', 'team1_win', 'tv_diff', 'tv_match', 'mirror_match']].copy()\n",
    "team2_wins = df_matches[['match_id', 'match_date',  'team2_id', 'team2_coach_id', 'team2_race_name', 'team2_value', 'team2_win', 'tv_diff', 'tv_match', 'mirror_match']].copy()\n",
    "\n",
    "team1_wins.columns = team2_wins.columns = ['match_id', 'match_date', 'team_id', 'coach_id', 'race_name', 'team_value', 'wins', 'tv_diff', 'tv_match', 'mirror_match']\n",
    "\n",
    "# combine both dataframes\n",
    "df_wins = pd.concat([team1_wins, team2_wins])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Match outcomes: How much is a draw worth?\n",
    "\n",
    "If we want to calculate a win rate for each race, we need to decide what to do with draws.\n",
    "I've never given the matter much thought, but it turns out other people have!\n",
    "\n",
    "For example, in football, there is a popular weighting scheme where wins are given 3 points, draws 1 point and losses 0 points.\n",
    "This is called [three points for a win](https://en.wikipedia.org/wiki/Three_points_for_a_win) . \n",
    "In Blood bowl leagues and tournaments, this rule is often used as well.\n",
    "So, if we want to predict which teams perform best in these settings (have the highest probability of winning a tournament), we need to weigh the match outcomes accordingly.\n",
    "\n",
    "However, in Blood Bowl data analysis, it seems that a 2:1:0 (W / D / L) weighting scheme is most commonly used. \n",
    "This scheme has the advantage that the weighted average win percentage over all matches is always 50%, creating a nice reference point allowing conclusions such as this and that team has an x percent above average win percentage.\n",
    "\n",
    "For example, Mike Davies from the NAF calculates win rate by weighting each win as 1 point, and each draw as 0.5 points (For example, [here](https://public.tableau.com/app/profile/mike.sann0638.davies/viz/NAFGames_0/SuccessBB2020)).\n",
    "\n",
    "So if we want to compare with others, it makes sense to adapt this scheme as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a dataset on the match-team level, lets prep the data a bit further.\n",
    "We add the half point for a draw in the `wins` column.\n",
    "\n",
    "And we create a team value bin to be able to compare win rates for teams that are hopefully more similar in team development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.loc[df_wins['wins'] == 0, 'wins'] = 0.5\n",
    "df_wins.loc[df_wins['wins'] == -1, 'wins'] = 0\n",
    "\n",
    "# convert to float\n",
    "df_wins['wins'] = df_wins['wins'].astype(float)\n",
    "\n",
    "df_wins['tv_bin'] = pd.cut(df_wins['tv_match'], [0, 950, 1250,1550, 1850, float(\"inf\")], labels=['< 950', '1.1K', '1.4K', '1.7K', '> 1850'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, Lets have a look at our dataset again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins.query('team_value > 1000 & team_value < 1020')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! Almost there. There is still something missing though, we need to know, for all the teams in our matches dataset, in what division or league they are playing, and what version of the rules they use. For these we turn to the API again, to fetch more data, now on the team level.\n",
    "\n",
    "# Step 2: Fetch data on team division and ruleset\n",
    "\n",
    "Let grab for all teams in `df_wins` the team **division** and **ruleset**.\n",
    "\n",
    "A limitation of the API is that it shows only the latest version of the teams and leagues.  This hides the fact that leagues have changed their rules since they were first created. For example, the NAF used BB2016 rules up until summer of 2021, and thereafter switched to the new BB2020 ruleset for their latest online tournament.\n",
    "So we have to use our \"domain knowledge\" here to interpret the data properly.\n",
    "\n",
    "**Note to self**: contact Christer suggesting change to freeze rulesets as soons as matches have been played with them.\n",
    "And force users to create new rulesets if they want to update / change previous rulesets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make list of all teams that need to be fetched\n",
    "team_ids = list(df_wins.query('match_id < 4339205')['team_id'].dropna())\n",
    "\n",
    "# get unique values by converting to a Python set and back to list\n",
    "team_ids = list(set(team_ids))\n",
    "\n",
    "len(team_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_team_ids = list(df_wins.query('match_id >= 4339205')['team_id'].dropna())\n",
    "team_ids = list(set(new_team_ids) - set(team_ids)) \n",
    "len(team_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have to fetch data for 43+4K different teams. \n",
    "\n",
    "We use the same approach as above, looping over all `team_id` 's and making a separate API call for each team.\n",
    "\n",
    "**IMPORTANT: here too, we limit ourselves to a maximum of 3 API calls per second to avoid overloading the FUMBBL server**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_teams = pd.DataFrame(columns=['team_id', 'division_id', 'division_name',  'league' ,\n",
    "    'ruleset', 'roster_id', 'race_name',  'games_played'])\n",
    "\n",
    "target = 'data/df_teams_' + time.strftime(\"%Y%m%d_%H%M%S\") + '.h5'\n",
    "print(target)\n",
    "\n",
    "fullrun = 0\n",
    "\n",
    "if fullrun:\n",
    "    print('fetching team data for ', len(team_ids), ' teams')\n",
    "    for t in range(len(team_ids)):    \n",
    "        api_string = \"https://fumbbl.com/api/team/get/\" + str(int(team_ids[t]))\n",
    "        wait_time = (random.uniform(0.5, 1) + 0.25)/3\n",
    "        time.sleep(wait_time)\n",
    "        team = requests.get(api_string)\n",
    "        team = team.json()\n",
    "        # grab fields\n",
    "        team_id = team['id']\n",
    "        division_id = team['divisionId']\n",
    "        division_name = team['division']\n",
    "        ruleset = team['ruleset']\n",
    "        league = team['league']\n",
    "        roster_id = team['roster']['id']\n",
    "        race_name = team['roster']['name']\n",
    "        games_played = team['record']['games']\n",
    "        # add to dataframe\n",
    "        df_teams.loc[t] = [team_id, division_id, division_name, league, ruleset, roster_id, race_name, games_played]\n",
    "        if t % 100 == 0: \n",
    "            # write tmp data as hdf5 file\n",
    "            print(t, end='')\n",
    "            print(\".\", end='')\n",
    "            df_teams.to_hdf(target, key='df_teams', mode='w')\n",
    "    \n",
    "    df_teams.to_hdf(target, key='df_teams', mode='w')\n",
    "else:\n",
    "    # read from hdf5 file\n",
    "    df_teams1 = pd.read_hdf('data/df_teams_20211030_115137.h5')\n",
    "    df_teams2 = pd.read_hdf('data/df_teams_20211202_222458.h5')\n",
    "    df_teams = pd.concat([df_teams1, df_teams2], ignore_index=True)\n",
    "\n",
    "\n",
    "df_teams['roster_name'] = df_teams['roster_id'].astype(str) + '_' + df_teams['race_name']\n",
    "\n",
    "df_teams.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting the divisions and leagues to analyse\n",
    "\n",
    "FUMBBL allows coaches to create their own rulesets to play their own leagues and tournaments with. For example, there is a so-called \"Secret League\" where coaches can play with \"Ninja halflings\", of with \"Ethereal\" spirits etc. \n",
    "\n",
    "Since we want the team strength for the official rulesets BB2016 and BB2020, we need to drop the matches that are played under different rules.\n",
    "\n",
    "Lets have look at the various divisions and leagues, which rulesets are used, and which races are played how often.\n",
    "There are a lot of small leagues being played on FUMBBL, they account for maybe X% of all the matches.\n",
    "\n",
    "We only look at divisions and leagues with a sufficient volume of matches, or otherwise we do not have sufficient statistics for each race.\n",
    "\n",
    "So I aggregated the data by division, league and ruleset, and filtered on at least 150 different teams that have played at least once last year.\n",
    "Apart from the main \"Divisions\" that are part of FUMBBL, there were a few user-run leagues present in this table, so I looked up their names on FUMBBL and what ruleset is used (BB2016, BB2020 or some other variant). This information (contained in an xlsx) is added to the dataset below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add ruleset_version and division_name from xlsx\n",
    "ruleset_division_names = pd.read_excel('data/ruleset_division_names.xlsx',  engine='openpyxl')\n",
    "\n",
    "df_teams = pd.merge(df_teams, ruleset_division_names, on= ['league', 'ruleset', 'division_id'], how='left')\n",
    "\n",
    "df_teams['division_name'] = df_teams['new_division_name']\n",
    "\n",
    "df_teams = df_teams.drop('new_division_name', 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_teams\n",
    "    .groupby(['ruleset', 'league', 'division_id', 'division_name',  'ruleset_version'], dropna=False)\n",
    "    .agg( n_teams = ('ruleset', 'count')\n",
    "    )\n",
    "    .sort_values('n_teams', ascending = False)\n",
    "    .query('n_teams > 150')['n_teams']\n",
    "    .reset_index()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are primary interested in the new BB2020 ruleset version. We see that apart from the new **Competitive** division of FUMBBL itself, already a few user run leagues have started to use BB2020 rules. However, I chose to not include these leagues in the comparison: \n",
    "\n",
    "* Both NAF and Lega Gladio tournaments consist of a mix of BB2016 and BB2020 matches, making these more difficult to analyse. \n",
    "* Then there is the Secret League, which is different because of all the extra teams available there. \n",
    "* Test Open League BB2020 has likely been the test group before the Competitive Division became available.\n",
    "\n",
    "The NAF tournaments current ruleset is interesting, because it introduces (for the first time) tiers in FUMBBL!\n",
    "The NAF online tournament allows coaches to distribute a fixed number of skills, depending on the team's tier.\n",
    "This makes match outcomes in this league less comparable to other divisions on FUMBBL.\n",
    "\n",
    "Then on to the BB2016 ruleset. Here we have three big FUMBBL divisions: Blackbox, Ranked and (regular) League.\n",
    "Blackbox and Ranked use ruleset 1. FUMBBL has a nice display of a rulesets, see e.g. here for [ruleset 1](https://fumbbl.com/p/ruleset?id=1). Comparing this ruleset to the ruleset used in the BB2016 regular league, we find a few small differences: e.g. the latter has the special play cards, has a few extra teams available (e.g. Simyin), but does not allow for wizards and does not the use the expensive mistakes rule.\n",
    "\n",
    "To get sufficient observations for all the 25+ teams, we need at least a few thousands matches played.\n",
    "\n",
    "So we end up with comparing\n",
    "\n",
    "* Competitive BB2020\n",
    "\n",
    "VERSUS\n",
    "\n",
    "* Ranked BB2016\n",
    "* Black box BB2016\n",
    "* standard BB2016 League division (ruleset 6 / league 0)\n",
    "\n",
    "If the differences between these three division can be considered to be small, we can pool the matches from these three leagues to get better statistics.\n",
    "So lets compare win rates between these three divisions. To do so we add the division information to the `df_wins` data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep: Merging the match data with the team / ruleset data and team tiers\n",
    "\n",
    "For each match in the `df_wins` **DataFrame** we can now add the team-level information from `df_teams`.\n",
    "We also add the team tiers we used for the NAF dataset.\n",
    "As both datasets contain 'race_name', we drop one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins = pd.merge(df_wins, df_teams.drop('race_name', 1), on='team_id', how='left')\n",
    "\n",
    "# 66 empty matches: we drop these\n",
    "df_wins = df_wins.dropna(subset=['match_date'])\n",
    "\n",
    "# add bb2020 tiers\n",
    "df_wins = pd.merge(df_wins, race_tiers, on='race_name', how='left')\n",
    "\n",
    "df_wins['team_id'] = pd.to_numeric(df_wins.team_id) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep: getting the dates right\n",
    "\n",
    "To see time trends, its useful to aggregate the data by week. For this we add a week number for each date, and from this week number, we convert back to a date to get a week_date. This last part is useful for plotting with `plotnine`, as this treats dates in a special way (PM how)\n",
    "We use the ISO definition of week, this has some unexpected behavior near the beginning / end of each year. \n",
    "\n",
    "The data starts in week 36 (september) of 2020, and stops halfway week 44 in 2021. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wins['week_number'] = df_wins['match_date'].dt.isocalendar().week\n",
    "\n",
    "\n",
    "# cannot convert to np int64 becaues of missing values\n",
    "# cannot convert to 'int64'-dtype NumPy array with missing values. Specify an appropriate 'na_value' for this dtype.\n",
    "df_wins['week_number'] = df_wins['week_number'].astype('Int64')\n",
    "#df_wins['week_number'] = df_wins['week_number'].fillna(0).astype(np.int64)\n",
    "\n",
    "# add year based on match date (but want it based on match ISO week)\n",
    "df_wins['year'] = pd.DatetimeIndex(df_wins['match_date']).year\n",
    "\n",
    "# manual fix year for ISO week 2020-53 (2020 has 53 ISO weeks, including a few days in jan 2021)\n",
    "df_wins.loc[(df_wins['year'] == 2021) & (df_wins['week_number'] == 53), 'year'] = 2020\n",
    "\n",
    "df_wins['week_year'] = df_wins['year'].astype(str) + '-' + df_wins['week_number'].astype(str)\n",
    "\n",
    "df_wins['week_date'] = pd.to_datetime(df_wins['week_year'].astype(\"string\") + '-1', format = \"%Y-%U-%w\")\n",
    "\n",
    "# manual fix of week date (grrrr)\n",
    "df_wins.loc[(df_wins['week_date'] ==  '2021-01-04') & (df_wins['week_number'] == 53), 'week_date'] = pd.to_datetime('2020-12-31')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Fetching the inducements for all our matches using BeatifulSoup and Regular expressions\n",
    "\n",
    "I highly recommend [this tutorial](https://hackersandslackers.com/scraping-urls-with-beautifulsoup/) for a great introduction to `BeautifulSoup`.\n",
    "\n",
    "In addition, to clean up the scraped text, I used **re** (Regular expressions), part of the [Python standard library](https://docs.python.org/3/library/index.html) to extract the actual inducements from the text string that contains them.\n",
    "\n",
    "The next trick is to use `pandas` *Explode* method (similar to `separate_rows` in `tidyverse` R) to give each inducement its own row in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "df_inducements = pd.DataFrame(columns=['match_id', 'team1_inducements', 'team2_inducements', 'coach1_ranking', 'coach2_ranking'])\n",
    "\n",
    "target = 'data/df_inducements_' + time.strftime(\"%Y%m%d_%H%M%S\") + '.h5'\n",
    "print(target)\n",
    "\n",
    "end_match = 4216258  \n",
    "begin_match = 4216257\n",
    "n_matches = end_match - begin_match\n",
    "\n",
    "full_run = 0\n",
    "\n",
    "print(n_matches)\n",
    "\n",
    "if(full_run):\n",
    "    for i in range(n_matches):\n",
    "        match_id = end_match - i\n",
    "        api_string = \"https://fumbbl.com/FUMBBL.php?page=match&id=\" + str(match_id)\n",
    "        # wait 0.5 s on average between each GET call\n",
    "        wait_time = (random.uniform(0.5, 1) + 0.25)/2\n",
    "        time.sleep(wait_time)\n",
    "        response = requests.get(api_string)\n",
    "\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "        if soup.find(\"div\", {\"class\": \"matchrecord\"}) is not None:\n",
    "            # match record is available\n",
    "            inducements = soup.find_all(\"div\", class_=\"inducements\")\n",
    "\n",
    "            pattern = re.compile(r'\\s+Inducements: (.*)\\n')\n",
    "\n",
    "            match = re.match(pattern, inducements[0].get_text())\n",
    "            if match:\n",
    "                team1_inducements = match.group(1)\n",
    "            else:\n",
    "                team1_inducements = ''\n",
    "\n",
    "            match = re.match(pattern, inducements[1].get_text())\n",
    "            if match:\n",
    "                team2_inducements = match.group(1)\n",
    "            else:\n",
    "                team2_inducements = ''\n",
    "\n",
    "            coach_rankings = soup.find_all(\"div\", class_=\"coach\")\n",
    "\n",
    "            coach1_ranking = coach_rankings[0].get_text()\n",
    "            coach2_ranking = coach_rankings[1].get_text()\n",
    "\n",
    "            df_inducements.loc[i] = [match_id, team1_inducements, team2_inducements, coach1_ranking, coach2_ranking]\n",
    "\n",
    "        if i % 100 == 0: \n",
    "                    # write tmp data as hdf5 file\n",
    "                    print(i, end='')\n",
    "                    print(\".\", end='')\n",
    "                    df_inducements.to_hdf(target, key='df_inducements', mode='w')\n",
    "\n",
    "    # write data as hdf5 file\n",
    "    df_inducements.to_hdf(target, key='df_inducements', mode='w')\n",
    "else:\n",
    "    # read from hdf5 file\n",
    "    \n",
    "    df_inducements0 = pd.read_hdf('data/df_inducements_20211210_094223.h5')\n",
    "    df_inducements1 = pd.read_hdf('data/df_inducements_20211209_085450.h5')\n",
    "    df_inducements2 = pd.read_hdf('data/df_inducements_20211209_234850.h5')\n",
    "    df_inducements3 = pd.read_hdf('data/df_inducements_20211210_164630.h5')\n",
    "    df_inducements4 = pd.read_hdf('data/df_inducements_20211211_124503.h5')\n",
    "    df_inducements5 = pd.read_hdf('data/df_inducements_20211211_234148.h5')\n",
    "   \n",
    "    df_inducements = pd.concat([df_inducements0, df_inducements1, df_inducements2, df_inducements3, df_inducements4, df_inducements5], ignore_index = True)\n",
    "    \n",
    "\n",
    "df_inducements[\"match_id\"].min() # moeten tot 4216258, missen 4216258\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PM AS THIS ADDS INFO FOR EACH MATCH, FOR EACH TEAM separately, we have to add this to df_matches, AND THEN FROM THERE create the df_wins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep inducements (and coach rankings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "team1_inducements = df_inducements[['match_id', 'team1_inducements']]\n",
    "team2_inducements = df_inducements[['match_id', 'team2_inducements']]\n",
    "\n",
    "# make column names equal\n",
    "team1_inducements.columns = team2_inducements.columns = ['match_id', 'inducements']\n",
    "\n",
    "# row bind the two dataframes\n",
    "inducements = pd.concat([team1_inducements, team2_inducements], ignore_index = True)\n",
    "\n",
    "# convert comma separated string to list\n",
    "inducements['inducements'] = inducements['inducements'].str.split(',')\n",
    "\n",
    "# make each element of the list a separate row\n",
    "inducements = inducements.explode('inducements')\n",
    "\n",
    "# strip leading and trailing whitespaces\n",
    "inducements['inducements'] = inducements['inducements'].str.strip()\n",
    "\n",
    "# create \"star player\" label\n",
    "inducements['star_player'] = 0\n",
    "inducements.loc[inducements['inducements'].str.contains(\"Star player\"), 'star_player'] = 1\n",
    "\n",
    "# create \"card\" label\n",
    "inducements['special_card'] = 0\n",
    "inducements.loc[inducements['inducements'].str.contains(\"Card\"), 'special_card'] = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What to do with multiples? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add inducement info to df_matches and df_wins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches = pd.merge(df_matches, df_inducements, on='match_id', how='left')\n",
    "\n",
    "df_sp = (inducements\n",
    "            .groupby(\"match_id\")\n",
    "            .agg(has_sp = (\"star_player\", \"max\"))\n",
    "            .reset_index()\n",
    ")\n",
    "\n",
    "\n",
    "df_wins = pd.merge(df_wins, df_sp, on = \"match_id\", how = \"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprep: coach rankings\n",
    "\n",
    "We want to extract the part `CR 152.53` from the scraped coach information field. Just as we matches on `Inducements:`, we can match on `CR ` and grab the contents directly after that, stopping when we encounter a whitespace.\n",
    "We use the `extract` method from `pandas` to extract the string vector-wise and assign it as a new column in the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pattern = re.compile(r'\\s+Inducements: (.*)\\n')\n",
    "pattern = re.compile(r'.*CR (.*)\\s\\(.*')\n",
    "\n",
    "match = re.match(pattern, df_inducements.loc[0, 'coach2_ranking'])\n",
    "\n",
    "if match is not None:\n",
    "    print(match.group(1)) # group(0) is the whole string\n",
    "else:\n",
    "    print(\"match is none\")\n",
    "#df_inducements['coach1_CR'] = \n",
    "df_inducements.loc[0, 'coach2_ranking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataprep: add the coach rankings\n",
    "df_inducements['coach1_CR'] = df_inducements['coach1_ranking'].str.extract(r'.*CR (.*)\\s\\(.*')\n",
    "df_inducements['coach2_CR'] = df_inducements['coach2_ranking'].str.extract(r'.*CR (.*)\\s\\(.*')\n",
    "\n",
    "df_inducements['coach1_CR'] = pd.to_numeric(df_inducements['coach1_CR'])\n",
    "df_inducements['coach2_CR'] = pd.to_numeric(df_inducements['coach2_CR'])\n",
    "\n",
    "df_inducements['CR_diff'] = np.abs(df_inducements['coach1_CR'] - df_inducements['coach2_CR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inducements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Coach ranking info to df_matches and df_wins\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches = pd.merge(df_matches, df_inducements[['match_id', 'coach1_CR', 'coach2_CR']], on='match_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches['CR_diff'] = np.abs(df_matches['coach1_CR'] - df_matches['coach2_CR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matches.query(\"match_id == 4216260\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding to df_wins\n",
    "\n",
    "PM have both coaches for each row."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save all four prepped datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PM\n",
    "df_matches\n",
    "df_wins\n",
    "df_teams\n",
    "df_inducements"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "50276fd1884268afe39607052f22ef19b84d915691d702a5c7e9a67a09867105"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit ('requests_env': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
