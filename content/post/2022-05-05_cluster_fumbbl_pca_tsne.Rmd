---
title: 'Cluster analysis of Blood Bowl teams using FUMBBL data in R: PCA vs T-SNE'
author: "Gertjan Verhoeven"
date: '2022-05-05'
summary: This blog post compares two unsupervised learning methods to learn which Blood Bowl teams cluster together if we look at various match related metrics from FUMBBL such as scoring, injuries, passes and blocks.
slug: blood-bowl-cluster-analysis
draft: yes
categories:
- Blood Bowl
- Machine Learning
- Clustering
- Unsupervised learning
tags:
- t-sne
- pca
baseurl: https://gsverhoeven.github.io
header:
  image: headers/wilhelm-gunkel-di8ognBauG0-unsplash.png
  preview: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Load packages

```{r}
library(tidyverse)
library(ggfortify)
library(ggrepel)
```

# Read in the FUMBBL data

```{r}
df_mbt <- read.csv(file = "../../../fumbbl_datasets/datasets/current/df_mbt.csv")

race_types <- unique(df_mbt %>% select(race_name, race_type))

```

```{r}
df_mbt %>% 
  filter(division_name == "Blackbox") %>%
  saveRDS("fumbbl_cluster/blackbox.rds")

df_mbt %>% 
  filter(division_name == "Competitive") %>%
  saveRDS("fumbbl_cluster/competitive.rds")

df_mbt %>% 
  filter(division_name == "Ranked") %>%
  saveRDS("fumbbl_cluster/ranked.rds")

df_mbt %>% 
  filter(division_name == "Regular_league") %>%
  filter(race_name != "Treeman") %>%
  filter(race_name != "Simyin") %>%
  saveRDS("fumbbl_cluster/league.rds")
```


Make four selections of datasets. Try the purrr code.

```{r eval = F}
data_dir <- c("fumbbl_cluster/")

league_data <- c("Competitive" = "competitive.rds", "Blackbox" = "blackbox.rds", 
                 "Ranked" = "ranked.rds", "League" = "league.rds")

read_and_clean <- function(path) {
  readRDS(str_c(data_dir, path))
}

data_tables <- map(league_data, read_and_clean)

select_stats <- function(df) {
  df %>% 
  select(race_name, race_type, team_score, away_team_score:away_cas_rip) %>%
  select(-(home_cas_bh:home_cas_rip), -(away_cas_bh:away_cas_rip))
}

data_tables <- map(data_tables, select_stats)

data_tables$Competitive %>% colnames()


```
Suppose we want to compare the 25+ Blood Bowl races on their match statistics with each other, and see which races have comparable stats.
If we have only one statistic, it is easy: we can just plot the races on a horizontal line and see which races are closest by.

Lets do that for number of blocks made:

```{r}
res <- data_tables$Competitive %>% group_by(race_name, race_type) %>% summarise(avg_block = mean(home_block), size = n())
ggplot(res, aes(x = avg_block, y = 0, size = size, col = race_type)) +
         geom_point() +
scale_size_area()
```
But races can be similar if we look at blocks, but dissimilar if we look at e.g. passing. So lets add passing on the y axis.

```{r}
res <- data_tables$Competitive %>% group_by(race_name, race_type) %>% summarise(avg_block = mean(home_block), avg_pass = mean(abs(home_pass)), size = n())

ggplot(res, aes(x = avg_block, y = avg_pass, size = size, col = race_type)) +
         geom_point() +
  scale_size_area() +
  expand_limits(y=-0.5) +
  geom_label_repel(aes(label = race_name), size  = 2)
  

```
If we look at the Human race, this plot suggests that it is more similar to Imperial Nobility and Old World Alliance, than it is to Skaven.
Although Human has the same average passing distance as Skaven (which is surprisingly short, as there are a lot of 0 distance passes), the number of blocks for Skaven is much lower, and thus if we compare on both statistics, Imperial Nobility and OWA win out.

Now with two statistics, we can simply plot them and calculate a distance between all points.
What if we have more than two statistics? E.g. we have 5 statistics? We have too many dimensions to plot.
For these there exists so-called dimension reduction techniques.
In this blog post we'll examine two of them.

So we have for each combination of race and performance statistic (touchdowns, blocks etc) a value.
We can now either try to group the performance variables, this is about correlations between variables. Which variables are related to each other? 
This produces things like a correlation network graph. This is a poor mans factor analysis.
Alternatively, we can try to group the races: which races are close by? This is cluster analysis.
How can this be different whereas we simply can flip the dataset and have races as columns and performance stats as rows?

# Selecting variables to include

The nufflytics blog post has a somewhat surprising selection of match statistics.
For example, the number of inflicted touchdowns is selected, but not the number of sustained touchdowns.

# Blood Bowl 2 performance statistics

The Cyanide Blood Bowl 2 API (not publicly accessible) apparently offers the following stats for each match, for both teams:

Scoring related:

* Ball occupation (not available in FUMBBL)
* Touchdowns
* Meters running (rushes)

Blocking related:

* Casualties
* Knock outs
* Injuries
* Dead

Passing related:

* Interceptions (not available in FUMBBL)
* Meters passing (passing yards)
* Passes (completions)

Fouling related:

* Expulsions (sent off players after fouling)
* FUMBBL: fouls (not available in BB2 API)

Other:

* Tackles

# Simulated data

He mentions that each match generates two data points, one for each team.

If we include all stats for both the home and away team, something peculiar happens:
The principal components are exactly opposite.

```{r}
set.seed(123)
home_score <- rpois(n = 10000, lambda = 1)
away_score <- rpois(n = 10000, lambda = 1)

df <- rbind(data.frame(home_score, away_score), 
            data.frame(home_score = away_score, away_score = home_score))

PCA <-  df %>% 
    as.matrix() %>% 
    prcomp(scale = T)
PCA
```

```{r}
round(PCA$sdev^2/sum(PCA$sdev^2)*100,1)
```

```{r}
autoplot(PCA, loadings = TRUE, loadings.label = TRUE)
```
Can we fix this by selecting at random one team for each match?

```{r}
set.seed(123)
sel_vec <- rbinom(n = 10000, size = 1, p = 0.5)

sel_vec <- c(sel_vec, 1 -  sel_vec)


```


```{r}
PCA <- df[sel_vec == 1,] %>% 
    as.matrix() %>% 
    prcomp(scale = T)
PCA
```
```{r fig.height = 4, fig.width = 4}
autoplot(PCA, loadings = TRUE, loadings.label = TRUE)
```

```{r}
cor(df$home_score, df$away_score)
```
The scores are completely uncorrelated, even with the duplicate "mirror" matches included.

# Select for each match only one team at random

```{r}
set.seed(123)
sel_vec <- rbinom(n = nrow(df_mbt)/2, size = 1, p = 0.5)

sel_vec <- c(sel_vec, 1 -  sel_vec)

  
# check if it works
df_mbt2 <- df_mbt[sel_vec == 1,]
df_mbt2 <- df_mbt2 %>% filter(match_id != 4239544)
```

We leave out the cas breakdown in badly hurt, injured and dead, since this biases the analysis strongly to differences in Armor value.

# Analysis

```{r}
run_pca <- function(df) {
  df %>% 
    select(-race_name, -race_type) %>% 
    as.matrix() %>% 
    prcomp(scale = T)
}

PCAs <- map(data_tables, run_pca)
```

```{r}
PCAs[[1]]
```

```{r}
autoplot(PCAs[1], loadings = TRUE, loadings.label = TRUE)
```

```{r}
round(PCA$sdev^2/sum(PCA$sdev^2)*100,1)
```
The first two components explain 33% of variation in the match statistics.
The more variables we include, the lower the first components explain variation.

```{r}
cbind(as_data_frame(PCAs[[1]]$x), race = data_tables[[1]]$race_name) %>% 
  ggplot(aes(x = PC1, y = -1*PC2, colour = factor(race) %>% forcats::fct_reorder2(PC1, PC2, sum))) +
  geom_point(alpha = 0.5) +
  theme(legend.position = "none") +
  ggtitle("PCA", "FUMBBL")
```
```{r fig.width= 16, fig.height = 16}
plot_pca <- function(pca, data, flip_x = 1, flip_y = 1, league) { 
  cbind(data.frame(pca$x), race = data$race_name, race_type = data$race_type) %>% 
    group_by(race) %>% 
    summarise(PC1 = median(PC1)*flip_x, 
              PC2 = median(PC2)*flip_y, 
              count = n()) %>% 
    left_join(race_types, by = c("race" = "race_name")) %>%
    ggplot(aes(PC1, PC2, label = race, colour = factor(race_type))) +
      geom_point(aes(size = count), alpha = 0.4) +
      ggrepel::geom_text_repel(size = 4, point.padding = unit(0.05, "lines")) + 
      theme(legend.position = "none") +
      ggtitle(league) +
      scale_x_continuous(expand = c(0.2,0))+
      scale_y_continuous(expand = c(0.2,0))
}

# do a parallel map over multiple inputs (lists)
plots = pmap(.l = list(PCAs, data_tables, 
                       flip_x = c(-1,-1,1,-1), 
                       flip_y = c(1,1,-1,1), 
                       names(league_data)), 
             .f = plot_pca)

cowplot::plot_grid(plotlist = plots)
```

# back to the data

```{r}
res <- data_tables$Competitive %>%
  mutate(pc1 = PCAs[[1]]$x[,1]) %>%
  group_by(race_name) %>%
  select(where(is.numeric)) %>%
  summarise(across(everything(), mean)) %>%
  arrange(-home_block)

View(res)
```



# T-SNE

Swiss Roll (Geron book)
https://jlmelville.github.io/smallvis/swisssne.html

https://members.loria.fr/moberger/Enseignement/AVR/Exposes/TR_Dimensiereductie.pdf

Jesse Krijthe created an R package that "wraps" around the C++ code of Laurens van der Maaten.
t-distributed Stochastic Nearest Neighbour Embedding (T-SNE) needs some serious computation that scales unfavourably with the size of the dataset. There are various tricks to reduce computation. A Tree model is built to find 3 * perplexity nearest neighbours, ignoring the rest. The Barnes-Hutt approximation is controlled by the $theta$ parameter. To help the algorithm an initial PCA step is also computed.

A high perplexity means that a lot of nearest neighbours are taken into account. This means that the higher this parameter, the more the clustering resembles the global structure, i.e. how ALL datapoints relate to each other.

```{r}
library(Rtsne)

set.seed(1234)

## 15 min

TSNE <-  data_tables$Blackbox %>% 
    select(-race_name, -race_type) %>% 
    as.matrix() %>% 
    Rtsne(check_duplicates = FALSE, pca = TRUE, perplexity=50, max_iter = 1000, theta=0.5, dims=2, verbose = TRUE, num_threads = 2 )
```

```{r fig.height = 5, fig.width = 7}
flip_x <- -1
flip_y <- 1

cbind(data.frame(TSNE$Y), race = df_pca$race_name, race_type = df_pca$race_type) %>% 
    group_by(race) %>% 
    summarise(PC1 = median(X1)*flip_x, PC2 = median(X2)*flip_y, count = n()) %>% 
    left_join(race_types, by = c("race" = "race_name")) %>%
     ggplot(aes(PC1, PC2, label = race, colour = factor(race_type))) +
    geom_point(aes(size = count), alpha = 0.4) +
    ggrepel::geom_text_repel(size = 3, point.padding = unit(0.05, "lines")) + 
    #theme(legend.position = "none") +
    ggtitle("FUMBBL t-sne clustering") +
    scale_x_continuous(expand = c(0.2,0)) +
    scale_y_continuous(expand = c(0.2,0))
```
Interestingly, the non-linear clustering has placed Black Orc close to Lizardmen, which sort of makes sense given the similarities between both teams. The big difference is in fouling, and that is only one characteristic of the 14 included.

Khorne is close to humans and Chaos Renegade.

This suggests that the new teams are not typed properly by me.
Ogre should be stunty as well.

