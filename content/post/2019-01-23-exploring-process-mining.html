---
title: Exploring Process Mining in R
author: Gertjan Verhoeven
date: '2019-06-20'
summary: In this post, we'll explore the BupaR suite of Process Mining packages created by Gert Janssenswillen of Hasselt University.
slug: exploring-process-mining
draft: FALSE
categories:
  - R
tags:
  - process mining
baseurl: "https://gsverhoeven.github.io"
header:
  image: "headers/ceiling-clean-clinic-247786.jpg"
  preview: FALSE

---



<p>In this post, we’ll explore the <a href="https://www.bupar.net">BupaR</a> suite of <em>Process Mining</em> packages created by <em>Gert Janssenswillen</em> from Hasselt University.</p>
<p>We start with exploring the <code>patients</code> dataset contained in the <code>eventdataR</code> package. According to the documentation, this is an “Artifical eventlog about patients”.</p>
<div id="getting-started" class="section level1">
<h1>Getting started</h1>
<p>After installing all required packages, we can load the whole “bupaverse” by loading the <code>bupaR</code> package.</p>
<pre class="r"><code>library(ggplot2)
library(bupaR)</code></pre>
<pre><code>## Warning in library(package, lib.loc = lib.loc, character.only = TRUE,
## logical.return = TRUE, : there is no package called &#39;xesreadR&#39;</code></pre>
<pre><code>## Warning in library(package, lib.loc = lib.loc, character.only = TRUE,
## logical.return = TRUE, : there is no package called &#39;processmonitR&#39;</code></pre>
<pre><code>## Warning in library(package, lib.loc = lib.loc, character.only = TRUE,
## logical.return = TRUE, : there is no package called &#39;petrinetR&#39;</code></pre>
<pre class="r"><code>library(processmapR)</code></pre>
<p>Now, our dataset is already in <code>eventlog</code> format, but typically this not the case.
Here’s how to turn a data.frame into an object of class <code>eventlog</code>:</p>
<pre class="r"><code>patients &lt;- eventdataR::patients

df &lt;- eventlog(patients,
               case_id = &quot;patient&quot;,
               activity_id = &quot;handling&quot;,
               activity_instance_id = &quot;handling_id&quot;,
               lifecycle_id = &quot;registration_type&quot;,
               timestamp = &quot;time&quot;,
               resource_id = &quot;employee&quot;)</code></pre>
<p>Let’s check it out.</p>
<pre class="r"><code>summary(df)</code></pre>
<pre><code>## Number of events:  5442
## Number of cases:  500
## Number of traces:  7
## Number of distinct activities:  7
## Average trace length:  10.884
## 
## Start eventlog:  2017-01-02 11:41:53
## End eventlog:  2018-05-05 07:16:02</code></pre>
<pre><code>##                   handling      patient          employee  handling_id       
##  Blood test           : 474   Length:5442        r1:1000   Length:5442       
##  Check-out            : 984   Class :character   r2:1000   Class :character  
##  Discuss Results      : 990   Mode  :character   r3: 474   Mode  :character  
##  MRI SCAN             : 472                      r4: 472                     
##  Registration         :1000                      r5: 522                     
##  Triage and Assessment:1000                      r6: 990                     
##  X-Ray                : 522                      r7: 984                     
##  registration_type      time                         .order    
##  complete:2721     Min.   :2017-01-02 11:41:53   Min.   :   1  
##  start   :2721     1st Qu.:2017-05-06 17:15:18   1st Qu.:1361  
##                    Median :2017-09-08 04:16:50   Median :2722  
##                    Mean   :2017-09-02 20:52:34   Mean   :2722  
##                    3rd Qu.:2017-12-22 15:44:11   3rd Qu.:4082  
##                    Max.   :2018-05-05 07:16:02   Max.   :5442  
## </code></pre>
<p>So we learn that there are 500 “cases”, i.e. patients. There are 7 different activities.</p>
<p>Let’s check out the data for a single patient:</p>
<pre class="r"><code>df %&gt;% filter(patient == 1) %&gt;% 
  arrange(handling_id) #%&gt;% </code></pre>
<pre><code>## Log of 12 events consisting of:
## 1 trace 
## 1 case 
## 6 instances of 6 activities 
## 6 resources 
## Events occurred from 2017-01-02 11:41:53 until 2017-01-09 19:45:45 
##  
## Variables were mapped as follows:
## Case identifier:     patient 
## Activity identifier:     handling 
## Resource identifier:     employee 
## Activity instance identifier:    handling_id 
## Timestamp:           time 
## Lifecycle transition:        registration_type 
## 
## # A tibble: 12 x 7
##    handling patient employee handling_id registration_ty… time               
##    &lt;fct&gt;    &lt;chr&gt;   &lt;fct&gt;    &lt;chr&gt;       &lt;fct&gt;            &lt;dttm&gt;             
##  1 Registr… 1       r1       1           start            2017-01-02 11:41:53
##  2 Registr… 1       r1       1           complete         2017-01-02 12:40:20
##  3 Blood t… 1       r3       1001        start            2017-01-05 08:59:04
##  4 Blood t… 1       r3       1001        complete         2017-01-05 14:34:27
##  5 MRI SCAN 1       r4       1238        start            2017-01-05 21:37:12
##  6 MRI SCAN 1       r4       1238        complete         2017-01-06 01:54:23
##  7 Discuss… 1       r6       1735        start            2017-01-07 07:57:49
##  8 Discuss… 1       r6       1735        complete         2017-01-07 10:18:08
##  9 Check-o… 1       r7       2230        start            2017-01-09 17:09:43
## 10 Check-o… 1       r7       2230        complete         2017-01-09 19:45:45
## 11 Triage … 1       r2       501         start            2017-01-02 12:40:20
## 12 Triage … 1       r2       501         complete         2017-01-02 22:32:25
## # … with 1 more variable: .order &lt;int&gt;</code></pre>
<pre class="r"><code> # select(handling, handling_id, registration_type) # does not work</code></pre>
<p>We learn that each “handling” has a separate start and complete timestamp.</p>
</div>
<div id="traces" class="section level1">
<h1>Traces</h1>
<p>The summary info of the event log also counts so-called “traces”. A trace is defined a unique sequence of events in the event log. Apparently, there are only seven different traces (possible sequences). Let’s visualize them.</p>
<p>To visualize all traces, we set <code>coverage</code> to 1.0.</p>
<pre class="r"><code>df %&gt;% processmapR::trace_explorer(type = &quot;frequent&quot;, coverage = 1.0)</code></pre>
<p><img src="/post/2019-01-23-exploring-process-mining_files/figure-html/unnamed-chunk-5-1.png" width="672" />
So there are a few traces (0.6%) that do not end with a check-out.
Ignoring these rare cases, we find that there are two types of cases:</p>
<ul>
<li>Cases that get an X-ray</li>
<li>Cases that get a blood test followed by an MRI scan</li>
</ul>
</div>
<div id="the-dotted-chart" class="section level1">
<h1>The dotted chart</h1>
<p>A really powerful visualization in process mining comes in the form of a “dotted chart”. The dotted chart function produces a <code>ggplot</code> graph, which is nice, because so we can actually tweak the graph as we can with regular ggplot objects.</p>
<p>It has two nice use cases.
The first is when we plot actual time on the x-axis, and sort the cases by starting date.</p>
<pre class="r"><code>df %&gt;% dotted_chart(x = &quot;absolute&quot;, sort = &quot;start&quot;) + ggtitle(&quot;All cases&quot;) +
  theme_gray()</code></pre>
<pre><code>## Joining, by = &quot;patient&quot;</code></pre>
<p><img src="/post/2019-01-23-exploring-process-mining_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<p>The slope of this graphs learns us the rate of new cases, and if this changes over time. Here it appears constant, with 500 cases divided over five quarter years.</p>
<p>The second is to align all cases relative to the first event, and sort on duration of the whole sequence of events.</p>
<pre class="r"><code>df %&gt;% dotted_chart(x = &quot;relative&quot;, sort = &quot;duration&quot;) + ggtitle(&quot;All cases&quot;) +
  theme_gray()</code></pre>
<pre><code>## Joining, by = &quot;patient&quot;</code></pre>
<p><img src="/post/2019-01-23-exploring-process-mining_files/figure-html/unnamed-chunk-7-1.png" width="672" /></p>
<p>A nice pattern emerges, where all cases start with registration, then quickly proceed to triage and assessment, after that, a time varying period of 1-10 days follows where either the blood test + MRI scan, or the X-ray is performed, followed by discussing the results. Finally, check out occurs.</p>
</div>
<div id="conclusion" class="section level1">
<h1>Conclusion</h1>
<p>To conclude, the process mining approach to analyze time series event data appears highly promising. The dotted chart is a great addition to my data visualization repertoire, and the process mining folks appear to have at lot more goodies, such as Trace Alignment.</p>
</div>
