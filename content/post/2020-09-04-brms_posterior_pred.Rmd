---
title: The posterior distribution of an average treatment effect in Stan using brms::posterior_predict()
author: Gertjan Verhoeven & Misja Mikkers
date: '2020-09-04'
summary: Here we show how to calculate the posterior distribution of the adjusted average treatment effect for the covariates of a particular population using Stan & brms. 
slug: posterior-distribution-average-treatment-effect
draft: FALSE
categories:
  - R
tags:
  - brms, ate, causal effect, bayesian statistics
baseurl: "https://gsverhoeven.github.io"
header:
  image: "headers/treatment.png"
  preview: FALSE
---

# Introduction

Suppose we have data from a Randomized Controlled Trial (RCT). Patients get treated, or not, depending only on a coin flip.
The outcome is a count variable, such as the number of times the patient gets admitted to the hospital.
The treatment is expected to reduce the number of hospital admissions for patients.

Suppose further that after we fitted the data, we want to now what would have happened if we had treated ALL the patients in the sample, versus if no patient in the sample would have received treatment.

Well, that is easy, we just take the fitted model, change treatment from zero to one, and observe the effect on the outcome, right?

Yes, but the uncertainty is harder. We have uncertainty in the estimated effect of the intercept and covariate, as well us in the treatment variable. And these uncertainties can be correlated (for example between the coefficients of intercept and covariate)

Here we show how to use `posterior_predict()` to simulate outcomes of the model for the sampled parameters.
If we do this for two counterfactuals, all patients treated, and all patients untreated, and subtract these, we can easily calculate the posterior distribution of the average treatment effect!

# Packages

```{r, message = TRUE, warning = TRUE}
library(tidyverse)
library(rstan)
library(brms) 
```

# Data simulation

```{r}
set.seed(123)     

id <- 1:200   
n_obs <- length(id)
t_eff <- 0.7
p_eff <- 0.1

df_sim <- as.data.frame(id) %>% 
mutate(Predictor = rgamma(n_obs, shape = 5, scale = 2)) %>% # positive cont predictor
mutate(Error = rnorm(n_obs, mean = 0, sd = 2)) %>% # add noise
mutate(Treatment = ifelse(runif(n_obs) < 0.5, 0, 1)) %>% # Flip a coin for treatment
mutate(Lambda = exp(p_eff * Predictor - t_eff * Treatment)) %>% # generate lambda for the poisson dist
mutate(Admissions = rpois(n_obs, lambda = Lambda))

```


# Summarize data

```{r}
summary(df_sim)
```

The Treatment variable should reduce admissions.
Lets visualize the distribution of Admission values for both treated and untreated patients:

```{r, warning=FALSE}
ggplot(data = df_sim, aes(x = Admissions)) +
  geom_histogram(stat="count") +
  facet_wrap(~ Treatment) + 
  theme_bw()
```

The effect of the treatment is clearly visible. Now lets fit our Bayesian Poisson model to it.

# Fit model

```{r}
model1 <- brm(
  formula = as.integer(Admissions) ~  Predictor + Treatment,
   data = df_sim,
  family = poisson(),
  warmup = 2000, iter = 5000, 
  cores = 2, 
  chains = 4,
  seed = 123 
)
```
# Check model fit.

```{r}
summary(model1)
```
```{r}
pairs(model1)
```


# Predict()

First we use `predict()` to calculate a treatment effect for each patient. This gives us a standard error for each patient, but we lose a lot of information we need to properly calculate the posterior distribution for the ATE.
But we can compare later on.

```{r}
df_sim_t0 <- df_sim %>% mutate(Treatment = 0)

df_sim_t1 <- df_sim %>% mutate(Treatment = 1)

df_sim_preds <- df_sim %>% mutate(Voorspellingt0 = predict(model1, newdata = df_sim_t0))

df_sim_preds <- df_sim_preds %>% mutate(Voorspellingt1 = predict(model1, newdata = df_sim_t1))
```

Ok, so far so good. Now move on to `posterior_predict()`

# Posterior_predict()

PM 

```{r}
pp_t0 <- posterior_predict(model1, newdata = df_sim_t0)

pp_t1 <- posterior_predict(model1, newdata = df_sim_t1)

diff <- pp_t1 - pp_t0
```

Check if we still understand what is going on.

We now have for eacht datapoint, for each sample a treatment effect (based on the difference of two draws from the model, with Treatment on and off).

Averaging over all datapoints and samples should give us the estimated treatment effect.

Compare to the fit parameters (intercept and treatment).
We calculate upper and lower bounds using the CI values from `brm`

```{r}
mean(diff)

est_t <- -0.89
est_intercept <- -0.02
est_pred_eff <- 0.1
avg_pred <- mean(df_sim$Predictor)

# brm fit parameters (intercept plus treatment)
mean_val <- exp(est_intercept + (est_pred_eff * df_sim$Predictor) +  est_t) - exp(est_intercept + (est_pred_eff * df_sim$Predictor))

mean_val_alt <- df_sim_preds[,8][,1] - df_sim_preds[,7][,1] 

#mean_val <- mean(mean_val)
plot(mean_val, mean_val_alt)
abline(0, 1)

mean(mean_val)
# use the Q5 Q95 vals for the model uncertainty (we ignore the uncertainty in the intercept, tricky to add)
#lower_val <- exp(-0.02+0.1*9.47 - 1.12) - exp(-0.02+0.1*9.47)
#upper_val <- exp(-0.02 + 0.1*9.47 - 0.68) - exp(-0.02+0.1*9.47)
```

Now average over all datapoints, but keep the samples dimension.
This is the estimated effect, FOR A PARTICULAR SAMPLE.

```{r}
mean_per_sample <- apply(diff, 1, mean)
```

The samples dimension now gives us the variability (uncertainty) of the estimate.

We compare with the Poisson model fit parameter for Treatment.

```{r}
ggplot(data.frame(mean_per_sample), aes(x = mean_per_sample)) +
  geom_histogram() + 
  geom_vline(xintercept = mean(mean_val))# +
#  geom_vline(xintercept = lower_val) +
#  geom_vline(xintercept = upper_val)
```
The variability in the samples is slightly higher than expected. This is likely due to us ignoring the uncertainty in the Intercept and Predictor.
