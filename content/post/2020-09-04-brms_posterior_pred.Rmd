---
title: The posterior distribution of an average treatment effect in Stan using brms::posterior_predict()
author: Gertjan Verhoeven & Misja Mikkers
date: '2020-09-04'
summary: Here we show how to calculate the posterior distribution of the adjusted average treatment effect for the covariates of a particular population using Stan & brms. 
slug: posterior-distribution-average-treatment-effect
draft: FALSE
categories:
  - R
tags:
  - brms, ate, causal effect, bayesian statistics
baseurl: "https://gsverhoeven.github.io"
header:
  image: "headers/national-cancer-institute-lSE4l8x2J7k-unsplash.jpg"
  preview: FALSE
---

# Introduction

Suppose we have data from a Randomized Controlled Trial (RCT) and we want to estimate the average treatment effect (ATE). 
Patients get treated, or not, depending only on a coin flip. This is encoded in the `Treatment` variable.
The outcome is a count variable `Admissions`, representing the number of times the patient gets admitted to the hospital.
The treatment is expected to reduce the number of hospital admissions for patients.

To complicate matters (a bit): As is often the case with patients, not all patients are identical :)
Suppose that older patients have on average more Admissions. So `Age` is a covariate.

# Average treatment effect (ATE)

Now, after we fitted a model to the data, we want to actually **use** our model to answer "What-if" questions (counterfactuals).
Here we answer the following question: 

* What would the average reduction in Admissions be if we had treated **ALL** the patients in the sample, compared to a situation where **NO** patient in the sample would have received treatment?

Well, that is easy, we just take the fitted model, change treatment from zero to one for each, and observe the ("marginal") effect on the outcome, right?

Yes, but the uncertainty is harder. We have uncertainty in the estimated coefficients of the intercept and covariate, as well us in the treatment variable. And these uncertainties can be correlated (for example between the coefficients of intercept and covariate).

Here we show how to use `posterior_predict()` to simulate outcomes of the model using the sampled parameters.
If we do this for two counterfactuals, all patients treated, and all patients untreated, and subtract these, we can easily calculate the posterior distribution of the average treatment effect.

Let's do it!

# Packages used

This tutorial uses [brms](https://github.com/paul-buerkner/brms), allowing user-friendly bayesian modelling with [Stan](https://mc-stan.org/.

```{r, message = TRUE, warning = TRUE}
library(tidyverse)
library(rstan)
library(brms) 
```

# Data simulation

We generate fake data that matches our problem setup.

`Admissions` are determined by patient `Age`, whether the patient has `Treatment`, and some random `Noise` to capture unobserved effects that influence `Admissions`. We exponentiate them to always get a positive number, and plug it in the Poisson distribution using `rpois()`.

```{r}
set.seed(123) 

id <- 1:200   
n_obs <- length(id)
b_tr <- 0.7
b_age <- 0.1

df_sim <- as.data.frame(id) %>% 
mutate(Age = rgamma(n_obs, shape = 5, scale = 2)) %>% # positive cont predictor
mutate(Noise = rnorm(n_obs, mean = 0, sd = 0.5)) %>% # add noise
mutate(Treatment = ifelse(runif(n_obs) < 0.5, 0, 1)) %>% # Flip a coin for treatment
mutate(Lambda = exp(b_age * Age - b_tr * Treatment + Noise)) %>% # generate lambda for the poisson dist
mutate(Admissions = rpois(n_obs, lambda = Lambda))

```


# Summarize data

Ok, so what does our dataset look like?

```{r}
summary(df_sim)
```

The Treatment variable should reduce admissions.
Lets visualize the distribution of Admission values for both treated and untreated patients:

```{r, warning=FALSE}
ggplot(data = df_sim, aes(x = Admissions)) +
  geom_histogram(stat="count") +
  facet_wrap(~ Treatment) + 
  theme_bw()
```

The effect of the treatment on reducing admissions is clearly visible. Now lets fit our Bayesian Poisson model to it.

# Fit model

We use `brms` default priors for convenience here. For a real application we would of course put effort into into crafting priors that reflect our current knowledge of the problem at hand.

```{r}
model1 <- brm(
  formula = as.integer(Admissions) ~  Age + Treatment,
   data = df_sim,
  family = poisson(),
  warmup = 2000, iter = 5000, 
  cores = 2, 
  chains = 4,
  seed = 123,
  silent = TRUE,
  refresh = 0,
)
```
# Check model fit

```{r}
summary(model1)
```

We see that the posterior dists for $\beta_{Age}$ and $\beta_{Treatment}$ cover the true values, so looking good.
To get a fuller glimpse into the (correlated) uncertainty of the model parameters we make a pairs plot:

```{r}
pairs(model1)
```

As expected, the coefficients $\beta_{Intercept}$ (added by `brms`) and $\beta_{Age}$ are highly correlated.

# Approach 1: Calculate Individual Treatment effects using the model fit object

We can calculate for each patient an individual treatment effect using the estimated model parameters.

```{r}
est_intercept <- fixef(model1, pars = "Intercept")[,1]
est_age_eff <- fixef(model1, pars = "Age")[,1]
est_t <- fixef(model1, pars = "Treatment")[,1]

# brm fit parameters (intercept plus treatment)
ites <- exp(est_intercept + (est_age_eff * df_sim$Age) +  est_t) - exp(est_intercept + (est_age_eff * df_sim$Age))

ggplot(data.frame(ites), aes(x = ites)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(ites), col = "red")
```

Averaging the ITEs gives us the ATE, displayed in red. 

Ok, so **on average**, our treatment reduces the number of Admissions by -1.9. 

You may wonder: why do we even have a distribution of treatment effects here? Should it not be the same for each patient?
Here a peculiarity of the Poisson regression model comes to surface: 
The effect of changing `Treatment` from 0 to 1 on the outcome depends on the value of `Age` of the patient.
Why? Because we exponentiate the linear model before we plug it into the Poisson distribution.

Next, the uncertainty. How to get all this underlying uncertainty in the model parameters, that have varying effects depending on the covariates of patients, and properly incorporate  that in the ATE?

For this we have to work with the full posterior distribution of model parameters.

# Predict()

First we use `predict()` to calculate a treatment effect for each patient. 

Note that by default, `summary = TRUE` and thus we get for each datapoint a summary (mean, std. dev, 2.5% and 97.5% quantiles) of the posterior distribution of plausible outcomes given the covariates of that datapoint.

By subtracting for each patient the mean outcome when treated from the mean outcome when not treated, we get an **individual treatment effect** (ITE).

```{r}
df_sim_t0 <- df_sim %>% mutate(Treatment = 0)

df_sim_t1 <- df_sim %>% mutate(Treatment = 1)

df_sim_preds <- df_sim %>% mutate(Voorspellingt0 = 
                                    predict(model1, newdata = df_sim_t0))

df_sim_preds <- df_sim_preds %>% mutate(Voorspellingt1 = 
                                          predict(model1, newdata = df_sim_t1))
```

```{r}
# ITEs
tr_effs <- df_sim_preds[,8][,1] - df_sim_preds[,7][,1] 

ggplot(data.frame(tr_effs), aes(x = tr_effs)) + 
  geom_histogram() +
  geom_vline(xintercept = mean(tr_effs), col = "red")
```


But what is the range of plausible values of the ATE consistent with the data & model?

We move on to `brms::posterior_predict()`. 
This is basically just `brms::predict(summary = FALSE)`.

# Posterior_predict()

Now that we have some experience using `predict()`, let us look a bit under the hood.

`posterior_predict()` (and therefore `predict()` as well) has two tricks:

The first trick is to take advantage of the fact that we have the full set of parameter draws from the posterior.
Conceptually, we imagine that each separate draw of the posterior represents a particular version of our model. 
In our example model fit, we have 12.000 samples from the posterior. 

Thus, we have 12.000 versions of our model, where unlikely parameter combinations occur less often compared to likely parameter combinations. The full uncertainty of our model parameters is contained in this "collection of models" . 

The second trick is that we simulate (generate) predictions from each of these 12.000 models.
Under the hood, this means computing for each model (we have 12.000), for each observation (we have 200) the predicted lambda value given the covariates, and drawing a single value from a Poisson distribution with that $\Lambda$ value (e.g. running `rpois(n = 1, lambda)` ).

This gives us a 12.000 x 200 matrix, that we can compute with.
For our application, the computation is simple: use `posterior_predict()` on our dataset with Treatment set to zero, do the same for our dataset with Treatment set to one, and subtract the two matrices.

```{r}
pp_t0 <- posterior_predict(model1, newdata = df_sim_t0)

pp_t1 <- posterior_predict(model1, newdata = df_sim_t1)

diff <- pp_t1 - pp_t0
```

Averaging over all datapoints and samples should give us the estimated treatment effect.



Now average over all datapoints, but keep the samples dimension.
This is the estimated effect, FOR A PARTICULAR SAMPLE.

```{r}
mean_per_sample <- apply(diff, 1, mean)
```

The samples dimension now gives us the variability (uncertainty) of the estimate.

We compare with the Poisson model fit parameter for Treatment.

```{r}
ggplot(data.frame(mean_per_sample), aes(x = mean_per_sample)) +
  geom_histogram() + 
  geom_vline(xintercept = mean(mean_val))# +
#  geom_vline(xintercept = lower_val) +
#  geom_vline(xintercept = upper_val)
```
The variability in the samples is slightly higher than expected. This is likely due to us ignoring the uncertainty in the Intercept and Predictor.

# To conclude


