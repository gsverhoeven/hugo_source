---
title: Cronbach's alpha and its models
author: Gertjan Verhoeven
date: '2019-06-20'
summary: Working for the first time with questionnaire data, I felt i needed some basic understanding of measurement theory, and the various approaches regarding reliability and validity of questionnaires.
slug: cronbach-alpha-measurement-theory
draft: TRUE
categories:
  - R
tags:
  - cronbach's alpha, validity
baseurl: "https://gsverhoeven.github.io"
header:
  image: "headers/ceiling-clean-clinic-247786.jpg"
  preview: FALSE

---



<div id="summary" class="section level1">
<h1>Summary</h1>
<p>Working for the first time with questionnaire data, I felt i needed some basic understanding of measurement theory, and the various approaches regarding reliability and validity of questionnaires.</p>
<p>Cronbach’s alpha was something I already associated with the social sciences before I knew any stats.
So I was curious to find out what it is, and how it can be useful.</p>
<p>As always, we use simulated data. Fortunately, the <code>psych</code> package by Hugh Revelle contains functions to simulate data with the appropriate structure.</p>
<p>Before getting busy, let us explain the statistical models that underlie Cronbach ’s alpha.
In this I follow Cho (2016). This study proves that various reliability coefficients are generated from measurement models nested within the bi-factor measurement model.</p>
<p>Unfortunately, with rare exceptions, we normally are faced with just one test, not two, three or four. How then to estimate the reliability of that one test?</p>
<p>It has been proposed that α {} can be viewed as the expected correlation of two tests that measure the same construct. By using this definition, it is implicitly assumed that the average correlation of a set of items is an accurate estimate of the average correlation of all items that pertain to a certain construct.</p>
<p>The term item is used throughout this article, but items could be anything—questions, raters, indicators- for all of which, one might ask, to what extent they “measure the same thing.” Items that are manipulated are commonly referred to as variables.</p>
</div>
<div id="revelle" class="section level1">
<h1>Revelle:</h1>
<p>Although defined in terms of the correlation of a test with a test just like it, reliability can be estimated by the characteristics of the items <em>within the test</em>. The desire for an easy to use “magic bullet” based upon the <em>domain sampling model</em> has led to a number of solutions for estimating the reliability of a test based upon characteristics of the covariances of the items. All of these estimates are based upon <em>classical test theory</em> and assume that the covariances between items represents true covariance, but that the variances of the items reflect an unknown sum of true and unique variance.</p>
<p>A <em>tau-equivalent</em> measurement model is a special case of a <em>congeneric</em> measurement model, hereby assuming all factor loadings to be the same.</p>
<p>The most important difference between CTT and IRT is that in CTT, one uses a common estimate of the measurement precision that is assumed to be equal for all individuals irrespective of their attribute levels. In IRT, however, the measurement precision depends on the latent-attribute value. This can result in differences between CTT and IRT with respect to their conclusions about statistical significance of change.</p>
</div>
<div id="cronbach-s-alpha-and-its-measurement-models" class="section level1">
<h1>Cronbach ’s alpha and its measurement models</h1>
<p>Cronbach’s alpha is meant for single latent variables / factors / traits.</p>
<p>Classical Test Theory (CTT) considers four or more tests to be congenerically equivalent if all tests may be expressed in terms of one factor and a residual error. (N.b. we need at least four tests to identify all free parameters of the model).</p>
<p>To determine the scale, the variance of the latent variable is set to 1.</p>
<ul>
<li><p>Congeneric tests may differ in both factor loading and error variances.
The congeneric model does not have additional constraints.</p></li>
<li><p>The tau-equivalent model is the same as the congeneric model, only with the constraint that all the factor loadings are equal, but allows the error variances to vary from item to item.
Tau equivalent tests have equal factor loadings but may have unequal errors.</p></li>
</ul>
<p>For example, an <em>essentially tau-equivalent model</em> includes a constant, whereas a <em>strictly tau-equivalent model</em> does not. Although the addition of a constant has an effect on the mean, it does not affect the
variances, covariances or the value of reliability.</p>
<ul>
<li>The (unidimensional) parallel model is the tau-equivalent model with the constraint that the error variances are all equal. Parallel tests are the special case where (usually two) tests have equal factor loadings.</li>
</ul>
</div>
<div id="step-one-simulate-data-for-a-congeneric-model" class="section level1">
<h1>Step one: simulate data for a congeneric model</h1>
<pre class="r"><code>library(ggplot2)
library(psych)</code></pre>
<pre><code>## 
## Attaching package: &#39;psych&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:ggplot2&#39;:
## 
##     %+%, alpha</code></pre>
<pre class="r"><code>set.seed(42) #keep the same starting values
#four congeneric measures

loadings &lt;- rep(1, 4)
loadings &lt;- c(0.8, 0.7, 0.6, 0.5)

errors &lt;- c(0.8, 0.7, 0.6, 0.5)

errors &lt;- sqrt(1 - loadings^2)
errors &lt;- rep(0.1, 4)

r4 &lt;- psych::sim.congeneric(loads = loadings,
                            err = errors, #A vector of error variances 
                            low = -3, # values less than low are forced to low (when cat = T)
                            high = 3, # values greater than high are forced to high
                            short = FALSE, 
                            categorical = FALSE,
                            N = 10000)</code></pre>
<p>Now we have less noise on the item with the lower factor loadings.
<span class="math inline">\(\theta\)</span> is the (common) latent variable.</p>
</div>
<div id="step-two-describe-simulated-data" class="section level1">
<h1>Step two: describe simulated data</h1>
<pre class="r"><code>my.df &lt;- data.frame(r4$latent, r4$observed)

# Check factor loadings
fit1 &lt;- lm(V1 ~ theta, data = my.df)
fit2 &lt;- lm(V2 ~ theta, data = my.df)
fit3 &lt;- lm(V3 ~ theta, data = my.df)
fit4 &lt;- lm(V4 ~ theta, data = my.df)

sd(fit1$residuals)</code></pre>
<pre><code>## [1] 0.1007705</code></pre>
<pre class="r"><code>sd(fit2$residuals)</code></pre>
<pre><code>## [1] 0.1013989</code></pre>
<pre class="r"><code>sd(fit3$residuals)</code></pre>
<pre><code>## [1] 0.1008644</code></pre>
<pre class="r"><code>sd(fit4$residuals)</code></pre>
<pre><code>## [1] 0.09897803</code></pre>
<pre class="r"><code>errors &lt;- my.df[, colnames(my.df) %in% c(&quot;e1&quot;, &quot;e2&quot;, &quot;e3&quot;, &quot;e4&quot;)]

cor(errors)</code></pre>
<pre><code>##              e1           e2           e3           e4
## e1  1.000000000  0.010432462  0.002030510 -0.006050927
## e2  0.010432462  1.000000000 -0.008618315 -0.027381449
## e3  0.002030510 -0.008618315  1.000000000 -0.005340683
## e4 -0.006050927 -0.027381449 -0.005340683  1.000000000</code></pre>
<pre class="r"><code># errors are uncorrelated with each other
cov(errors)</code></pre>
<pre><code>##              e1          e2           e3           e4
## e1  1.015522554  0.01066020  0.002063898 -0.006035393
## e2  0.010660197  1.02817565 -0.008814430 -0.027480772
## e3  0.002063898 -0.00881443  1.017364269 -0.005331801
## e4 -0.006035393 -0.02748077 -0.005331801  0.979665221</code></pre>
<pre class="r"><code>var(my.df$e1)</code></pre>
<pre><code>## [1] 1.015523</code></pre>
<pre class="r"><code>var(my.df$theta)</code></pre>
<pre><code>## [1] 1.012307</code></pre>
</div>
<div id="step-three-calculate-cronbachs-alpha" class="section level1">
<h1>Step three: Calculate Cronbach’s Alpha</h1>
<p>Ok, let’s have it. The cronbach alpha.</p>
<pre class="r"><code># r4 population correlation matrix
psych::alpha(r4$observed)</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: psych::alpha(x = r4$observed)
## 
##   raw_alpha std.alpha G6(smc) average_r S/N     ase    mean   sd median_r
##       0.98      0.99    0.99      0.97 154 0.00013 -0.0074 0.66     0.97
## 
##  lower alpha upper     95% confidence boundaries
## 0.98 0.98 0.98 
## 
##  Reliability if an item is dropped:
##    raw_alpha std.alpha G6(smc) average_r S/N alpha se   var.r med.r
## V1      0.98      0.99    0.99      0.97 102  0.00021 1.9e-05  0.97
## V2      0.97      0.99    0.99      0.97 109  0.00023 3.1e-05  0.97
## V3      0.98      0.99    0.99      0.98 119  0.00021 3.8e-05  0.97
## V4      0.99      0.99    0.99      0.98 140  0.00015 9.8e-06  0.98
## 
##  Item statistics 
##        n raw.r std.r r.cor r.drop    mean   sd
## V1 10000  0.99  0.99  0.99   0.99 -0.0090 0.81
## V2 10000  0.99  0.99  0.99   0.99 -0.0071 0.71
## V3 10000  0.99  0.99  0.99   0.98 -0.0070 0.61
## V4 10000  0.99  0.99  0.98   0.98 -0.0066 0.51</code></pre>
<p>Check with ground truth:</p>
<pre class="r"><code># calculate total score
my.df$sumV &lt;- with(my.df, V1+V2+V3+V4)

my.df$sumE &lt;- with(my.df, e1+e2+e3+e4)

plot(my.df$sumV, my.df$theta)</code></pre>
<p><img src="/post/2020-01-20-cronbach_alpha_blog_files/figure-html/unnamed-chunk-4-1.png" width="672" /></p>
<pre class="r"><code># raw alpha
(1-sum(diag(cov(r4$observed)))/var(my.df$sumV))*4/3</code></pre>
<pre><code>## [1] 0.984329</code></pre>
<pre class="r"><code>cov(r4$observed)</code></pre>
<pre><code>##           V1        V2        V3        V4
## V1 0.6568506 0.5665898 0.4855468 0.4045279
## V2 0.5665898 0.5065013 0.4252159 0.3541304
## V3 0.4855468 0.4252159 0.3746968 0.3037033
## V4 0.4045279 0.3541304 0.3037033 0.2629166</code></pre>
</div>
<div id="and-why-does-this-measure-reliability-of-a-test" class="section level1">
<h1>And why does this measure “reliability” of a test?</h1>
<p>The resulting α coefficient of reliability ranges from 0 to 1 in providing this overall assessment of a measure’s reliability. If all of the scale items are entirely independent from one another (i.e., are not correlated or share no covariance), then α = 0; and, if all of the items have high covariances, then α will approach 1 as the number of items in the scale approaches infinity.</p>
<p>Cronbach’s α {} assumes that all factor loadings are equal. In reality this is rarely the case, and hence it systematically underestimates the reliability. An alternative to Cronbach’s α {} that does not rely on this assumption is congeneric reliability ( ρ C {<em>{C}} </em>{C})</p>
</div>
<div id="does-it-measure-unidimensionality" class="section level1">
<h1>Does it measure unidimensionality?</h1>
<p>Let ’s simulate data that has TWO factors, that are fully independent (uncorrelated).
So that’s two independent (orthogonal) factors.</p>
<pre class="r"><code># examples of two independent factors that produce reasonable alphas
#this is a case where alpha is a poor indicator of unidimensionality
set.seed(123)
two.f &lt;- data.frame(sim.item(nvar = 8,
                             nsub = 10000))

with(two.f, plot(V1, V3))</code></pre>
<p><img src="/post/2020-01-20-cronbach_alpha_blog_files/figure-html/unnamed-chunk-6-1.png" width="672" /></p>
<pre class="r"><code>#sim.item(nvar = 72, nsub = 500, circum = FALSE, xloading = 0.6, yloading = 0.6, 
# gloading = 0, xbias = 0, ybias = 0, categorical = FALSE, low = -3, high = 3, 
# truncate = FALSE, cutpoint = 0)

#specify which items to reverse key by name
alpha(two.f, keys = c(&quot;V1&quot;,&quot;V2&quot;,&quot;V7&quot;,&quot;V8&quot;))</code></pre>
<pre><code>## 
## Reliability analysis   
## Call: alpha(x = two.f, keys = c(&quot;V1&quot;, &quot;V2&quot;, &quot;V7&quot;, &quot;V8&quot;))
## 
##   raw_alpha std.alpha G6(smc) average_r S/N    ase  mean   sd median_r
##        0.6       0.6    0.63      0.16 1.5 0.0062 0.053 0.51    0.017
## 
##  lower alpha upper     95% confidence boundaries
## 0.58 0.6 0.61 
## 
##  Reliability if an item is dropped:
##     raw_alpha std.alpha G6(smc) average_r S/N alpha se var.r med.r
## V1-      0.56      0.56    0.59      0.15 1.3   0.0068 0.032 0.019
## V2-      0.57      0.57    0.59      0.16 1.3   0.0068 0.031 0.019
## V3       0.56      0.56    0.59      0.16 1.3   0.0068 0.032 0.019
## V4       0.56      0.56    0.59      0.16 1.3   0.0068 0.033 0.014
## V5       0.56      0.56    0.59      0.15 1.3   0.0068 0.033 0.013
## V6       0.56      0.56    0.59      0.16 1.3   0.0068 0.032 0.019
## V7-      0.56      0.56    0.59      0.15 1.3   0.0068 0.033 0.014
## V8-      0.57      0.57    0.60      0.16 1.3   0.0067 0.032 0.019
## 
##  Item statistics 
##         n raw.r std.r r.cor r.drop    mean   sd
## V1- 10000  0.52  0.52  0.42   0.31  0.1112 1.00
## V2- 10000  0.51  0.50  0.40   0.29  0.0949 1.00
## V3  10000  0.51  0.51  0.40   0.29  0.0048 1.01
## V4  10000  0.51  0.51  0.40   0.30 -0.0029 0.99
## V5  10000  0.52  0.52  0.41   0.30  0.0104 1.00
## V6  10000  0.51  0.51  0.41   0.30  0.0143 1.00
## V7- 10000  0.51  0.52  0.41   0.30  0.1067 0.99
## V8- 10000  0.50  0.50  0.38   0.28  0.0837 1.01</code></pre>
</div>
<div id="references" class="section level1">
<h1>References</h1>
<ul>
<li><p>Cho, E (2016). “Making Reliability Reliable”. Organizational Research Methods. 19 (4): 651–682
<a href="https://rameliaz.github.io/mg-sem-workshop/cho2016.pdf" class="uri">https://rameliaz.github.io/mg-sem-workshop/cho2016.pdf</a></p></li>
<li><p>Revelle, W The Personality Project: <a href="https://www.personality-project.org/r/book/Chapter7.pdf" class="uri">https://www.personality-project.org/r/book/Chapter7.pdf</a></p></li>
</ul>
</div>
